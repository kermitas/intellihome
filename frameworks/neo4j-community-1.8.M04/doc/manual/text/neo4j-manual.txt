
-------------------------------------------------------------------------------

The Neo4j Manual v1.8.M04

-------------------------------------------------------------------------------

The Neo4j Team neo4j.org <http://neo4j.org/> neotechnology.com <http://
neotechnology.com/>

Copyright © 2012 Neo Technology

License: Creative Commons 3.0

2012-06-11 06:26:23

Quickstart

  * Section 2.1, “What is a Graph Database?”

  * Chapter 16, Cypher Query Language

  * Chapter 4, Using Neo4j embedded in Java applications

  * Chapter 11, Using Neo4j embedded in Python applications

  * Chapter 6, Neo4j Remote Client Libraries

  * Chapter 10, Languages

  * Chapter 18, Neo4j Server

  * Chapter 19, REST API

-------------------------------------------------------------------------------

Table of Contents

Preface
I. Introduction

    1. Neo4j Highlights
    2. Graph Database Concepts

        2.1. What is a Graph Database?

            2.1.1. A Graph contains Nodes and Relationships
            2.1.2. Relationships organize the Graph
            2.1.3. Query a Graph with a Traversal
            2.1.4. Indexes look-up Nodes or Relationships
            2.1.5. Neo4j is a Graph Database

        2.2. Comparing Database Models

            2.2.1. A Graph Database transforms a RDBMS
            2.2.2. A Graph Database elaborates a Key-Value Store
            2.2.3. A Graph Database relates Column-Family
            2.2.4. A Graph Database navigates a Document Store

    3. The Neo4j Graph Database

        3.1. Nodes
        3.2. Relationships
        3.3. Properties
        3.4. Paths
        3.5. Traversal

II. Tutorials

    4. Using Neo4j embedded in Java applications

        4.1. Include Neo4j in your project

            4.1.1. Add Neo4j to the build path
            4.1.2. Add Neo4j as a dependency
            4.1.3. Starting and stopping

        4.2. Hello World

            4.2.1. Prepare the database
            4.2.2. Wrap mutating operations in a transaction
            4.2.3. Create a small graph
            4.2.4. Print the result
            4.2.5. Remove the data
            4.2.6. Shut down the database server

        4.3. User database with index
        4.4. Basic unit testing
        4.5. Traversal

            4.5.1. The Matrix
            4.5.2. Old traversal API
            4.5.3. Uniqueness of Paths in traversals
            4.5.4. Social network

        4.6. Domain entities
        4.7. Graph Algorithm examples
        4.8. Reading a management attribute
        4.9. OSGi setup

            4.9.1. Simple OSGi Activator scenario

        4.10. Execute Cypher Queries from Java

    5. Cypher Cookbook

        5.1. Hyperedges and Cypher

            5.1.1. Find Groups
            5.1.2. Find all groups and roles for a user
            5.1.3. Find common groups based on shared roles

        5.2. Basic Friend finding based on social neighborhood

            5.2.1. Simple Friend Finder

        5.3. Co-favorited places

            5.3.1. Co-Favorited Places - Users Who Like x Also Like y
            5.3.2. Co-Tagged Places - Places Related through Tags

        5.4. Find people based on similar favorites

            5.4.1. Find people based on similar favorites

        5.5. Find people based on mutual friends and groups

            5.5.1. Find mutual friends and groups

        5.6. Find friends based on similar tagging

            5.6.1. Find people based on similar tagged favorties

        5.7. Multirelational (social) graphs

            5.7.1. Who FOLLOWS or LOVES me back

        5.8. Pretty graphs in Cypher

            5.8.1. Star graph
            5.8.2. Wheel graph
            5.8.3. Complete graph
            5.8.4. Friendship graph

        5.9. Complex updates

            5.9.1. Insert a new value into a linked list

        5.10. A multilevel indexing structure (path tree)

            5.10.1. Return zero range
            5.10.2. Return the full range
            5.10.3. Return partly shared path ranges

        5.11. More complex similarity computations

            5.11.1. Calculate similarities by complex calculations

    6. Neo4j Remote Client Libraries

        6.1. How to use the REST API from Java

            6.1.1. Creating a graph through the REST API from Java
            6.1.2. Start the server
            6.1.3. Creating a node
            6.1.4. Adding properties
            6.1.5. Adding relationships
            6.1.6. Add properties to a relationship
            6.1.7. Querying graphs
            6.1.8. Phew, is that it?
            6.1.9. What’s next?
            6.1.10. Appendix: the code

    7. Extending the Neo4j Server

        7.1. Server Plugins
        7.2. Unmanaged Extensions

    8. The Traversal Framework

        8.1. Main concepts
        8.2. Traversal Framework Java API

            8.2.1. TraversalDescription
            8.2.2. Evaluator
            8.2.3. Traverser
            8.2.4. Uniqueness
            8.2.5. Order - How to move through branches?
            8.2.6. BranchSelector
            8.2.7. Path
            8.2.8. PathExpander/RelationshipExpander
            8.2.9. Expander
            8.2.10. How to use the Traversal framework

    9. Domain Modeling Gallery

        9.1. User roles in graphs

            9.1.1. Get the admins
            9.1.2. Get the group memberships of a user
            9.1.3. Get all groups
            9.1.4. Get all members of all groups

        9.2. ACL structures in graphs

            9.2.1. Generic approach
            9.2.2. Read-permission example

    10. Languages
    11. Using Neo4j embedded in Python applications

        11.1. Hello, world!
        11.2. A sample app using traversals and indexes

            11.2.1. Domain logic
            11.2.2. Creating data and getting it back

III. Reference

    12. Capabilities

        12.1. Data Security
        12.2. Data Integrity

            12.2.1. Core Graph Engine
            12.2.2. Different Data Sources

        12.3. Data Integration

            12.3.1. Event-based Synchronization
            12.3.2. Periodic Synchronization
            12.3.3. Periodic Full Export/Import of Data

        12.4. Availability and Reliability

            12.4.1. Operational Availability
            12.4.2. Disaster Recovery/ Resiliency

        12.5. Capacity

            12.5.1. File Sizes
            12.5.2. Read speed
            12.5.3. Write speed
            12.5.4. Data size

    13. Transaction Management

        13.1. Interaction cycle
        13.2. Isolation levels
        13.3. Default locking behavior
        13.4. Deadlocks
        13.5. Delete semantics
        13.6. Creating unique nodes

            13.6.1. Single thread
            13.6.2. Get or create
            13.6.3. Pessimistic locking

        13.7. Transaction events

    14. Data Import

        14.1. Batch Insertion

            14.1.1. Batch Inserter Examples
            14.1.2. Batch Graph Database
            14.1.3. Index Batch Insertion

    15. Indexing

        15.1. Introduction
        15.2. Create
        15.3. Delete
        15.4. Add
        15.5. Remove
        15.6. Update
        15.7. Search

            15.7.1. Get
            15.7.2. Query

        15.8. Relationship indexes
        15.9. Scores
        15.10. Configuration and fulltext indexes
        15.11. Extra features for Lucene indexes

            15.11.1. Numeric ranges
            15.11.2. Sorting
            15.11.3. Querying with Lucene Query objects
            15.11.4. Compound queries
            15.11.5. Default operator
            15.11.6. Caching

        15.12. Automatic Indexing

            15.12.1. Configuration
            15.12.2. Search
            15.12.3. Runtime Configuration
            15.12.4. Updating the Automatic Index

    16. Cypher Query Language

        16.1. Operators
        16.2. Expressions
        16.3. Parameters
        16.4. Identifiers
        16.5. Comments
        16.6. Updating the graph with Cypher

            16.6.1. Updating query structure
            16.6.2. Query Parts & Structure
            16.6.3. Returning data

        16.7. Transactions and Cypher
        16.8. Patterns
        16.9. Start

            16.9.1. Node by id
            16.9.2. Relationship by id
            16.9.3. Multiple nodes by id
            16.9.4. All nodes
            16.9.5. Node by index lookup
            16.9.6. Relationship by index lookup
            16.9.7. Node by index query
            16.9.8. Multiple start points

        16.10. Match

            16.10.1. Introduction
            16.10.2. Related nodes
            16.10.3. Outgoing relationships
            16.10.4. Directed relationships and identifier
            16.10.5. Match by relationship type
            16.10.6. Match by multiple relationship types
            16.10.7. Match by relationship type and use an identifier
            16.10.8. Relationship types with uncommon characters
            16.10.9. Multiple relationships
            16.10.10. Variable length relationships
            16.10.11. Relationship identifier in variable length relationships
            16.10.12. Zero length paths
            16.10.13. Optional relationship
            16.10.14. Optional typed and named relationship
            16.10.15. Properties on optional elements
            16.10.16. Complex matching
            16.10.17. Shortest path
            16.10.18. All shortest paths
            16.10.19. Named path
            16.10.20. Matching on a bound relationship

        16.11. Where

            16.11.1. Boolean operations
            16.11.2. Filter on node property
            16.11.3. Regular expressions
            16.11.4. Escaping in regular expressions
            16.11.5. Case insensitive regular expressions
            16.11.6. Filtering on relationship type
            16.11.7. Property exists
            16.11.8. Default true if property is missing
            16.11.9. Default false if property is missing
            16.11.10. Filter on null values
            16.11.11. Filter on patterns
            16.11.12. IN operator

        16.12. Return

            16.12.1. Return nodes
            16.12.2. Return relationships
            16.12.3. Return property
            16.12.4. Return all elements
            16.12.5. Identifier with uncommon characters
            16.12.6. Column alias
            16.12.7. Optional properties
            16.12.8. Unique results

        16.13. Aggregation

            16.13.1. Introduction
            16.13.2. COUNT
            16.13.3. Count nodes
            16.13.4. Group Count Relationship Types
            16.13.5. Count entities
            16.13.6. Count non-null values
            16.13.7. SUM
            16.13.8. AVG
            16.13.9. MAX
            16.13.10. MIN
            16.13.11. COLLECT
            16.13.12. DISTINCT

        16.14. Order by

            16.14.1. Order nodes by property
            16.14.2. Order nodes by multiple properties
            16.14.3. Order nodes in descending order
            16.14.4. Ordering null

        16.15. Skip

            16.15.1. Skip first three
            16.15.2. Return middle two

        16.16. Limit

            16.16.1. Return first part

        16.17. With

            16.17.1. Filter on aggregate function results
            16.17.2. Alternative syntax of with

        16.18. Create

            16.18.1. Create single node
            16.18.2. Create single node and set properties
            16.18.3. Return created node
            16.18.4. Create a relationship between two nodes
            16.18.5. Create a relationship and set properties
            16.18.6. Create a full path
            16.18.7. Create single node from map
            16.18.8. Create multiple nodes from maps

        16.19. Delete

            16.19.1. Delete single node
            16.19.2. Remove a node and connected relationships
            16.19.3. Remove a property

        16.20. Set

            16.20.1. Set a property

        16.21. Relate

            16.21.1. Create relationship if it is missing
            16.21.2. Create node if missing
            16.21.3. Create nodes with values
            16.21.4. Create relationship with values
            16.21.5. Describe complex pattern

        16.22. Foreach

            16.22.1. Mark all nodes along a path

        16.23. Functions

            16.23.1. Predicates
            16.23.2. Scalar functions
            16.23.3. Iterable functions
            16.23.4. Mathematical functions

        16.24. Compatibility

    17. Graph Algorithms

        17.1. Introduction

    18. Neo4j Server

        18.1. Server Installation

            18.1.1. As a Windows service
            18.1.2. Linux Service
            18.1.3. Mac OSX
            18.1.4. Multiple Server instances on one machine

        18.2. Server Configuration

            18.2.1. Important server configurations parameters
            18.2.2. Neo4j Database performance configuration
            18.2.3. Server logging configuration
            18.2.4. HTTP logging configuration
            18.2.5. Other configuration options

        18.3. Setup for remote debugging
        18.4. Using the server (including web administration) with an embedded
            database

            18.4.1. Getting the libraries
            18.4.2. Starting the Server from Java
            18.4.3. Providing custom configuration

        18.5. Server Performance Tuning

            18.5.1. Specifying Neo4j tuning properties
            18.5.2. Specifying JVM tuning properties

        18.6. Server Installation in the Cloud

            18.6.1. Heroku

    19. REST API

        19.1. Service root

            19.1.1. Get service root

        19.2. Nodes

            19.2.1. Create Node
            19.2.2. Create Node with properties
            19.2.3. Get node
            19.2.4. Get non-existent node
            19.2.5. Delete node
            19.2.6. Nodes with relationships can not be deleted

        19.3. Relationships

            19.3.1. Get Relationship by ID
            19.3.2. Create relationship
            19.3.3. Create a relationship with properties
            19.3.4. Delete relationship
            19.3.5. Get all properties on a relationship
            19.3.6. Set all properties on a relationship
            19.3.7. Get single property on a relationship
            19.3.8. Set single property on a relationship
            19.3.9. Get all relationships
            19.3.10. Get incoming relationships
            19.3.11. Get outgoing relationships
            19.3.12. Get typed relationships
            19.3.13. Get relationships on a node without relationships

        19.4. Relationship types

            19.4.1. Get relationship types

        19.5. Node properties

            19.5.1. Set property on node
            19.5.2. Update node properties
            19.5.3. Get properties for node
            19.5.4. Property values can not be null
            19.5.5. Property values can not be nested
            19.5.6. Delete all properties from node
            19.5.7. Delete a named property from a node

        19.6. Relationship properties

            19.6.1. Update relationship properties
            19.6.2. Remove property from a relationship
            19.6.3. Remove non-existent property from a relationship
            19.6.4. Remove properties from a non-existing relationship
            19.6.5. Remove property from a non-existing relationship

        19.7. Indexes

            19.7.1. Create node index
            19.7.2. Create node index with configuration
            19.7.3. Delete node index
            19.7.4. List node indexes
            19.7.5. Add node to index
            19.7.6. Remove all entries with a given node from an index
            19.7.7. Remove all entries with a given node and key from an index
            19.7.8. Remove all entries with a given node, key and value from an
                index
            19.7.9. Find node by exact match
            19.7.10. Find node by query

        19.8. Unique Indexes

            19.8.1. Create a unique node in an index
            19.8.2. Create a unique node in an index (the case where it exists)
            19.8.3. Add a node to an index unless a node already exists for the
                given mapping
            19.8.4. Create a unique relationship in an index
            19.8.5. Add a relationship to an index unless a relationship
                already exists for the given mapping

        19.9. Automatic Indexes

            19.9.1. Find node by exact match from an automatic index
            19.9.2. Find node by query from an automatic index

        19.10. Configurable Automatic Indexing

            19.10.1. Create an auto index for nodes with specific configuration
            19.10.2. Create an auto index for relationships with specific
                configuration
            19.10.3. Get current status for autoindexing on nodes
            19.10.4. Enable node autoindexing
            19.10.5. Lookup list of properties being autoindexed
            19.10.6. Add a property for autoindexing on nodes
            19.10.7. Remove a property for autoindexing on nodes

        19.11. Traversals

            19.11.1. Traversal using a return filter
            19.11.2. Return relationships from a traversal
            19.11.3. Return paths from a traversal
            19.11.4. Traversal returning nodes below a certain depth
            19.11.5. Creating a paged traverser
            19.11.6. Paging through the results of a paged traverser
            19.11.7. Paged traverser page size
            19.11.8. Paged traverser timeout

        19.12. Cypher queries

            19.12.1. Send a Query
            19.12.2. Return paths
            19.12.3. Send queries with parameters
            19.12.4. Nested results
            19.12.5. Server errors

        19.13. Built-in Graph Algorithms

            19.13.1. Find all shortest paths
            19.13.2. Find one of the shortest paths between nodes
            19.13.3. Execute a Dijkstra algorithm with similar weights on
                relationships
            19.13.4. Execute a Dijkstra algorithm with weights on relationships

        19.14. Batch operations

            19.14.1. Execute multiple operations in batch
            19.14.2. Refer to items created earlier in the same batch job
            19.14.3. Execute multiple operations in batch streaming

        19.15. WADL Support
        19.16. Cypher Plugin

            19.16.1. Send a Query
            19.16.2. Return paths
            19.16.3. Send queries with parameters
            19.16.4. Server errors

        19.17. Gremlin Plugin

            19.17.1. Send a Gremlin Script - URL encoded
            19.17.2. Load a sample graph
            19.17.3. Sort a result using raw Groovy operations
            19.17.4. Send a Gremlin Script - JSON encoded with table results
            19.17.5. Returning nested pipes
            19.17.6. Set script variables
            19.17.7. Send a Gremlin Script with variables in a JSON Map
            19.17.8. Return paths from a Gremlin script
            19.17.9. Send an arbitrary Groovy script - Lucene sorting
            19.17.10. Emit a sample graph
            19.17.11. HyperEdges - find user roles in groups
            19.17.12. Group count
            19.17.13. Collect multiple traversal results
            19.17.14. Collaborative filtering
            19.17.15. Chunking and offsetting in Gremlin
            19.17.16. Modify the graph while traversing
            19.17.17. Flow algorithms with Gremlin
            19.17.18. Script execution errors

    20. Python embedded bindings

        20.1. Installation

            20.1.1. Installation on OSX/Linux
            20.1.2. Installation on Windows

        20.2. Core API

            20.2.1. Getting started
            20.2.2. Transactions
            20.2.3. Nodes
            20.2.4. Relationships
            20.2.5. Properties
            20.2.6. Paths

        20.3. Indexes

            20.3.1. Index management
            20.3.2. Indexing things
            20.3.3. Searching the index

        20.4. Cypher Queries

            20.4.1. Querying and reading the result
            20.4.2. Parameterized and prepared queries

        20.5. Traversals

            20.5.1. Basic traversals
            20.5.2. Traversal results
            20.5.3. Uniqueness
            20.5.4. Ordering
            20.5.5. Evaluators - advanced filtering

IV. Operations

    21. Installation & Deployment

        21.1. Deployment Scenarios

            21.1.1. Server
            21.1.2. Embedded

        21.2. System Requirements

            21.2.1. CPU
            21.2.2. Memory
            21.2.3. Disk
            21.2.4. Filesystem
            21.2.5. Software
            21.2.6. JDK Version

        21.3. Installation

            21.3.1. Embedded Installation
            21.3.2. Server Installation

        21.4. Upgrading

            21.4.1. Automatic Upgrade
            21.4.2. Explicit Upgrade
            21.4.3. Upgrade 1.6 → 1.7
            21.4.4. Upgrade 1.5 → 1.6
            21.4.5. Upgrade 1.4 → 1.5

        21.5. Usage Data Collector

            21.5.1. Technical Information
            21.5.2. How to disable UDC

    22. Configuration & Performance

        22.1. Introduction

            22.1.1. How to add configuration settings

        22.2. Performance Guide

            22.2.1. Try this first
            22.2.2. Neo4j primitives' lifecycle
            22.2.3. Configuring Neo4j

        22.3. Caches in Neo4j

            22.3.1. File buffer cache
            22.3.2. Object cache

        22.4. JVM Settings

            22.4.1. Configuring heap size and GC

        22.5. Compressed storage of short strings
        22.6. Compressed storage of short arrays
        22.7. Memory mapped IO settings

            22.7.1. Optimizing for traversal speed example
            22.7.2. Batch insert example

        22.8. Linux Performance Guide

            22.8.1. Setup
            22.8.2. Running the benchmark
            22.8.3. Fixing the problem

        22.9. Linux specific notes

            22.9.1. File system tuning for high IO
            22.9.2. Setting the number of open files

    23. High Availability

        23.1. Architecture
        23.2. Setup and configuration

            23.2.1. Small
            23.2.2. Medium
            23.2.3. Large
            23.2.4. Installation Notes

        23.3. How Neo4j HA operates
        23.4. High Availability setup tutorial

            23.4.1. Background
            23.4.2. Setup and start the Coordinator cluster
            23.4.3. Start the Neo4j Servers in HA mode
            23.4.4. Start Neo4j Embedded in HA mode

        23.5. Setting up HAProxy as a load balancer

            23.5.1. Installing HAProxy
            23.5.2. Configuring HAProxy
            23.5.3. Configuring separate sets for master and slaves
            23.5.4. Cache-based sharding with HAProxy

    24. Backup

        24.1. Embedded and Server
        24.2. Online Backup from Java
        24.3. High Availability
        24.4. Restoring Your Data

    25. Security

        25.1. Securing access to the Neo4j Server

            25.1.1. Secure the port and remote client connection accepts
            25.1.2. Arbitrary code execution
            25.1.3. HTTPS support
            25.1.4. Server Authorization Rules
            25.1.5. Hosted Scripting
            25.1.6. Security in Depth
            25.1.7. Rewriting URLs with a Proxy installation

    26. Monitoring

        26.1. JMX

            26.1.1. Adjusting remote JMX access to the Neo4j Server
            26.1.2. How to connect to a Neo4j instance using JMX and JConsole
            26.1.3. How to connect to the JMX monitoring programmatically
            26.1.4. Reference of supported JMX MBeans

V. Tools

    27. Web Administration

        27.1. Dashboard tab

            27.1.1. Entity chart
            27.1.2. Status monitoring

        27.2. Data tab
        27.3. Console tab
        27.4. The Server Info tab

    28. Neo4j Shell

        28.1. Starting the shell

            28.1.1. Enabling the shell server
            28.1.2. Connecting to a shell server
            28.1.3. Pointing the shell to a path
            28.1.4. Read-only mode
            28.1.5. Run a command and then exit

        28.2. Passing options and arguments
        28.3. Enum options
        28.4. Filters
        28.5. Node titles
        28.6. How to use (individual commands)

            28.6.1. Current node/relationship and path
            28.6.2. Listing the contents of a node/relationship
            28.6.3. Creating nodes and relationships
            28.6.4. Setting, renaming and removing properties
            28.6.5. Deleting nodes and relationships
            28.6.6. Environment variables
            28.6.7. Executing groovy/python scripts
            28.6.8. Traverse
            28.6.9. Query with Cypher
            28.6.10. Indexing
            28.6.11. Transactions

        28.7. Extending the shell: Adding your own commands
        28.8. An example shell session
        28.9. A Matrix example

VI. Community

    29. Community Support
    30. Contributing to Neo4j

        30.1. Contributor License Agreement

            30.1.1. Summary
            30.1.2. Common questions
            30.1.3. How to sign

        30.2. Areas for contribution

            30.2.1. Neo4j Distribution
            30.2.2. Maintaining Neo4j Documentation
            30.2.3. Drivers and bindings to Neo4j

        30.3. Writing Neo4j Documentation

            30.3.1. Overall Flow
            30.3.2. File Structure in docs.jar
            30.3.3. Headings and document structure
            30.3.4. Writing
            30.3.5. Gotchas
            30.3.6. Links
            30.3.7. Text Formatting
            30.3.8. Admonitions
            30.3.9. Images
            30.3.10. Attributes
            30.3.11. Comments
            30.3.12. Code Snippets
            30.3.13. A sample Java based documentation test
            30.3.14. Hello world Sample Chapter
            30.3.15. Integrated Live Console
            30.3.16. Toolchain

        30.4. Contributing Code to Neo4j

            30.4.1. Intro
            30.4.2. The Fast Track
            30.4.3. Governance fundamentals
            30.4.4. Contributor roles
            30.4.5. Code Style
            30.4.6. Unit Tests
            30.4.7. Workflow
            30.4.8. Commit messages

        30.5. Contributors

A. Manpages

    neo4j — Neo4j Server control and management
    neo4j-shell — a command-line tool for exploring and manipulating a graph
        database
    neo4j-backup — Neo4j Backup Tool
    neo4j-coordinator — Neo4j Coordinator for High-Availability clusters
    neo4j-coordinator-shell — Neo4j Coordinator Shell interactive interface

B. Questions & Answers

List of Figures

2.1. RDBMS
2.2. Graph Database as RDBMS
2.3. Key-Value Store
2.4. Graph Database as Key-Value Store
2.5. Document Store
2.6. Graph Database as Document Store
4.1. Hello World Graph
4.2. Node space view of users
4.3. Matrix node space view
4.4. Descendants Example Graph
4.5. Social network data model
8.1. Traversal Example Graph
15.1. Movie and Actor Graph
16.1. Example Graph
19.1. Final Graph
19.2. Final Graph
19.3. Final Graph
19.4. Final Graph
19.5. Final Graph
19.6. Final Graph
19.7. Final Graph
19.8. Final Graph
19.9. Final Graph
19.10. Starting Graph
19.11. Final Graph
19.12. Starting Graph
19.13. Final Graph
19.14. Final Graph
19.15. Starting Graph
19.16. Final Graph
19.17. Final Graph
19.18. Starting Graph
19.19. Final Graph
19.20. Final Graph
19.21. Final Graph
19.22. Final Graph
19.23. Final Graph
19.24. Final Graph
19.25. Final Graph
19.26. Final Graph
19.27. Final Graph
19.28. Final Graph
19.29. Final Graph
19.30. Final Graph
19.31. Final Graph
19.32. Starting Graph
19.33. Final Graph
19.34. Final Graph
19.35. Starting Graph
19.36. Final Graph
19.37. Final Graph
19.38. Final Graph
19.39. Final Graph
19.40. Final Graph
19.41. Final Graph
19.42. Final Graph
19.43. Final Graph
19.44. Final Graph
19.45. Final Graph
19.46. Final Graph
19.47. Final Graph
19.48. Final Graph
19.49. Final Graph
19.50. Final Graph
19.51. Final Graph
19.52. Final Graph
19.53. Final Graph
19.54. Final Graph
19.55. Final Graph
19.56. Final Graph
19.57. Final Graph
19.58. Final Graph
19.59. Final Graph
19.60. Final Graph
19.61. Final Graph
19.62. Final Graph
19.63. Final Graph
19.64. Final Graph
19.65. Final Graph
19.66. Final Graph
19.67. Final Graph
19.68. Final Graph
19.69. Final Graph
19.70. Final Graph
19.71. Final Graph
19.72. Final Graph
19.73. Final Graph
19.74. Final Graph
19.75. Final Graph
19.76. Final Graph
19.77. Final Graph
19.78. Final Graph
19.79. Final Graph
19.80. Final Graph
19.81. Final Graph
19.82. Final Graph
19.83. Final Graph
19.84. Final Graph
19.85. Final Graph
19.86. Final Graph
19.87. Final Graph
19.88. Final Graph
19.89. Final Graph
19.90. Final Graph
19.91. Final Graph
19.92. Final Graph
19.93. Final Graph
19.94. Final Graph
19.95. Final Graph
19.96. Final Graph
19.97. Starting Graph
19.98. Final Graph
19.99. Starting Graph
19.100. Final Graph
19.101. Final Graph
23.1. Typical setup when running multiple Neo4j instances in HA mode
26.1. Connecting JConsole to the Neo4j Java process
26.2. Neo4j MBeans View
27.1. Web Administration Dashboard
27.2. Entity charting
27.3. Status indicator panels
27.4. Browsing and manipulating data
27.5. Editing properties
27.6. Traverse data with Gremlin
27.7. Query data with Cypher
27.8. Interact over HTTP
27.9. JMX Attributes
28.1. Shell Matrix Example
30.1. Hello World Graph

List of Tables

3.1. Using relationship direction and type
3.2. Property value types
5.1. Result
5.2. Result
5.3. Result
5.4. Result
5.5. Result
5.6. Result
5.7. Result
5.8. Result
5.9. Result
5.10. Result
5.11. Result
5.12. Result
5.13. Result
5.14. Result
5.15. Result
5.16. Result
5.17. Result
5.18. Result
5.19. Result
6.1. Neo4j REST clients contributed by the community.
10.1. Neo4j embedded drivers contributed by the community.
15.1. Lucene indexing configuration parameters
16.1. Result
16.2. Result
16.3. Result
16.4. Result
16.5. Result
16.6. Result
16.7. Result
16.8. Result
16.9. Result
16.10. Result
16.11. Result
16.12. Result
16.13. Result
16.14. Result
16.15. Result
16.16. Result
16.17. Result
16.18. Result
16.19. Result
16.20. Result
16.21. Result
16.22. Result
16.23. Result
16.24. Result
16.25. Result
16.26. Result
16.27. Result
16.28. Result
16.29. Result
16.30. Result
16.31. Result
16.32. Result
16.33. Result
16.34. Result
16.35. Result
16.36. Result
16.37. Result
16.38. Result
16.39. Result
16.40. Result
16.41. Result
16.42. Result
16.43. Result
16.44. Result
16.45. Result
16.46. Result
16.47. Result
16.48. Result
16.49. Result
16.50. Result
16.51. Result
16.52. Result
16.53. Result
16.54. Result
16.55. Result
16.56. Result
16.57. Result
16.58. Result
16.59. Result
16.60. Result
16.61. Result
16.62. Result
16.63. Result
16.64. Result
16.65. Result
16.66. Result
16.67. Result
16.68. Result
16.69. Result
16.70. Result
16.71. Result
16.72. Result
16.73. Result
16.74. Result
16.75. Result
16.76. Result
16.77. Result
16.78. Result
16.79. Result
16.80. Result
16.81. Result
16.82. Result
16.83. Result
16.84. Result
16.85. Result
16.86. Result
16.87. Result
16.88. Result
16.89. Result
16.90. Result
16.91. Result
16.92. Result
16.93. Result
16.94. Result
16.95. Result
16.96. Result
16.97. Result
16.98. Result
16.99. Result
16.100. Result
16.101. Result
16.102. Result
16.103. Result
16.104. Result
16.105. Result
18.1. neo4j-wrapper.conf JVM tuning properties
21.1. Neo4j deployment options
21.2. Neo4j editions
21.3. Upgrade process for Neo4J version
22.1. Guidelines for heap size
23.1. HighlyAvailableGraphDatabase configuration parameters
26.1. MBean Branched Store (org.neo4j.management.BranchedStore) Attributes
26.2. MBean Cache/NodeCache (org.neo4j.management.Cache) Attributes
26.3. MBean Cache/NodeCache (org.neo4j.management.Cache) Operations
26.4. MBean Cache/RelationshipCache (org.neo4j.management.Cache) Attributes
26.5. MBean Cache/RelationshipCache (org.neo4j.management.Cache) Operations
26.6. MBean Configuration (org.neo4j.jmx.impl.ConfigurationBean) Attributes
26.7. MBean Configuration (org.neo4j.jmx.impl.ConfigurationBean) Operations
26.8. MBean Diagnostics (org.neo4j.management.Diagnostics) Attributes
26.9. MBean Diagnostics (org.neo4j.management.Diagnostics) Operations
26.10. MBean High Availability (org.neo4j.management.HighAvailability)
    Attributes
26.11. MBean High Availability (org.neo4j.management.HighAvailability)
    Operations
26.12. MBean Kernel (org.neo4j.jmx.Kernel) Attributes
26.13. MBean Locking (org.neo4j.management.LockManager) Attributes
26.14. MBean Locking (org.neo4j.management.LockManager) Operations
26.15. MBean Memory Mapping (org.neo4j.management.MemoryMapping) Attributes
26.16. MBean Primitive count (org.neo4j.jmx.Primitives) Attributes
26.17. MBean Store file sizes (org.neo4j.management.StoreFile) Attributes
26.18. MBean Transactions (org.neo4j.management.TransactionManager) Attributes
26.19. MBean XA Resources (org.neo4j.management.XaManager) Attributes
30.1. Result


-------------------------------------------------------------------------------

Preface

-------------------------------------------------------------------------------

This is the reference manual for Neo4j version 1.8.M04, written by the Neo4j
Team.

The main parts of the manual are:

  * Part I, “Introduction” — introducing graph database concepts and Neo4j.
  * Part II, “Tutorials” — learn how to use Neo4j.
  * Part III, “Reference” — detailed information on Neo4j.
  * Part IV, “Operations” — how to install and maintain Neo4j.
  * Part V, “Tools” — guides on tools.
  * Part VI, “Community” — getting help from, contributing to.
  * Appendix A, Manpages — command line documentation.
  * Appendix B, Questions & Answers — common questions.

The material is practical, technical, and focused on answering specific
questions. It addresses how things work, what to do and what to avoid to
successfully run Neo4j in a production environment.

The goal is to be thumb-through and rule-of-thumb friendly.

Each section should stand on its own, so you can hop right to whatever
interests you. When possible, the sections distill "rules of thumb" which you
can keep in mind whenever you wander out of the house without this manual in
your back pocket.

The included code examples are executed when Neo4j is built and tested. Also,
the REST API request and response examples are captured from real interaction
with a Neo4j server. Thus, the examples are always in sync with Neo4j.

Who should read this?

The topics should be relevant to architects, administrators, developers and
operations personnel.

Part I. Introduction

This part gives a bird’s eye view of what a graph database is, and then
outlines some specifics of Neo4j.

Table of Contents

1. Neo4j Highlights
2. Graph Database Concepts

    2.1. What is a Graph Database?

        2.1.1. A Graph contains Nodes and Relationships
        2.1.2. Relationships organize the Graph
        2.1.3. Query a Graph with a Traversal
        2.1.4. Indexes look-up Nodes or Relationships
        2.1.5. Neo4j is a Graph Database

    2.2. Comparing Database Models

        2.2.1. A Graph Database transforms a RDBMS
        2.2.2. A Graph Database elaborates a Key-Value Store
        2.2.3. A Graph Database relates Column-Family
        2.2.4. A Graph Database navigates a Document Store

3. The Neo4j Graph Database

    3.1. Nodes
    3.2. Relationships
    3.3. Properties
    3.4. Paths
    3.5. Traversal

Chapter 1. Neo4j Highlights

As a robust, scalable and high-performance database, Neo4j is suitable for full
enterprise deployment or a subset of the full server can be used in lightweight
projects.

It features:

  * true ACID transactions
  * high availability
  * scales to billions of nodes and relationships
  * high speed querying through traversals

Proper ACID behavior is the foundation of data reliability. Neo4j enforces that
all mutating operations occur within a transaction, guaranteeing consistent
data. This robustness extends from single instance embedded graphs to
multi-server high availability installations. For details, see Chapter 13, 
Transaction Management.

Reliable graph storage can easily be added to any application. A property graph
can scale in size and complexity as the application evolves, with little impact
on performance. Whether starting new development, or augmenting existing
functionality, Neo4j is only limited by physical hardware.

A single server instance can handle a graph of billions of nodes and
relationships. When data throughput is insufficient, the graph database can be
distributed among multiple servers in a high availability configuration. See
Chapter 23, High Availability to learn more.

The graph database storage shines when storing richly-connected data. Querying
is performed through traversals, which can perform millions of traversal steps
per second. A traversal step resembles a join in a RDBMS.

Chapter 2. Graph Database Concepts

This chapter contains an introduction to the graph data model and also compares
it to other data models used when persisting data.

2.1. What is a Graph Database?

A graph database stores data in a graph, the most generic of data structures,
capable of elegantly representing any kind of data in a highly accessible way.
Let’s follow along some graphs, using them to express graph concepts. We’ll
“read” a graph by following arrows around the diagram to form sentences.

2.1.1. A Graph contains Nodes and Relationships

    “A Graph —records data in→ Nodes —which have→ Properties”

The simplest possible graph is a single Node, a record that has named values
referred to as Properties. A Node could start with a single Property and grow
to a few million, though that can get a little awkward. At some point it makes
sense to distribute the data into multiple nodes, organized with explicit
Relationships.

graphdb-GVE.svg

2.1.2. Relationships organize the Graph

    “Nodes —are organized by→ Relationships —which also have→ Properties”

Relationships organize Nodes into arbitrary structures, allowing a Graph to
resemble a List, a Tree, a Map, or a compound Entity – any of which can be
combined into yet more complex, richly inter-connected structures.

2.1.3. Query a Graph with a Traversal

    “A Traversal —navigates→ a Graph; it —identifies→ Paths —which order→
    Nodes”

A Traversal is how you query a Graph, navigating from starting Nodes to related
Nodes according to an algorithm, finding answers to questions like “what music
do my friends like that I don’t yet own,” or “if this power supply goes down,
what web services are affected?”

graphdb-traversal.svg

2.1.4. Indexes look-up Nodes or Relationships

    “An Index —maps from→ Properties —to either→ Nodes or Relationships”

Often, you want to find a specific Node or Relationship according to a Property
it has. Rather than traversing the entire graph, use an Index to perform a
look-up, for questions like “find the Account for username master-of-graphs.”

graphdb-indexes.svg

2.1.5. Neo4j is a Graph Database

    “A Graph Database —manages a→ Graph and —also manages related→ Indexes”

Neo4j is a commercially supported open-source graph database. It was designed
and built from the ground-up to be a reliable database, optimized for graph
structures instead of tables. Working with Neo4j, your application gets all the
expressiveness of a graph, with all the dependability you expect out of a
database.

graphdb-overview.svg

2.2. Comparing Database Models

A Graph Database stores data structured in the Nodes and Relationships of a
graph. How does this compare to other persistence models? Because a graph is a
generic structure, let’s compare how a few models would look in a graph.

2.2.1. A Graph Database transforms a RDBMS

Topple the stacks of records in a relational database while keeping all the
relationships, and you’ll see a graph. Where an RDBMS is optimized for
aggregated data, Neo4j is optimized for highly connected data.

Figure 2.1. RDBMS

graphdb-compare-rdbms.svg


Figure 2.2. Graph Database as RDBMS

graphdb-compare-rdbms-g.svg


2.2.2. A Graph Database elaborates a Key-Value Store

A Key-Value model is great for lookups of simple values or lists. When the
values are themselves interconnected, you’ve got a graph. Neo4j lets you
elaborate the simple data structures into more complex, interconnected data.

Figure 2.3. Key-Value Store

graphdb-compare-kvstore.svg


K* represents a key, V* a value. Note that some keys point to other keys as
well as plain values.

Figure 2.4. Graph Database as Key-Value Store

graphdb-compare-kvstore-g.svg


2.2.3. A Graph Database relates Column-Family

Column Family (BigTable-style) databases are an evolution of key-value, using
"families" to allow grouping of rows. Stored in a graph, the families could
become hierarchical, and the relationships among data becomes explicit.

2.2.4. A Graph Database navigates a Document Store

The container hierarchy of a document database accommodates nice, schema-free
data that can easily be represented as a tree. Which is of course a graph.
Refer to other documents (or document elements) within that tree and you have a
more expressive representation of the same data. When in Neo4j, those
relationships are easily navigable.

Figure 2.5. Document Store

graphdb-compare-docdb.svg


D=Document, S=Subdocument, V=Value, D2/S2 = reference to subdocument in (other)
document.

Figure 2.6. Graph Database as Document Store

graphdb-compare-docdb-g.svg


Chapter 3. The Neo4j Graph Database

This chapter goes into more detail on the data model and behavior of Neo4j.

3.1. Nodes

The fundamental units that form a graph are nodes and relationships. In Neo4j,
both nodes and relationships can contain properties.

Nodes are often used to represent entities, but depending on the domain
relationships may be used for that purpose as well.

graphdb-nodes-overview.svg

Let’s start out with a really simple graph, containing only a single node with
one property:

graphdb-nodes.svg

3.2. Relationships

Relationships between nodes are a key part of a graph database. They allow for
finding related data. Just like nodes, relationships can have properties.

graphdb-rels-overview.svg

A relationship connects two nodes, and is guaranteed to have valid start and
end nodes.

graphdb-rels.svg

As relationships are always directed, they can be viewed as outgoing or
incoming relative to a node, which is useful when traversing the graph:

graphdb-rels-dir.svg

Relationships are equally well traversed in either direction. This means that
there is no need to add duplicate relationships in the opposite direction (with
regard to traversal or performance).

While relationships always have a direction, you can ignore the direction where
it is not useful in your application.

Note that a node can have relationships to itself as well:

graphdb-rels-loop.svg

To further enhance graph traversal all relationships have a relationship type.
Note that the word type might be misleading here, you could rather think of it
as a label. The following example shows a simple social network with two
relationship types.

graphdb-rels-twitter.svg

Table 3.1. Using relationship direction and type

+------------------------------------------------------------------------+
|What                          |How                                      |
|------------------------------+-----------------------------------------|
|get who a person follows      |outgoing follows relationships, depth one|
|------------------------------+-----------------------------------------|
|get the followers of a person |incoming follows relationships, depth one|
|------------------------------+-----------------------------------------|
|get who a person blocks       |outgoing blocks relationships, depth one |
|------------------------------+-----------------------------------------|
|get who a person is blocked by|incoming blocks relationships, depth one |
+------------------------------------------------------------------------+


This example is a simple model of a file system, which includes symbolic links:

graphdb-rels-filesys.svg

Depending on what you are looking for, you will use the direction and type of
relationships during traversal.

+-----------------------------------------------------------------------------+
|What                                 |How                                    |
|-------------------------------------+---------------------------------------|
|get the full path of a file          |incoming file relationships            |
|-------------------------------------+---------------------------------------|
|get all paths for a file             |incoming file and symbolic link        |
|                                     |relationships                          |
|-------------------------------------+---------------------------------------|
|get all files in a directory         |outgoing file and symbolic link        |
|                                     |relationships, depth one               |
|-------------------------------------+---------------------------------------|
|get all files in a directory,        |outgoing file relationships, depth one |
|excluding symbolic links             |                                       |
|-------------------------------------+---------------------------------------|
|get all files in a directory,        |outgoing file and symbolic link        |
|recursively                          |relationships                          |
+-----------------------------------------------------------------------------+

3.3. Properties

Both nodes and relationships can have properties.

Properties are key-value pairs where the key is a string. Property values can
be either a primitive or an array of one primitive type. For example String,
int and int[] values are valid for properties.

Note

null is not a valid property value. Nulls can instead be modeled by the absence
of a key.

graphdb-properties.svg

Table 3.2. Property value types

+-----------------------------------------------------------------------------+
|Type   |Description                        |Value range                      |
|-------+-----------------------------------+---------------------------------|
|boolean|                                   |true/false                       |
|-------+-----------------------------------+---------------------------------|
|byte   |8-bit integer                      |-128 to 127, inclusive           |
|-------+-----------------------------------+---------------------------------|
|short  |16-bit integer                     |-32768 to 32767, inclusive       |
|-------+-----------------------------------+---------------------------------|
|int    |32-bit integer                     |-2147483648 to 2147483647,       |
|       |                                   |inclusive                        |
|-------+-----------------------------------+---------------------------------|
|long   |64-bit integer                     |-9223372036854775808 to          |
|       |                                   |9223372036854775807, inclusive   |
|-------+-----------------------------------+---------------------------------|
|float  |32-bit IEEE 754 floating-point     |                                 |
|       |number                             |                                 |
|-------+-----------------------------------+---------------------------------|
|double |64-bit IEEE 754 floating-point     |                                 |
|       |number                             |                                 |
|-------+-----------------------------------+---------------------------------|
|char   |16-bit unsigned integers           |u0000 to uffff (0 to 65535)      |
|       |representing Unicode characters    |                                 |
|-------+-----------------------------------+---------------------------------|
|String |sequence of Unicode characters     |                                 |
+-----------------------------------------------------------------------------+


For further details on float/double values, see Java Language Specification
<http://java.sun.com/docs/books/jls/third_edition/html/typesValues.html#4.2.3>.

3.4. Paths

A path is one or more nodes with connecting relationships, typically retrieved
as a query or traversal result.

graphdb-path.svg

The shortest possible path has length zero and looks like this:

graphdb-path-example1.svg

A path of length one:

graphdb-path-example2.svg

3.5. Traversal

Traversing a graph means visiting its nodes, following relationships according
to some rules. In most cases only a subgraph is visited, as you already know
where in the graph the interesting nodes and relationships are found.

Neo4j comes with a callback based traversal API which lets you specify the
traversal rules. At a basic level there’s a choice between traversing breadth-
or depth-first.

For an in-depth introduction to the traversal framework, see Chapter 8, The
Traversal Framework. For Java code examples see Section 4.5, “Traversal”.

Other options to traverse or query graphs in Neo4j are Cypher and Gremlin.

Part II. Tutorials

The tutorial part describes how to set up your environment, and write programs
using Neo4j. It takes you from Hello World to advanced usage of graphs.

Table of Contents

4. Using Neo4j embedded in Java applications

    4.1. Include Neo4j in your project

        4.1.1. Add Neo4j to the build path
        4.1.2. Add Neo4j as a dependency
        4.1.3. Starting and stopping

    4.2. Hello World

        4.2.1. Prepare the database
        4.2.2. Wrap mutating operations in a transaction
        4.2.3. Create a small graph
        4.2.4. Print the result
        4.2.5. Remove the data
        4.2.6. Shut down the database server

    4.3. User database with index
    4.4. Basic unit testing
    4.5. Traversal

        4.5.1. The Matrix
        4.5.2. Old traversal API
        4.5.3. Uniqueness of Paths in traversals
        4.5.4. Social network

    4.6. Domain entities
    4.7. Graph Algorithm examples
    4.8. Reading a management attribute
    4.9. OSGi setup

        4.9.1. Simple OSGi Activator scenario

    4.10. Execute Cypher Queries from Java

5. Cypher Cookbook

    5.1. Hyperedges and Cypher

        5.1.1. Find Groups
        5.1.2. Find all groups and roles for a user
        5.1.3. Find common groups based on shared roles

    5.2. Basic Friend finding based on social neighborhood

        5.2.1. Simple Friend Finder

    5.3. Co-favorited places

        5.3.1. Co-Favorited Places - Users Who Like x Also Like y
        5.3.2. Co-Tagged Places - Places Related through Tags

    5.4. Find people based on similar favorites

        5.4.1. Find people based on similar favorites

    5.5. Find people based on mutual friends and groups

        5.5.1. Find mutual friends and groups

    5.6. Find friends based on similar tagging

        5.6.1. Find people based on similar tagged favorties

    5.7. Multirelational (social) graphs

        5.7.1. Who FOLLOWS or LOVES me back

    5.8. Pretty graphs in Cypher

        5.8.1. Star graph
        5.8.2. Wheel graph
        5.8.3. Complete graph
        5.8.4. Friendship graph

    5.9. Complex updates

        5.9.1. Insert a new value into a linked list

    5.10. A multilevel indexing structure (path tree)

        5.10.1. Return zero range
        5.10.2. Return the full range
        5.10.3. Return partly shared path ranges

    5.11. More complex similarity computations

        5.11.1. Calculate similarities by complex calculations

6. Neo4j Remote Client Libraries

    6.1. How to use the REST API from Java

        6.1.1. Creating a graph through the REST API from Java
        6.1.2. Start the server
        6.1.3. Creating a node
        6.1.4. Adding properties
        6.1.5. Adding relationships
        6.1.6. Add properties to a relationship
        6.1.7. Querying graphs
        6.1.8. Phew, is that it?
        6.1.9. What’s next?
        6.1.10. Appendix: the code

7. Extending the Neo4j Server

    7.1. Server Plugins
    7.2. Unmanaged Extensions

8. The Traversal Framework

    8.1. Main concepts
    8.2. Traversal Framework Java API

        8.2.1. TraversalDescription
        8.2.2. Evaluator
        8.2.3. Traverser
        8.2.4. Uniqueness
        8.2.5. Order - How to move through branches?
        8.2.6. BranchSelector
        8.2.7. Path
        8.2.8. PathExpander/RelationshipExpander
        8.2.9. Expander
        8.2.10. How to use the Traversal framework

9. Domain Modeling Gallery

    9.1. User roles in graphs

        9.1.1. Get the admins
        9.1.2. Get the group memberships of a user
        9.1.3. Get all groups
        9.1.4. Get all members of all groups

    9.2. ACL structures in graphs

        9.2.1. Generic approach
        9.2.2. Read-permission example

10. Languages
11. Using Neo4j embedded in Python applications

    11.1. Hello, world!
    11.2. A sample app using traversals and indexes

        11.2.1. Domain logic
        11.2.2. Creating data and getting it back

Chapter 4. Using Neo4j embedded in Java applications

It’s easy to use Neo4j embedded in Java applications. In this chapter you will
find everything needed — from setting up the environment to doing something
useful with your data.

4.1. Include Neo4j in your project

After selecting the appropriate edition for your platform, embed Neo4j in your
Java application by including the Neo4j library jars in your build. The
following sections will show how to do this by either altering the build path
directly or by using dependency management.

4.1.1. Add Neo4j to the build path

Get the Neo4j libraries from one of these sources:

  * Extract a Neo4j download <http://neo4j.org/download/> zip/tarball, and use
    the jar files found in the lib/ directory.
  * Use the jar files available from Maven Central Repository <http://
    search.maven.org/#search|ga|1|g%3A%22org.neo4j%22>

Add the jar files to your project:

JDK tools
    Append to -classpath
Eclipse
      * Right-click on the project and then go Build Path → Configure Build
        Path. In the dialog, choose Add External JARs, browse to the Neo4j lib/
        directory and select all of the jar files.
      * Another option is to use User Libraries <http://help.eclipse.org/indigo
        /index.jsp?topic=/org.eclipse.jdt.doc.user/reference/preferences/java/
        buildpath/ref-preferences-user-libraries.htm>.
IntelliJ IDEA
    See Libraries, Global Libraries, and the Configure Library dialog <http://
    www.jetbrains.com/idea/webhelp/
    libraries-global-libraries-and-the-configure-library-dialog.html>
NetBeans
      * Right-click on the Libraries node of the project, choose Add JAR/Folder
        , browse to the Neo4j lib/ directory and select all of the jar files.
      * You can also handle libraries from the project node, see Managing a
        Project’s Classpath <http://netbeans.org/kb/docs/java/
        project-setup.html#projects-classpath>.

4.1.2. Add Neo4j as a dependency

For an overview of the main Neo4j artifacts, see Table 21.2, “Neo4j editions”.
The artifacts listed there are top-level artifacts that will transitively
include the actual Neo4j implementation. You can either go with the top-level
artifact or include the individual components directly. The examples included
here use the top-level artifact approach.

4.1.2.1. Maven

Maven dependency. 

<project>
...
 <dependencies>
  <dependency>
   <groupId>org.neo4j</groupId>
   <artifactId>neo4j</artifactId>
   <version>${neo4j-version}</version>
  </dependency>
  ...
 </dependencies>
...
</project>

Where ${neo4j-version} is the desired version and the artifactId is found in 
Table 21.2, “Neo4j editions”.

4.1.2.2. Eclipse and Maven

For development in Eclipse <http://www.eclipse.org>, it is recommended to
install the M2Eclipse plugin <http://www.eclipse.org/m2e/> and let Maven manage
the project build classpath instead, see above. This also adds the possibility
to build your project both via the command line with Maven and have a working
Eclipse setup for development.

4.1.2.3. Ivy

Make sure to resolve dependencies from Maven Central, for example using this
configuration in your ivysettings.xml file:

<ivysettings>
  <settings defaultResolver="main"/>
  <resolvers>
    <chain name="main">
      <filesystem name="local">
        <artifact pattern="${ivy.settings.dir}/repository/[artifact]-[revision].[ext]" />
      </filesystem>
      <ibiblio name="maven_central" root="http://repo1.maven.org/maven2/" m2compatible="true"/>
    </chain>
  </resolvers>
</ivysettings>

With that in place you can add Neo4j to the mix by having something along these
lines to your ivy.xml file:

..
<dependencies>
  ..
  <dependency org="org.neo4j" name="neo4j" rev="${neo4j-version}"/>
  ..
</dependencies>
..

Where ${neo4j-version} is the desired version and the name is found in 
Table 21.2, “Neo4j editions”.

4.1.2.4. Gradle

The example below shows an example gradle build script for including the Neo4j
libraries.

def neo4jVersion = "[set-version-here]"
apply plugin: 'java'
repositories {
   mavenCentral()
}
dependencies {
   compile "org.neo4j:neo4j:${neo4jVersion}"
}

Where neo4jVersion is the desired version and the name ("neo4j" in the example)
is found in Table 21.2, “Neo4j editions”.

4.1.3. Starting and stopping

To create a new database or ópen an existing one you instantiate an
EmbeddedGraphDatabase <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/
neo4j/kernel/EmbeddedGraphDatabase.html>.

graphDb = new GraphDatabaseFactory().newEmbeddedDatabase( DB_PATH );
registerShutdownHook( graphDb );

Note

The EmbeddedGraphDatabase instance can be shared among multiple threads. Note
however that you can’t create multiple instances pointing to the same database.

To stop the database, call the shutdown() method:

graphDb.shutdown();

To make sure Neo4j is shut down properly you can add a shutdown hook:

private static void registerShutdownHook( final GraphDatabaseService graphDb )
{
    // Registers a shutdown hook for the Neo4j instance so that it
    // shuts down nicely when the VM exits (even if you "Ctrl-C" the
    // running example before it's completed)
    Runtime.getRuntime().addShutdownHook( new Thread()
    {
        @Override
        public void run()
        {
            graphDb.shutdown();
        }
    } );
}

If you want a read-only view of the database, use EmbeddedReadOnlyGraphDatabase
<http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/
EmbeddedReadOnlyGraphDatabase.html>.

To start Neo4j with configuration settings, a Neo4j properties file can be
loaded like this:

GraphDatabaseService graphDb = new GraphDatabaseFactory().
    newEmbeddedDatabaseBuilder( "target/database/location" ).
    loadPropertiesFromFile( pathToConfig + "neo4j.properties" ).
    newGraphDatabase();


Or you could of course create you own Map<String, String> programatically and
use that instead.

For configuration settings, see Chapter 22, Configuration & Performance.

4.2. Hello World

Learn how to create and access nodes and relationships. For information on
project setup, see Section 4.1, “Include Neo4j in your project”.

Remember, from Section 2.1, “What is a Graph Database?”, that a Neo4j graph
consist of:

  * Nodes that are connected by
  * Relationships, with
  * Properties on both nodes and relationships.

All relationships have a type. For example, if the graph represents a social
network, a relationship type could be KNOWS. If a relationship of the type
KNOWS connects two nodes, that probably represents two people that know each
other. A lot of the semantics (that is the meaning) of a graph is encoded in
the relationship types of the application. And although relationships are
directed they are equally well traversed regardless of which direction they are
traversed.

Tip

The source code of this example is found here: EmbeddedNeo4j.java <https://
github.com/neo4j/community/blob/1.8.M04/embedded-examples/src/main/java/org/
neo4j/examples/EmbeddedNeo4j.java>

4.2.1. Prepare the database

Relationship types can be created by using an enum. In this example we only
need a single relationship type. This is how to define it:

private static enum RelTypes implements RelationshipType
{
    KNOWS
}

We also prepare some variables to use:

GraphDatabaseService graphDb;
Node firstNode;
Node secondNode;
Relationship relationship;

The next step is to start the database server. Note that if the directory given
for the database doesn’t already exist, it will be created.

graphDb = new GraphDatabaseFactory().newEmbeddedDatabase( DB_PATH );
registerShutdownHook( graphDb );

Note that starting a database server is an expensive operation, so don’t start
up a new instance every time you need to interact with the database! The
instance can be shared by multiple threads. Transactions are thread confined.

As seen, we register a shutdown hook that will make sure the database shuts
down when the JVM exits. Now it’s time to interact with the database.

4.2.2. Wrap mutating operations in a transaction

All mutating transactions have to be performed in a transaction. This is a
conscious design decision, since we believe transaction demarcation to be an
important part of working with a real enterprise database. Now, transaction
handling in Neo4j is very easy:

Transaction tx = graphDb.beginTx();
try
{
    // Mutating operations go here
    tx.success();
}
finally
{
    tx.finish();
}

For more information on transactions, see Chapter 13, Transaction Management
and Java API for Transaction <http://components.neo4j.org/neo4j/1.8.M04/apidocs
/org/neo4j/graphdb/Transaction.html>.

4.2.3. Create a small graph

Now, let’s create a few nodes. The API is very intuitive. Feel free to have a
look at the JavaDocs at http://components.neo4j.org/neo4j/1.8.M04/apidocs/
<http://components.neo4j.org/neo4j/1.8.M04/apidocs/>. They’re included in the
distribution, as well. Here’s how to create a small graph consisting of two
nodes, connected with one relationship and some properties:

firstNode = graphDb.createNode();
firstNode.setProperty( "message", "Hello, " );
secondNode = graphDb.createNode();
secondNode.setProperty( "message", "World!" );

relationship = firstNode.createRelationshipTo( secondNode, RelTypes.KNOWS );
relationship.setProperty( "message", "brave Neo4j " );

We now have a graph that looks like this:

Figure 4.1. Hello World Graph

Hello-World-Graph-java.svg


4.2.4. Print the result

After we’ve created our graph, let’s read from it and print the result.

System.out.print( firstNode.getProperty( "message" ) );
System.out.print( relationship.getProperty( "message" ) );
System.out.print( secondNode.getProperty( "message" ) );

Which will output:

Hello, brave Neo4j World!

4.2.5. Remove the data

In this case we’ll remove the data before committing:

// let's remove the data
firstNode.getSingleRelationship( RelTypes.KNOWS, Direction.OUTGOING ).delete();
firstNode.delete();
secondNode.delete();

Note that deleting a node which still has relationships when the transaction
commits will fail. This is to make sure relationships always have a start node
and an end node.

4.2.6. Shut down the database server

Finally, shut down the database server when the application finishes:

graphDb.shutdown();

4.3. User database with index

You have a user database, and want to retrieve users by name. To begin with,
this is the structure of the database we want to create:

Figure 4.2. Node space view of users

users.png


That is, the reference node is connected to a users-reference node to which all
users are connected.

Tip

The source code used in this example is found here:
EmbeddedNeo4jWithIndexing.java <https://github.com/neo4j/community/blob/1.8.M04
/embedded-examples/src/main/java/org/neo4j/examples/
EmbeddedNeo4jWithIndexing.java>

To begin with, we define the relationship types we want to use:

private static enum RelTypes implements RelationshipType
{
    USERS_REFERENCE,
    USER
}

Then we have created two helper methods to handle user names and adding users
to the database:

private static String idToUserName( final int id )
{
    return "user" + id + "@neo4j.org";
}

private static Node createAndIndexUser( final String username )
{
    Node node = graphDb.createNode();
    node.setProperty( USERNAME_KEY, username );
    nodeIndex.add( node, USERNAME_KEY, username );
    return node;
}

The next step is to start the database server:

graphDb = new GraphDatabaseFactory().newEmbeddedDatabase( DB_PATH );
nodeIndex = graphDb.index().forNodes( "nodes" );
registerShutdownHook();

It’s time to add the users:

Transaction tx = graphDb.beginTx();
try
{
    // Create users sub reference node
    Node usersReferenceNode = graphDb.createNode();
    graphDb.getReferenceNode().createRelationshipTo(
        usersReferenceNode, RelTypes.USERS_REFERENCE );
    // Create some users and index their names with the IndexService
    for ( int id = 0; id < 100; id++ )
    {
        Node userNode = createAndIndexUser( idToUserName( id ) );
        usersReferenceNode.createRelationshipTo( userNode,
            RelTypes.USER );
    }

And here’s how to find a user by Id:

int idToFind = 45;
Node foundUser = nodeIndex.get( USERNAME_KEY,
    idToUserName( idToFind ) ).getSingle();
System.out.println( "The username of user " + idToFind + " is "
    + foundUser.getProperty( USERNAME_KEY ) );

4.4. Basic unit testing

The basic pattern of unit testing with Neo4j is illustrated by the following
example.

To access the Neo4j testing facilities you should have the neo4j-kernel 
tests.jar on the classpath during tests. You can download it from Maven
Central: org.neo4j:neo4j-kernel <http://search.maven.org/#search|ga|1|
g%3A%22org.neo4j%22%20AND%20a%3A%22neo4j-kernel%22>.

Using Maven as a dependency manager you would typically add this dependency as:

Maven dependency. 

<project>
...
 <dependencies>
  <dependency>
   <groupId>org.neo4j</groupId>
   <artifactId>neo4j-kernel</artifactId>
   <version>${neo4j-version}</version>
   <type>test-jar</type>
   <scope>test</scope>
  </dependency>
  ...
 </dependencies>
...
</project>

Where ${neo4j-version} is the desired version of Neo4j.

With that in place, we’re ready to code our tests.

Tip

For the full source code of this example see: Neo4jBasicTest.java <https://
github.com/neo4j/community/blob/1.8.M04/embedded-examples/src/test/java/org/
neo4j/examples/Neo4jBasicTest.java>

Before each test, create a fresh database:

@Before
public void prepareTestDatabase()
{
    graphDb = new TestGraphDatabaseFactory().newImpermanentDatabaseBuilder().newGraphDatabase();
}

After the test has executed, the database should be shut down:

@After
public void destroyTestDatabase()
{
    graphDb.shutdown();
}

During a test, create nodes and check to see that they are there, while
enclosing write operations in a transaction.

Transaction tx = graphDb.beginTx();

Node n = null;
try
{
    n = graphDb.createNode();
    n.setProperty( "name", "Nancy" );
    tx.success();
}
catch ( Exception e )
{
    tx.failure();
}
finally
{
    tx.finish();
}

// The node should have an id greater than 0, which is the id of the
// reference node.
assertThat( n.getId(), is( greaterThan( 0l ) ) );

// Retrieve a node by using the id of the created node. The id's and
// property should match.
Node foundNode = graphDb.getNodeById( n.getId() );
assertThat( foundNode.getId(), is( n.getId() ) );
assertThat( (String) foundNode.getProperty( "name" ), is( "Nancy" ) );

If you want to set configuration parameters at database creation, it’s done
like this:

Map<String, String> config = new HashMap<String, String>();
config.put( "neostore.nodestore.db.mapped_memory", "10M" );
config.put( "string_block_size", "60" );
config.put( "array_block_size", "300" );
GraphDatabaseService db = new ImpermanentGraphDatabase( config );

4.5. Traversal

For reading about traversals, see Chapter 8, The Traversal Framework.

For more examples of traversals, see Chapter 9, Domain Modeling Gallery.

4.5.1. The Matrix

The traversals from the Matrix example above, this time using the new traversal
API:

Tip

The source code of the examples is found here: NewMatrix.java <https://
github.com/neo4j/community/blob/1.8.M04/embedded-examples/src/main/java/org/
neo4j/examples/NewMatrix.java>

Friends and friends of friends. 

private static Traverser getFriends(
        final Node person )
{
    TraversalDescription td = Traversal.description()
            .breadthFirst()
            .relationships( RelTypes.KNOWS, Direction.OUTGOING )
            .evaluator( Evaluators.excludeStartPosition() );
    return td.traverse( person );
}

Let’s perform the actual traversal and print the results:

int numberOfFriends = 0;
String output = neoNode.getProperty( "name" ) + "'s friends:\n";
Traverser friendsTraverser = getFriends( neoNode );
for ( Path friendPath : friendsTraverser )
{
    output += "At depth " + friendPath.length() + " => "
              + friendPath.endNode()
                      .getProperty( "name" ) + "\n";
    numberOfFriends++;
}
output += "Number of friends found: " + numberOfFriends + "\n";

Which will give us the following output:

Thomas Anderson's friends:
At depth 1 => Trinity
At depth 1 => Morpheus
At depth 2 => Cypher
At depth 3 => Agent Smith
Number of friends found: 4

Who coded the Matrix? 

private static Traverser findHackers( final Node startNode )
{
    TraversalDescription td = Traversal.description()
            .breadthFirst()
            .relationships( RelTypes.CODED_BY, Direction.OUTGOING )
            .relationships( RelTypes.KNOWS, Direction.OUTGOING )
            .evaluator(
                    Evaluators.includeWhereLastRelationshipTypeIs( RelTypes.CODED_BY ) );
    return td.traverse( startNode );
}

Print out the result:

String output = "Hackers:\n";
int numberOfHackers = 0;
Traverser traverser = findHackers( getNeoNode() );
for ( Path hackerPath : traverser )
{
    output += "At depth " + hackerPath.length() + " => "
              + hackerPath.endNode()
                      .getProperty( "name" ) + "\n";
    numberOfHackers++;
}
output += "Number of hackers found: " + numberOfHackers + "\n";

Now we know who coded the Matrix:

Hackers:
At depth 4 => The Architect
Number of hackers found: 1

4.5.1.1. Walking an ordered path

This example shows how to use a path context holding a representation of a
path.

Tip

The source code of this example is found here: OrderedPath.java <https://
github.com/neo4j/community/blob/1.8.M04/embedded-examples/src/main/java/org/
neo4j/examples/orderedpath/OrderedPath.java>

Create a toy graph. 

Node A = db.createNode();
Node B = db.createNode();
Node C = db.createNode();
Node D = db.createNode();
A.createRelationshipTo( B, REL1 );
B.createRelationshipTo( C, REL2 );
C.createRelationshipTo( D, REL3 );
A.createRelationshipTo( C, REL2 );

example-ordered-path.svg

Now, the order of relationships (REL1 → REL2 → REL3) is stored in an ArrayList.
Upon traversal, the Evaluator can check against it to ensure that only paths
are included and returned that have the predefined order of relationships:

Define how to walk the path. 

final ArrayList<RelationshipType> orderedPathContext = new ArrayList<RelationshipType>();
orderedPathContext.add( REL1 );
orderedPathContext.add( withName( "REL2" ) );
orderedPathContext.add( withName( "REL3" ) );
TraversalDescription td = Traversal.description()
        .evaluator( new Evaluator()
        {
            @Override
            public Evaluation evaluate( final Path path )
            {
                if ( path.length() == 0 )
                {
                    return Evaluation.EXCLUDE_AND_CONTINUE;
                }
                RelationshipType expectedType = orderedPathContext.get( path.length() - 1 );
                boolean isExpectedType = path.lastRelationship()
                        .isType( expectedType );
                boolean included = path.length() == orderedPathContext.size()
                                   && isExpectedType;
                boolean continued = path.length() < orderedPathContext.size()
                                    && isExpectedType;
                return Evaluation.of( included, continued );
            }
        } );

Perform the traversal and print the result. 

Traverser traverser = td.traverse( A );
PathPrinter pathPrinter = new PathPrinter( "name" );
for ( Path path : traverser )
{
    output += Traversal.pathToString( path, pathPrinter );
}

Which will output:

(A)--[REL1]-->(B)--[REL2]-->(C)--[REL3]-->(D)

In this case we use a custom class to format the path output. This is how it’s
done:

static class PathPrinter implements Traversal.PathDescriptor<Path>
{
    private final String nodePropertyKey;

    public PathPrinter( String nodePropertyKey )
    {
        this.nodePropertyKey = nodePropertyKey;
    }

    @Override
    public String nodeRepresentation( Path path, Node node )
    {
        return "(" + node.getProperty( nodePropertyKey, "" ) + ")";
    }

    @Override
    public String relationshipRepresentation( Path path, Node from,
            Relationship relationship )
    {
        String prefix = "--", suffix = "--";
        if ( from.equals( relationship.getEndNode() ) )
        {
            prefix = "<--";
        }
        else
        {
            suffix = "-->";
        }
        return prefix + "[" + relationship.getType().name() + "]" + suffix;
    }
}

For options regarding output of a Path, see the Traversal <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/Traversal.html>
class.

Note

The following examples use a deprecated traversal API. It shares the underlying
implementation with the new traversal API, so performance-wise they are equal.
The functionality it provides is very limited in comparison.

4.5.2. Old traversal API

This is the first graph we want to traverse into:

Figure 4.3. Matrix node space view

examples-matrix.png


Tip

The source code of the examples is found here: Matrix.java <https://github.com/
neo4j/community/blob/1.8.M04/embedded-examples/src/main/java/org/neo4j/examples
/Matrix.java>

Friends and friends of friends. 

private static Traverser getFriends( final Node person )
{
    return person.traverse( Order.BREADTH_FIRST,
            StopEvaluator.END_OF_GRAPH,
            ReturnableEvaluator.ALL_BUT_START_NODE, RelTypes.KNOWS,
            Direction.OUTGOING );
}

Let’s perform the actual traversal and print the results:

int numberOfFriends = 0;
String output = neoNode.getProperty( "name" ) + "'s friends:\n";
Traverser friendsTraverser = getFriends( neoNode );
for ( Node friendNode : friendsTraverser )
{
    output += "At depth " +
                friendsTraverser.currentPosition().depth() +
                " => " +
                friendNode.getProperty( "name" ) + "\n";
    numberOfFriends++;
}
output += "Number of friends found: " + numberOfFriends + "\n";

Which will give us the following output:

Thomas Anderson's friends:
At depth 1 => Trinity
At depth 1 => Morpheus
At depth 2 => Cypher
At depth 3 => Agent Smith
Number of friends found: 4

Who coded the Matrix? 

private static Traverser findHackers( final Node startNode )
{
    return startNode.traverse( Order.BREADTH_FIRST,
            StopEvaluator.END_OF_GRAPH, new ReturnableEvaluator()
    {
        @Override
        public boolean isReturnableNode(
                final TraversalPosition currentPos )
        {
            return !currentPos.isStartNode()
            && currentPos.lastRelationshipTraversed()
            .isType( RelTypes.CODED_BY );
        }
    }, RelTypes.CODED_BY, Direction.OUTGOING, RelTypes.KNOWS,
    Direction.OUTGOING );
}

Print out the result:

String output = "Hackers:\n";
int numberOfHackers = 0;
Traverser traverser = findHackers( getNeoNode() );
for ( Node hackerNode : traverser )
{
    output += "At depth " +
                traverser.currentPosition().depth() +
                " => " +
                hackerNode.getProperty( "name" ) + "\n";
    numberOfHackers++;
}
output += "Number of hackers found: " + numberOfHackers + "\n";

Now we know who coded the Matrix:

Hackers:
At depth 4 => The Architect
Number of hackers found: 1

4.5.3. Uniqueness of Paths in traversals

This example is demonstrating the use of node uniqueness. Below an imaginary
domain graph with Principals that own pets that are descendant to other pets.

Figure 4.4. Descendants Example Graph

Descendants-Example-Graph-Uniqueness-of-Paths-in-traversals.svg


In order to return all descendants of Pet0 which have the relation owns to
Principal1 (Pet1 and Pet3), the Uniqueness of the traversal needs to be set to
NODE_PATH rather than the default NODE_GLOBAL so that nodes can be traversed
more that once, and paths that have different nodes but can have some nodes in
common (like the start and end node) can be returned.

final Node target = data.get().get( "Principal1" );
TraversalDescription td = Traversal.description()
        .uniqueness( Uniqueness.NODE_PATH )
        .evaluator( new Evaluator()
{
    @Override
    public Evaluation evaluate( Path path )
    {
        if ( path.endNode().equals( target ) )
        {
            return Evaluation.INCLUDE_AND_PRUNE;
        }
        return Evaluation.EXCLUDE_AND_CONTINUE;
    }
} );

Traverser results = td.traverse( start );

This will return the following paths:

(3)--[descendant,0]-->(1)<--[owns,3]--(5)
(3)--[descendant,2]-->(4)<--[owns,5]--(5)

In the default path.toString() implementation, (1)--[knows,2]-->(4) denotes a
node with ID=1 having a relationship with ID 2 or type knows to a node with
ID-4.

Let’s create a new TraversalDescription from the old one, having NODE_GLOBAL
uniqueness to see the difference.

Tip

The TraversalDescription object is immutable, so we have to use the new
instance returned with the new uniqueness setting.

TraversalDescription nodeGlobalTd = td.uniqueness( Uniqueness.NODE_GLOBAL );
results = nodeGlobalTd.traverse( start );

Now only one path is returned:

(3)--[descendant,0]-->(1)<--[owns,3]--(5)

4.5.4. Social network

Note

The following example uses the new experimental traversal API.

Social networks (know as social graphs out on the web) are natural to model
with a graph. This example shows a very simple social model that connects
friends and keeps track of status updates.

Tip

The source code of the example is found here: socnet <https://github.com/neo4j/
community/tree/1.8.M04/embedded-examples/src/main/java/org/neo4j/examples/
socnet>

4.5.4.1. Simple social model

Figure 4.5. Social network data model

socnet-model.png


The data model for a social network is pretty simple: Persons with names and
StatusUpdates with timestamped text. These entities are then connected by
specific relationships.

  * Person

      o friend: relates two distinct Person instances (no self-reference)
      o status: connects to the most recent StatusUpdate
  * StatusUpdate

      o next: points to the next StatusUpdate in the chain, which was posted
        before the current one

4.5.4.2. Status graph instance

The StatusUpdate list for a Person is a linked list. The head of the list (the
most recent status) is found by following status. Each subsequent StatusUpdate
is connected by next.

Here’s an example where Andreas Kollegger micro-blogged his way to work in the
morning:

andreas-status-updates.svg

To read the status updates, we can create a traversal, like so:

TraversalDescription traversal = Traversal.description().
        depthFirst().
        relationships( NEXT );

This gives us a traverser that will start at one StatusUpdate, and will follow
the chain of updates until they run out. Traversers are lazy loading, so it’s
performant even when dealing with thousands of statuses - they are not loaded
until we actually consume them.

4.5.4.3. Activity stream

Once we have friends, and they have status messages, we might want to read our
friends status' messages, in reverse time order - latest first. To do this, we
go through these steps:

 1. Gather all friend’s status update iterators in a list - latest date first.
 2. Sort the list.
 3. Return the first item in the list.
 4. If the first iterator is exhausted, remove it from the list. Otherwise, get
    the next item in that iterator.
 5. Go to step 2 until there are no iterators left in the list.

Animated, the sequence looks like this <http://www.slideshare.net/systay/
pattern-activity-stream>.

The code looks like:

PositionedIterator<StatusUpdate> first = statuses.get(0);
StatusUpdate returnVal = first.current();

if ( !first.hasNext() )
{
    statuses.remove( 0 );
}
else
{
    first.next();
    sort();
}

return returnVal;

4.6. Domain entities

This page demonstrates one way to handle domain entities when using Neo4j. The
principle at use is to wrap the entities around a node (the same approach can
be used with relationships as well).

Tip

The source code of the examples is found here: Person.java <https://github.com/
neo4j/community/blob/1.8.M04/embedded-examples/src/main/java/org/neo4j/examples
/socnet/Person.java>

First off, store the node and make it accessible inside the package:

private final Node underlyingNode;

Person( Node personNode )
{
    this.underlyingNode = personNode;
}

protected Node getUnderlyingNode()
{
    return underlyingNode;
}


Delegate attributes to the node:

public String getName()
{
    return (String)underlyingNode.getProperty( NAME );
}


Make sure to override these methods:

@Override
public int hashCode()
{
    return underlyingNode.hashCode();
}

@Override
public boolean equals( Object o )
{
    return o instanceof Person &&
            underlyingNode.equals( ( (Person)o ).getUnderlyingNode() );
}

@Override
public String toString()
{
    return "Person[" + getName() + "]";
}


4.7. Graph Algorithm examples

Tip

The source code used in the example is found here: PathFindingExamplesTest.java
<https://github.com/neo4j/community/blob/1.8.M04/embedded-examples/src/test/
java/org/neo4j/examples/PathFindingExamplesTest.java>

Calculating the shortest path (least number of relationships) between two
nodes:

Node startNode = graphDb.createNode();
Node middleNode1 = graphDb.createNode();
Node middleNode2 = graphDb.createNode();
Node middleNode3 = graphDb.createNode();
Node endNode = graphDb.createNode();
createRelationshipsBetween( startNode, middleNode1, endNode );
createRelationshipsBetween( startNode, middleNode2, middleNode3, endNode );

// Will find the shortest path between startNode and endNode via
// "MY_TYPE" relationships (in OUTGOING direction), like f.ex:
//
// (startNode)-->(middleNode1)-->(endNode)
//
PathFinder<Path> finder = GraphAlgoFactory.shortestPath(
        Traversal.expanderForTypes( ExampleTypes.MY_TYPE, Direction.OUTGOING ), 15 );
Iterable<Path> paths = finder.findAllPaths( startNode, endNode );

Using Dijkstra’s algorithm <http://en.wikipedia.org/wiki/
Dijkstra%27s_algorithm> to calculate cheapest path between node A and B where
each relationship can have a weight (i.e. cost) and the path(s) with least cost
are found.

PathFinder<WeightedPath> finder = GraphAlgoFactory.dijkstra(
        Traversal.expanderForTypes( ExampleTypes.MY_TYPE, Direction.BOTH ), "cost" );

WeightedPath path = finder.findSinglePath( nodeA, nodeB );

// Get the weight for the found path
path.weight();

Using A* <http://en.wikipedia.org/wiki/A*_search_algorithm> to calculate the
cheapest path between node A and B, where cheapest is for example the path in a
network of roads which has the shortest length between node A and B. Here’s our
example graph:

A* algorithm example graph

Node nodeA = createNode( "name", "A", "x", 0d, "y", 0d );
Node nodeB = createNode( "name", "B", "x", 7d, "y", 0d );
Node nodeC = createNode( "name", "C", "x", 2d, "y", 1d );
Relationship relAB = createRelationship( nodeA, nodeC, "length", 2d );
Relationship relBC = createRelationship( nodeC, nodeB, "length", 3d );
Relationship relAC = createRelationship( nodeA, nodeB, "length", 10d );

EstimateEvaluator<Double> estimateEvaluator = new EstimateEvaluator<Double>()
{
    public Double getCost( final Node node, final Node goal )
    {
        double dx = (Double) node.getProperty( "x" ) - (Double) goal.getProperty( "x" );
        double dy = (Double) node.getProperty( "y" ) - (Double) goal.getProperty( "y" );
        double result = Math.sqrt( Math.pow( dx, 2 ) + Math.pow( dy, 2 ) );
        return result;
    }
};
PathFinder<WeightedPath> astar = GraphAlgoFactory.aStar(
        Traversal.expanderForAllTypes(),
        CommonEvaluators.doubleCostEvaluator( "length" ), estimateEvaluator );
WeightedPath path = astar.findSinglePath( nodeA, nodeB );

4.8. Reading a management attribute

The EmbeddedGraphDatabase <http://components.neo4j.org/neo4j/1.8.M04/apidocs/
org/neo4j/kernel/EmbeddedGraphDatabase.html> class includes a convenience
method <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/
EmbeddedGraphDatabase.html#getManagementBean%28java.lang.Class%29> to get
instances of Neo4j management beans. The common JMX service can be used as
well, but from your code you probably rather want to use the approach outlined
here.

Tip

The source code of the example is found here: JmxTest.java <https://github.com/
neo4j/community/blob/1.8.M04/embedded-examples/src/test/java/org/neo4j/examples
/JmxTest.java>

This example shows how to get the start time of a database:

private static Date getStartTimeFromManagementBean(
        GraphDatabaseService graphDbService )
{
    GraphDatabaseAPI graphDb = (GraphDatabaseAPI) graphDbService;
    Kernel kernel = graphDb.getSingleManagementBean( Kernel.class );
    Date startTime = kernel.getKernelStartTime();
    return startTime;
}

Depending on which Neo4j edition you are using different sets of management
beans are available.

  * For all editions, see the org.neo4j.jmx <http://components.neo4j.org/
    neo4j-jmx/1.8.M04/apidocs/org/neo4j/jmx/package-summary.html> package.
  * For the Advanced and Enterprise editions, see the org.neo4j.management
    <http://components.neo4j.org/neo4j-management/1.8.M04/apidocs/org/neo4j/
    management/package-summary.html> package as well.

4.9. OSGi setup

In OSGi <http://www.osgi.org/> - related contexts like a number like
Application Servers (e.g. Glassfish <http://glassfish.java.net/> ) and Eclipse
<http://www.eclipse.org> - based systems, Neo4j can be setup up explicitly
instead of discovering services via the Java Service Loader mechanism.

4.9.1. Simple OSGi Activator scenario

As seen in the following example, instead of relying on the Classloading of the
Neo4j kernal, the Neo4j bundles are treated as library bundles, and the
services like the IndexProviders and CacheProviders are explicitly
instantiated, configured and registered. Just make the necessary jars available
as wrapped library bundles , so all needed classes are exported and seen by the
bundle containing the Activator.

public class Neo4jActivator implements BundleActivator
{

    private static GraphDatabaseService db;
    private ServiceRegistration serviceRegistration;
    private ServiceRegistration indexServiceRegistration;

    @Override
    public void start( BundleContext context ) throws Exception
    {
        //the cache providers
        ArrayList<CacheProvider> cacheList = new ArrayList<CacheProvider>();
        cacheList.add( new SoftCacheProvider() );

        //the index providers
        IndexProvider lucene = new LuceneIndexProvider();
        ArrayList<IndexProvider> provs = new ArrayList<IndexProvider>();
        provs.add( lucene );
        ListIndexIterable providers = new ListIndexIterable();
        providers.setIndexProviders( provs );

        //the database setup
        GraphDatabaseFactory gdbf = new GraphDatabaseFactory();
        gdbf.setIndexProviders( providers );
        gdbf.setCacheProviders( cacheList );
        db = gdbf.newEmbeddedDatabase( "target/db" );

        //the OSGi registration
        serviceRegistration = context.registerService(
                GraphDatabaseService.class.getName(), db, new Hashtable<String,String>() );
        System.out.println( "registered " + serviceRegistration.getReference() );
        indexServiceRegistration = context.registerService(
                Index.class.getName(), db.index().forNodes( "nodes" ),
                new Hashtable<String,String>() );
        Transaction tx = db.beginTx();
        try
        {
            Node firstNode = db.createNode();
            Node secondNode = db.createNode();
            Relationship relationship = firstNode.createRelationshipTo(
                    secondNode, DynamicRelationshipType.withName( "KNOWS" ) );

            firstNode.setProperty( "message", "Hello, " );
            secondNode.setProperty( "message", "world!" );
            relationship.setProperty( "message", "brave Neo4j " );
            db.index().forNodes( "nodes" ).add( firstNode, "message", "Hello" );
            tx.success();
        }
        catch ( Exception e )
        {
            e.printStackTrace();
            throw new RuntimeException( e );
        }
        finally
        {
            tx.finish();
        }

    }

    @Override
    public void stop( BundleContext context ) throws Exception
    {
        serviceRegistration.unregister();
        indexServiceRegistration.unregister();
        db.shutdown();

    }

}

Tip

The source code of the example above is found here <https://github.com/neo4j/
community/tree/1.8.M04/embedded-examples/src/test/java/org/neo4j/examples/osgi
/>.

4.10. Execute Cypher Queries from Java

Tip

The full source code of the example: JavaQuery.java <https://github.com/neo4j/
community/blob/1.8.M04/cypher/src/test/java/org/neo4j/cypher/javacompat/
JavaQuery.java>

In Java, you can use the Cypher query language like this:

GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( DB_PATH );
// add some data first
Transaction tx = db.beginTx();
try
{
    Node refNode = db.getReferenceNode();
    refNode.setProperty( "name", "reference node" );
    tx.success();
}
finally
{
    tx.finish();
}

// let's execute a query now
ExecutionEngine engine = new ExecutionEngine( db );
ExecutionResult result = engine.execute( "start n=node(0) return n, n.name" );
System.out.println( result );

Which will output:

+---------------------------------------------------+
| n                              | n.name           |
+---------------------------------------------------+
| Node[0]{name:"reference node"} | "reference node" |
+---------------------------------------------------+
1 row
0 ms

Caution

The classes used here are from the org.neo4j.cypher.javacompat package, not
org.neo4j.cypher, see link to the Java API below.

You can get a list of the columns in the result:

List<String> columns = result.columns();
System.out.println( columns );

This outputs:

[n, n.name]

To fetch the result items in a single column, do like this:

Iterator<Node> n_column = result.columnAs( "n" );
for ( Node node : IteratorUtil.asIterable( n_column ) )
{
    // note: we're grabbing the name property from the node,
    // not from the n.name in this case.
    nodeResult = node + ": " + node.getProperty( "name" );
    System.out.println( nodeResult );
}

In this case there’s only one node in the result:

Node[0]: reference node

To get all columns, do like this instead:

for ( Map<String, Object> row : result )
{
    for ( Entry<String, Object> column : row.entrySet() )
    {
        rows += column.getKey() + ": " + column.getValue() + "; ";
    }
    rows += "\n";
}
System.out.println( rows );

This outputs:

n.name: reference node; n: Node[0];

For more information on the Java interface to Cypher, see the Java API <http://
components.neo4j.org/neo4j-cypher/1.8.M04/apidocs/index.html>.

For more information and examples for Cypher, see Chapter 16, Cypher Query
Language and Chapter 5, Cypher Cookbook.

Chapter 5. Cypher Cookbook

The following cookbook aims to provide a few snippets, examples and use-cases
and their query-solutions in Cypher. For the Cypher reference documentation,
see Chapter 16, Cypher Query Language.

5.1. Hyperedges and Cypher

Imagine a user being part of different groups. A group can have different
roles, and a user can be part of different groups. He also can have different
roles in different groups apart from the membership. The association of a User,
a Group and a Role can be referred to as a HyperEdge. However, it can be easily
modeled in a property graph as a node that captures this n-ary relationship, as
depicted below in the U1G2R1 node.

Graph

cypher-hyperedge-graph.svg

5.1.1. Find Groups

To find out in what roles a user is for a particular groups (here Group2), the
following Cypher Query can traverse this HyperEdge node and provide answers.

Query

START n=node:node_auto_index(name = "User1")
MATCH n-[:hasRoleInGroup]->hyperEdge-[:hasGroup]->group, hyperEdge-[:hasRole]->role
WHERE group.name = "Group2"
RETURN role.name

The role of User1:

Table 5.1. Result

+---------+
|role.name|
|---------|
|1 row    |
|---------|
|0 ms     |
|---------|
|"Role1"  |
+---------+


5.1.2. Find all groups and roles for a user

Here, find all groups and the roles a user has, sorted by the roles names.

Query

START n=node:node_auto_index(name = "User1")
MATCH n-[:hasRoleInGroup]->hyperEdge-[:hasGroup]->group, hyperEdge-[:hasRole]->role
RETURN role.name, group.name
ORDER BY role.name asc

The groups and roles of User1

Table 5.2. Result

+---------------------+
|role.name|group.name |
|---------------------|
|2 rows               |
|---------------------|
|0 ms                 |
|---------------------|
|"Role1"  |"Group2"   |
|---------+-----------|
|"Role2"  |"Group1"   |
+---------------------+


5.1.3. Find common groups based on shared roles

Assume you have a more complicated graph:

 1. 2 user nodes User1, User2
 2. User1 is in Group1, Group2, Group3.
 3. User1 has Role1, Role2 in Group1; Role2, Role3 in Group2; Role3, Role4 in
    Group3 (hyper edges)
 4. User2 is in Group1, Group2, Group3
 5. User2 has Role2, Role5 in Group1; Role3, Role4 in Group2; Role5, Role6 in
    Group3 (hyper edges)

The graph for this looks like the following (nodes like U1G2R23 representing
the HyperEdges):

Graph

cypher-hyperedgecommongroups-graph.svg

To return Group1 and Group2 as User1 and User2 share at least one common role
in those 2 groups, the cypher query looks like:

Query

START u1=node:node_auto_index(name = "User1"),u2=node:node_auto_index(name = "User2")
MATCH u1-[:hasRoleInGroup]->hyperEdge1-[:hasGroup]->group,
      hyperEdge1-[:hasRole]->role,
      u2-[:hasRoleInGroup]->hyperEdge2-[:hasGroup]->group,
      hyperEdge2-[:hasRole]->role
RETURN group.name, count(role)
ORDER BY group.name asc

The groups where User1 and User2 share at least one common role:

Table 5.3. Result

+-----------------------+
|group.name|count(role) |
|-----------------------|
|2 rows                 |
|-----------------------|
|0 ms                   |
|-----------------------|
|"Group1"  |1           |
|----------+------------|
|"Group2"  |1           |
+-----------------------+


5.2. Basic Friend finding based on social neighborhood

Imagine an example graph like

Graph

cypher-collabfiltering-graph.svg

5.2.1. Simple Friend Finder

To find out the friends of Joes friends that are not already his friends,
Cypher looks like:

Query

START joe=node:node_auto_index(name = "Joe")
MATCH joe-[:knows]->friend-[:knows]->friend_of_friend, joe-[r?:knows]->friend_of_friend
WHERE r IS NULL
RETURN friend_of_friend.name, COUNT(*)
ORDER BY COUNT(*) DESC, friend_of_friend.name

The list of Friends-of-friends order by the number of connections to them,
secondly by their name.

Table 5.4. Result

+-------------------------------+
|friend_of_friend.name |COUNT(*)|
|-------------------------------|
|3 rows                         |
|-------------------------------|
|0 ms                           |
|-------------------------------|
|"Ian"                 |2       |
|----------------------+--------|
|"Derrick"             |1       |
|----------------------+--------|
|"Jill"                |1       |
+-------------------------------+


5.3. Co-favorited places

Graph

cypher-cofavoritedplaces-graph.svg

5.3.1. Co-Favorited Places - Users Who Like x Also Like y

Find places that people also like who favorite this place:

  * Determine who has favorited place x.
  * What else have they favorited that is not place x.

Query

START place=node:node_auto_index(name = "CoffeeShop1")
MATCH place<-[:favorite]-person-[:favorite]->stuff
RETURN stuff.name, count(*)
ORDER BY count(*) DESC, stuff.name

The list of places that are favorited by people that favorited the start place.

Table 5.5. Result

+----------------------+
|stuff.name   |count(*)|
|----------------------|
|3 rows                |
|----------------------|
|0 ms                  |
|----------------------|
|"MelsPlace"  |2       |
|-------------+--------|
|"CoffeShop2" |1       |
|-------------+--------|
|"SaunaX"     |1       |
+----------------------+


5.3.2. Co-Tagged Places - Places Related through Tags

Find places that are tagged with the same tags:

  * Determine the tags for place x.
  * What else is tagged the same as x that is not x.

Query

START place=node:node_auto_index(name = "CoffeeShop1")
MATCH place-[:tagged]->tag<-[:tagged]-otherPlace

RETURN otherPlace.name, collect(tag.name)
ORDER By otherPlace.name desc

The list of possible friends ranked by them liking similar stuff that are not
yet friends.

Table 5.6. Result

+---------------------------------+
|otherPlace.name|collect(tag.name)|
|---------------------------------|
|3 rows                           |
|---------------------------------|
|0 ms                             |
|---------------------------------|
|"MelsPlace"    |["Cool","Cosy"]  |
|---------------+-----------------|
|"CoffeeShop3"  |["Cosy"]         |
|---------------+-----------------|
|"CoffeeShop2"  |["Cool"]         |
+---------------------------------+


5.4. Find people based on similar favorites

Graph

cypher-peoplesimilarityfavorites-graph.svg

5.4.1. Find people based on similar favorites

To find out the possible new friends based on them liking similar things as the
asking person:

Query

START me=node:node_auto_index(name = "Joe")
MATCH me-[:favorite]->stuff<-[:favorite]-person
WHERE NOT(me-[:friend]-person)
RETURN person.name, count(stuff)
ORDER BY count(stuff) DESC

The list of possible friends ranked by them liking similar stuff that are not
yet friends.

Table 5.7. Result

+-------------------------+
|person.name|count(stuff) |
|-------------------------|
|2 rows                   |
|-------------------------|
|0 ms                     |
|-------------------------|
|"Derrick"  |2            |
|-----------+-------------|
|"Jill"     |1            |
+-------------------------+


5.5. Find people based on mutual friends and groups

Graph

cypher-mutualfriendsandgroups-graph.svg

5.5.1. Find mutual friends and groups

In this scenario, the problem is to determine mutual friends and groups, if
any, between persons. If no mutual groups or friends are found, there should be
a 0 returned.

Query

START me=node(5), other=node(4, 3)
MATCH pGroups=me-[?:member_of_group]->mg<-[?:member_of_group]-other, pMutualFriends=me-[?:knows]->mf<-[?:knows]-other
RETURN other.name as name,
      count(distinct pGroups) AS mutualGroups,
      count(distinct pMutualFriends) AS mutualFriends ORDER By mutualFriends DESC

The question we are asking is — how many unique paths are there between me and
Jill, the paths being common group memberships, and common friends. If the
paths are mandatory, no results will be returned if me and Bob lack any common
friends, and we don’t want that. To make a path optional, you have to make at
least one of it’s relationships optional. That makes the whole path optional.

Table 5.8. Result

+---------------------------------+
|name  |mutualGroups|mutualFriends|
|---------------------------------|
|2 rows                           |
|---------------------------------|
|0 ms                             |
|---------------------------------|
|"Jill"|1           |1            |
|------+------------+-------------|
|"Bob" |1           |0            |
+---------------------------------+


5.6. Find friends based on similar tagging

Graph

cypher-peoplesimilaritytags-graph.svg

5.6.1. Find people based on similar tagged favorties

To find out people similar to me based on taggings of their favorited items, an
approach could be: * Determine the tags associated with what I favorite. * What
else is tagged with those tags? * Who favorites items tagged with the same
tags. * Sort the result by how many of the same things these people like.

Query

START me=node(9)
MATCH me-[:favorite]->myFavorites-[:tagged]->tag<-[:tagged]-theirFavorites<-[:favorite]-people
WHERE NOT(me=people)
RETURN people.name as name, count(*) as similar_favs
ORDER BY similar_favs DESC

The list of possible friends ranked by them liking similar stuff that are not
yet friends.

Table 5.9. Result

+-----------------------+
|name     |similar_favs |
|-----------------------|
|2 rows                 |
|-----------------------|
|0 ms                   |
|-----------------------|
|"Sara"   |2            |
|---------+-------------|
|"Derrick"|1            |
+-----------------------+


5.7. Multirelational (social) graphs

Graph

cypher-multirelationalsocialnetwork-graph.svg

5.7.1. Who FOLLOWS or LOVES me back

This example shows a multi-relational network between persons and things they
like. A multi-relational graph is a graph with more than one kind of
relationship between nodes.

Query

START me=node:node_auto_index(name = 'Joe')
MATCH me-[r1]->other-[r2]->me
WHERE type(r1)=type(r2) AND type(r1) =~ /FOLLOWS|LOVES/
RETURN other.name, type(r1)

People that FOLLOWS or LOVES Joe back.

Table 5.10. Result

+---------------------+
|other.name |type(r1) |
|---------------------|
|3 rows               |
|---------------------|
|0 ms                 |
|---------------------|
|"Sara"     |"FOLLOWS"|
|-----------+---------|
|"Maria"    |"FOLLOWS"|
|-----------+---------|
|"Maria"    |"LOVES"  |
+---------------------+


5.8. Pretty graphs in Cypher

This section is showing how to create some of the named pretty graphs on
Wikipedia <http://en.wikipedia.org/wiki/Gallery_of_named_graphs>.

The graph visualizations look best using a Force Directed Layout, while the
current layout below is different. For better results, use the live demos in
the online version of this manual <http://docs.neo4j.org>.

5.8.1. Star graph

Works by first creating a center node, and then once per element in the range,
creates a leaf node and connects it to the center

Query

CREATE center
foreach( x in range(1,10) :

CREATE leaf, center-[:X]->leaf
)
RETURN id(center) as id;

The center node.

Table 5.11. Result

+-------------------------+
|id                       |
|-------------------------|
|1 row                    |
|-------------------------|
|Nodes created: 11        |
|-------------------------|
|Relationships created: 10|
|-------------------------|
|3 ms                     |
|-------------------------|
|1                        |
+-------------------------+


Graph

cypher-prettygraphsstar-graph.svg

5.8.2. Wheel graph

This graph is created in a number of steps:

  * create a center node
  * once per element in the range, create a leaf and connect it to the center.
  * select 2 leafs from the center node and conenct them.
  * find the minimum and maximum leaf and connect these.
  * return the center node.

Query

CREATE center
foreach( x in range(1,10) :

CREATE leaf={count:x}, center-[:X]->leaf
)
==== center ====
MATCH large_leaf<--center-->small_leaf
WHERE large_leaf.count = small_leaf.count + 1
CREATE small_leaf-[:X]->large_leaf

==== center, min(small_leaf.count) as min, max(large_leaf.count) as max ====
MATCH first_leaf<--center-->last_leaf
WHERE first_leaf.count = min AND last_leaf.count = max
CREATE last_leaf-[:X]->first_leaf

RETURN id(center) as id

The center node.

Table 5.12. Result

+-------------------------+
|id                       |
|-------------------------|
|1 row                    |
|-------------------------|
|Nodes created: 11        |
|-------------------------|
|Relationships created: 20|
|-------------------------|
|Properties set: 10       |
|-------------------------|
|16 ms                    |
|-------------------------|
|1                        |
+-------------------------+


Graph

cypher-prettygraphswheel-graph.svg

5.8.3. Complete graph

For this graph, a root node is created, and used to hang a number of nodes
from. Then, two nodes are selected, hanging from the center, with the
requirement that the id of the first be less than the id of the next. This is
to prevent double relationships and self relationships. Using said match,
relationships between all these nodes are created. Lastly, the center node and
all relationships connected to it are removed.

Query

CREATE center
foreach( x in range(1,10) :

CREATE leaf={count : x}, center-[:X]->leaf
)
==== center ====
MATCH leaf1<--center-->leaf2
WHERE id(leaf1)<id(leaf2)
CREATE leaf1-[:X]->leaf2
==== center ====
MATCH center-[r]->()
DELETE center,r;

Nothing returned.

Table 5.13. Result

+-------------------------+
|Nodes created: 11        |
|-------------------------|
|Relationships created: 55|
|-------------------------|
|Properties set: 10       |
|-------------------------|
|Nodes deleted: 1         |
|-------------------------|
|Relationships deleted: 10|
|-------------------------|
|54 ms                    |
|-------------------------|
|(empty result)           |
+-------------------------+


Graph

cypher-prettygraphscompletegraph-graph.svg

5.8.4. Friendship graph

Works by first creating a center node, and then once per element in the range,
creates a cycle graph and connects it to the center

Query

CREATE center
foreach( x in range(1,10) :

CREATE leaf1, leaf2, center-[:X]->leaf1, center-[:X]->leaf2, leaf1-[:X]->leaf2
)
RETURN ID(center) as id

The id of the center node.

Table 5.14. Result

+-------------------------+
|id                       |
|-------------------------|
|1 row                    |
|-------------------------|
|Nodes created: 21        |
|-------------------------|
|Relationships created: 30|
|-------------------------|
|6 ms                     |
|-------------------------|
|1                        |
+-------------------------+


Graph

cypher-prettygraphsfriendshipgraph-graph.svg

5.9. Complex updates

This section is showing some graph-related update operations that require
advanced graph manipulations.

5.9.1. Insert a new value into a linked list

In this example, a new value is inserted at the right position into an existing
Linked List.

Firstly, a new linked list, containing the nodes with values 0 and 2 is created
in the first subquery.

In the second part, we are looking for the node in the position before our new
node will have, and the node that will come after. They will already be
connected with each other with the relationship identifier old. The 0 in zero-
[:LINK*0..]->before means that there are zero or more relationships between the
root node and the before node. Having zero relationships between two node in a
path means that they are the same node. When the linked list is empty, the
root, before and after identifier will all point to the same node - the newly
created root node. The self relationship will be in the old identifier.

In the last query part, the old relationship is deleted.

Query

CREATE zero={name:0,value:0}, two={value:2,name:2}, zero-[:LINK]->two-[:LINK]->zero
==== zero ====
MATCH zero-[:LINK*0..]->before,
after-[:LINK*0..]->zero,
before-[old:LINK]->after
WHERE before.value? <= 1 AND
1 <= after.value?
CREATE newValue={name:1,value : 1},
before-[:LINK]->newValue,
newValue-[:LINK]->after
DELETE old
==== zero ====
MATCH p = zero-[:LINK*1..]->zero
RETURN length(p) as list_length

The length of the full list.

Table 5.15. Result

+------------------------+
|list_length             |
|------------------------|
|1 row                   |
|------------------------|
|Nodes created: 3        |
|------------------------|
|Relationships created: 4|
|------------------------|
|Properties set: 6       |
|------------------------|
|Relationships deleted: 1|
|------------------------|
|9 ms                    |
|------------------------|
|3                       |
+------------------------+


Graph

cypher-linkedlist-graph.svg

5.10. A multilevel indexing structure (path tree)

In this example, a multi-level tree structure is used to index event nodes
(here Event1, Event2 and Event3, in this case with a YEAR-MONTH-DAY
granularity, making this a timeline indexing structure. However, this approach
should work for a wide range of multi-level ranges.

The structure follows a couple of rules:

  * Events can be indexed multiple times by connecting the indexing structure
    leafs with the events via a VALUE relationship.
  * The querying is done in a path-range fashion. That is, the start- and end
    path from the indexing root to the start and end leafs in the tree are
    calculated
  * Using Cypher, the queries following different strategies can be expressed
    as path sections and put together using one single query.

The graph below depicts a structure with 3 Events being attached to an index
structure at different leafs.

Graph

cypher-pathtree-layout-path.svg

5.10.1. Return zero range

Here, only the events indexed under one leaf (2010-12-31) are returned. The
query only needs one path segment rootPath (color Green) through the index.

Graph

cypher-pathtree-layout-zero-range.svg

Query

START root=node:node_auto_index(name = 'Root')
MATCH rootPath=root-[:`2010`]->()-[:`12`]->()-[:`31`]->leaf, leaf-[:VALUE]->event
RETURN event.name
ORDER BY event.name ASC

Returning all events on the date 2010-12-31, in this case Event1 and Event2

Table 5.16. Result

+----------+
|event.name|
|----------|
|2 rows    |
|----------|
|0 ms      |
|----------|
|"Event1"  |
|----------|
|"Event2"  |
+----------+


5.10.2. Return the full range

In this case, the range goes from the first to the last leaf of the index tree.
Here, startPath (color Greenyellow) and endPath (color Green) span up the
range, valuePath (color Blue) is then connecting the leafs, and the values can
be read from the middle node, hanging off the values (color Red) path.

Graph

cypher-pathtree-layout-full-range-path.svg

Query

START root=node:node_auto_index(name = 'Root')
MATCH startPath=root-[:`2010`]->()-[:`12`]->()-[:`31`]->startLeaf,
      endPath=root-[`:2011`]->()-[:`01`]->()-[:`03`]->endLeaf,
      valuePath=startLeaf-[:NEXT*0..]->middle-[:NEXT*0..]->endLeaf,
      values=middle-[:VALUE]->event
RETURN event.name
ORDER BY event.name ASC

Returning all events between 2010-12-31 and 2011-01-03, in this case all
events.

Table 5.17. Result

+----------+
|event.name|
|----------|
|4 rows    |
|----------|
|0 ms      |
|----------|
|"Event1"  |
|----------|
|"Event2"  |
|----------|
|"Event2"  |
|----------|
|"Event3"  |
+----------+


5.10.3. Return partly shared path ranges

Here, the query range results in partly shared paths when querying the index,
making the introduction of and common path segment commonPath (color Black)
necessary, before spanning up startPath (color Greenyellow) and endPath (color
Darkgreen) . After that, valuePath (color Blue) connects the leafs and the
indexed values are returned off values (color Red) path.

Graph

cypher-pathtree-layout-shared-root-path.svg

Query

START root=node:node_auto_index(name = 'Root')
MATCH commonPath=root-[:`2011`]->()-[:`01`]->commonRootEnd,
      startPath=commonRootEnd-[:`01`]->startLeaf,
      endPath=commonRootEnd-[:`03`]->endLeaf,
      valuePath=startLeaf-[:NEXT*0..]->middle-[:NEXT*0..]->endLeaf,
      values=middle-[:VALUE]->event
RETURN event.name
ORDER BY event.name ASC

Returning all events between 2011-01-01 and 2011-01-03, in this case Event2 and
Event3.

Table 5.18. Result

+----------+
|event.name|
|----------|
|2 rows    |
|----------|
|0 ms      |
|----------|
|"Event2"  |
|----------|
|"Event3"  |
+----------+


5.11. More complex similarity computations

5.11.1. Calculate similarities by complex calculations

Here, a similarity between two players in a game is calculated by the number of
times they have eaten the same food.

Query

START me=node(*)
MATCH me-[r1:ATE]->food<-[r2:ATE]-you
WHERE has(me.name) and me.name = 'me'
==== me,count(distinct r1) as H1,count(distinct r2) as H2,you ====
MATCH me-[r1:ATE]->food<-[r2:ATE]-you
RETURN sum((1-ABS(r1.times/H1-r2.times/H2))*(r1.times+r2.times)/(H1+H2)) as similarity

The two players and their similarity measure.

Table 5.19. Result

+----------+
|similarity|
|----------|
|1 row     |
|----------|
|0 ms      |
|----------|
|-30.0     |
+----------+


Graph

cypher-complexsimilarity-graph.svg

Chapter 6. Neo4j Remote Client Libraries

The included Java example shows a “low-level” approach to using the Neo4j REST
API from Java. For other options, see below.

Table 6.1. Neo4j REST clients contributed by the community.

+-----------------------------------------------------------------------------+
|name             |language / |URL                                            |
|                 |framework  |                                               |
|-----------------+-----------+-----------------------------------------------|
|Java-Rest-Binding|Java       |https://github.com/neo4j/java-rest-binding/    |
|                 |           |<https://github.com/neo4j/java-rest-binding/>  |
|-----------------+-----------+-----------------------------------------------|
|Neo4jClient      |.NET       |http://hg.readify.net/neo4jclient/ <http://    |
|                 |           |hg.readify.net/neo4jclient/>                   |
|-----------------+-----------+-----------------------------------------------|
|Neo4jRestNet     |.NET       |https://github.com/SepiaGroup/Neo4jRestNet     |
|                 |           |<https://github.com/SepiaGroup/Neo4jRestNet>   |
|-----------------+-----------+-----------------------------------------------|
|py2neo           |Python     |http://py2neo.org/ <http://py2neo.org/>        |
|-----------------+-----------+-----------------------------------------------|
|Bulbflow         |Python     |http://bulbflow.com/ <http://bulbflow.com/>    |
|-----------------+-----------+-----------------------------------------------|
|neo4jrestclient  |Python     |https://github.com/versae/neo4j-rest-client    |
|                 |           |<https://github.com/versae/neo4j-rest-client>  |
|-----------------+-----------+-----------------------------------------------|
|neo4django       |Django     |https://github.com/scholrly/neo4django <https:/|
|                 |           |/github.com/scholrly/neo4django>               |
|-----------------+-----------+-----------------------------------------------|
|Neo4jPHP         |PHP        |https://github.com/jadell/Neo4jPHP <https://   |
|                 |           |github.com/jadell/Neo4jPHP>                    |
|-----------------+-----------+-----------------------------------------------|
|neography        |Ruby       |https://github.com/maxdemarzi/neography <https:|
|                 |           |//github.com/maxdemarzi/neography>             |
|-----------------+-----------+-----------------------------------------------|
|neoid            |Ruby       |https://github.com/elado/neoid <https://       |
|                 |           |github.com/elado/neoid>                        |
|-----------------+-----------+-----------------------------------------------|
|node.js          |JavaScript |https://github.com/thingdom/node-neo4j <https:/|
|                 |           |/github.com/thingdom/node-neo4j>               |
|-----------------+-----------+-----------------------------------------------|
|Neocons          |Clojure    |https://github.com/michaelklishin/neocons      |
|                 |           |<https://github.com/michaelklishin/neocons>    |
+-----------------------------------------------------------------------------+


6.1. How to use the REST API from Java

6.1.1. Creating a graph through the REST API from Java

The REST API uses HTTP and JSON, so that it can be used from many languages and
platforms. Still, when geting started it’s useful to see some patterns that can
be re-used. In this brief overview, we’ll show you how to create and manipulate
a simple graph through the REST API and also how to query it.

For these examples, we’ve chosen the Jersey <http://jersey.java.net/> client
components, which are easily downloaded <http://jersey.java.net/nonav/
documentation/latest/user-guide.html#chapter_deps> via Maven.

6.1.2. Start the server

Before we can perform any actions on the server, we need to start it as per
Section 18.1, “Server Installation”.

WebResource resource = Client.create()
        .resource( SERVER_ROOT_URI );
ClientResponse response = resource.get( ClientResponse.class );

System.out.println( String.format( "GET on [%s], status code [%d]",
        SERVER_ROOT_URI, response.getStatus() ) );
response.close();

If the status of the response is 200 OK, then we know the server is running
fine and we can continue. If the code fails to conenct to the server, then
please have a look at Chapter 18, Neo4j Server.

Note

If you get any other response than 200 OK (particularly 4xx or 5xx responses)
then please check your configuration and look in the log files in the data/log
directory.

6.1.3. Creating a node

The REST API uses POST to create nodes. Encapsulating that in Java is
straightforward using the Jersey client:

final String nodeEntryPointUri = SERVER_ROOT_URI + "node";
// http://localhost:7474/db/data/node

WebResource resource = Client.create()
        .resource( nodeEntryPointUri );
// POST {} to the node entry point URI
ClientResponse response = resource.accept( MediaType.APPLICATION_JSON )
        .type( MediaType.APPLICATION_JSON )
        .entity( "{}" )
        .post( ClientResponse.class );

final URI location = response.getLocation();
System.out.println( String.format(
        "POST to [%s], status code [%d], location header [%s]",
        nodeEntryPointUri, response.getStatus(), location.toString() ) );
response.close();

return location;

If the call completes successfully, under the covers it will have sent a HTTP
request containing a JSON payload to the server. The server will then have
created a new node in the database and responded with a 201 Created response
and a Location header with the URI of the newly created node.

In our example, we call this functionality twice to create two nodes in our
database.

6.1.4. Adding properties

Once we have nodes in our datatabase, we can use them to store useful data. In
this case, we’re going to store information about music in our database. Let’s
start by looking at the code that we use to create nodes and add properties.
Here we’ve added nodes to represent "Joe Strummer" and a band called "The
Clash".

URI firstNode = createNode();
addProperty( firstNode, "name", "Joe Strummer" );
URI secondNode = createNode();
addProperty( secondNode, "band", "The Clash" );

Inside the addProperty method we determine the resource that represents
properties for the node and decide on a name for that property. We then proceed
to PUT the value of that property to the server.

String propertyUri = nodeUri.toString() + "/properties/" + propertyName;
// http://localhost:7474/db/data/node/{node_id}/properties/{property_name}

WebResource resource = Client.create()
        .resource( propertyUri );
ClientResponse response = resource.accept( MediaType.APPLICATION_JSON )
        .type( MediaType.APPLICATION_JSON )
        .entity( "\"" + propertyValue + "\"" )
        .put( ClientResponse.class );

System.out.println( String.format( "PUT to [%s], status code [%d]",
        propertyUri, response.getStatus() ) );
response.close();

If everything goes well, we’ll get a 204 No Content back indicating that the
server processed the request but didn’t echo back the property value.

6.1.5. Adding relationships

Now that we have nodes to represent Joe Strummer and The Clash, we can relate
them. The REST API supports this through a POST of a relationship
representation to the start node of the relationship. Correspondingly in Java
we POST some JSON to the URI of our node that represents Joe Strummer, to
establish a relationship between that node and the node representing The Clash.

URI relationshipUri = addRelationship( firstNode, secondNode, "singer",
        "{ \"from\" : \"1976\", \"until\" : \"1986\" }" );

Inside the addRelationship method, we determine the URI of the Joe Strummer
node’s relationships, and then POST a JSON description of our intended
relationship. This description contains the destination node, a label for the
relationship type, and any attributes for the relation as a JSON collection.

private static URI addRelationship( URI startNode, URI endNode,
        String relationshipType, String jsonAttributes )
        throws URISyntaxException
{
    URI fromUri = new URI( startNode.toString() + "/relationships" );
    String relationshipJson = generateJsonRelationship( endNode,
            relationshipType, jsonAttributes );

    WebResource resource = Client.create()
            .resource( fromUri );
    // POST JSON to the relationships URI
    ClientResponse response = resource.accept( MediaType.APPLICATION_JSON )
            .type( MediaType.APPLICATION_JSON )
            .entity( relationshipJson )
            .post( ClientResponse.class );

    final URI location = response.getLocation();
    System.out.println( String.format(
            "POST to [%s], status code [%d], location header [%s]",
            fromUri, response.getStatus(), location.toString() ) );

    response.close();
    return location;
}

If all goes well, we receive a 201 Created status code and a Location header
which contains a URI of the newly created relation.

6.1.6. Add properties to a relationship

Like nodes, relationships can have properties. Since we’re big fans of both Joe
Strummer and the Clash, we’ll add a rating to the relationship so that others
can see he’s a 5-star singer with the band.

addMetadataToProperty( relationshipUri, "stars", "5" );

Inside the addMetadataToProperty method, we determine the URI of the properties
of the relationship and PUT our new values (since it’s PUT it will always
overwrite existing values, so be careful).

private static void addMetadataToProperty( URI relationshipUri,
        String name, String value ) throws URISyntaxException
{
    URI propertyUri = new URI( relationshipUri.toString() + "/properties" );
    String entity = toJsonNameValuePairCollection( name, value );
    WebResource resource = Client.create()
            .resource( propertyUri );
    ClientResponse response = resource.accept( MediaType.APPLICATION_JSON )
            .type( MediaType.APPLICATION_JSON )
            .entity( entity )
            .put( ClientResponse.class );

    System.out.println( String.format(
            "PUT [%s] to [%s], status code [%d]", entity, propertyUri,
            response.getStatus() ) );
    response.close();
}


Assuming all goes well, we’ll get a 200 OK response back from the server (which
we can check by calling ClientResponse.getStatus()) and we’ve now established a
very small graph that we can query.

6.1.7. Querying graphs

As with the embedded version of the database, the Neo4j server uses graph
traversals to look for data in graphs. Currently the Neo4j server expects a
JSON payload describing the traversal to be POST-ed at the starting node for
the traversal (though this is likely to change in time to a GET-based
approach).

To start this process, we use a simple class that can turn itself into the
equivalent JSON, ready for POST-ing to the server, and in this case we’ve
hardcoded the traverser to look for all nodes with outgoing relationships with
the type "singer".

// TraversalDescription turns into JSON to send to the Server
TraversalDescription t = new TraversalDescription();
t.setOrder( TraversalDescription.DEPTH_FIRST );
t.setUniqueness( TraversalDescription.NODE );
t.setMaxDepth( 10 );
t.setReturnFilter( TraversalDescription.ALL );
t.setRelationships( new Relationship( "singer", Relationship.OUT ) );

Once we have defined the parameters of our traversal, we just need to transfer
it. We do this by determining the URI of the traversers for the start node, and
then POST-ing the JSON representation of the traverser to it.

URI traverserUri = new URI( startNode.toString() + "/traverse/node" );
WebResource resource = Client.create()
        .resource( traverserUri );
String jsonTraverserPayload = t.toJson();
ClientResponse response = resource.accept( MediaType.APPLICATION_JSON )
        .type( MediaType.APPLICATION_JSON )
        .entity( jsonTraverserPayload )
        .post( ClientResponse.class );

System.out.println( String.format(
        "POST [%s] to [%s], status code [%d], returned data: "
                + System.getProperty( "line.separator" ) + "%s",
        jsonTraverserPayload, traverserUri, response.getStatus(),
        response.getEntity( String.class ) ) );
response.close();

Once that request has completed, we get back our dataset of singers and the
bands they belong to:

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/82/relationships/out",
  "data" : {
    "band" : "The Clash",
    "name" : "Joe Strummer"
  },
  "traverse" : "http://localhost:7474/db/data/node/82/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/82/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/82/properties/{key}",
  "all_relationships" : "http://localhost:7474/db/data/node/82/relationships/all",
  "self" : "http://localhost:7474/db/data/node/82",
  "properties" : "http://localhost:7474/db/data/node/82/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/82/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/82/relationships/in",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/82/relationships/in/{-list|&|types}",
  "create_relationship" : "http://localhost:7474/db/data/node/82/relationships"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/83/relationships/out",
  "data" : {
  },
  "traverse" : "http://localhost:7474/db/data/node/83/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/83/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/83/properties/{key}",
  "all_relationships" : "http://localhost:7474/db/data/node/83/relationships/all",
  "self" : "http://localhost:7474/db/data/node/83",
  "properties" : "http://localhost:7474/db/data/node/83/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/83/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/83/relationships/in",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/83/relationships/in/{-list|&|types}",
  "create_relationship" : "http://localhost:7474/db/data/node/83/relationships"
} ]

6.1.8. Phew, is that it?

That’s a flavor of what we can do with the REST API. Naturally any of the HTTP
idioms we provide on the server can be easily wrapped, including removing nodes
and relationships through DELETE. Still if you’ve gotten this far, then
switching .post() for .delete() in the Jersey client code should be
straightforward.

6.1.9. What’s next?

The HTTP API provides a good basis for implementers of client libraries, it’s
also great for HTTP and REST folks. In the future though we expect that
idiomatic language bindings will appear to take advantage of the REST API while
providing comfortable language-level constructs for developers to use, much as
there are similar bindings for the embedded database. For a list of current
Neo4j REST clients and embedded wrappers, see http://www.delicious.com/neo4j/
drivers <http://www.delicious.com/neo4j/drivers>.

6.1.10. Appendix: the code

  * CreateSimpleGraph.java <https://github.com/neo4j/community/blob/1.8.M04/
    server-examples/src/main/java/org/neo4j/examples/server/
    CreateSimpleGraph.java>
  * Relationship.java <https://github.com/neo4j/community/blob/1.8.M04/
    server-examples/src/main/java/org/neo4j/examples/server/Relationship.java>
  * TraversalDescription.java <https://github.com/neo4j/community/blob/1.8.M04/
    server-examples/src/main/java/org/neo4j/examples/server/
    TraversalDescription.java>

Chapter 7. Extending the Neo4j Server

The Neo4j Server can be extended by either plugins or unmanaged extensions. For
more information on the server, see Chapter 18, Neo4j Server.

7.1. Server Plugins

Quick info

  * The server’s functionality can be extended by adding plugins.
  * Plugins are user-specified code which extend the capabilities of the
    database, nodes, or relationships.
  * The neo4j server will then advertise the plugin functionality within
    representations as clients interact via HTTP.

Plugins provide an easy way to extend the Neo4j REST API with new
functionality, without the need to invent your own API. Think of plugins as
server-side scripts that can add functions for retrieving and manipulating
nodes, relationships, paths, properties or indices.

Tip

If you want to have full control over your API, and are willing to put in the
effort, and understand the risks, then Neo4j server also provides hooks for
unmanaged extensions based on JAX-RS.

The needed classes reside in the org.neo4j:server-api <http://search.maven.org/
#search|gav|1|g%3A%22org.neo4j%22%20AND%20a%3A%22server-api%22> jar file. See
the linked page for downloads and instructions on how to include it using
dependency management. For Maven projects, add the Server API dependencies in
your pom.xml like this:

<dependency>
  <groupId>org.neo4j</groupId>
  <artifactId>server-api</artifactId>
  <version>${neo4j-version}</version>
</dependency>

Where ${neo4j-version} is the intended version.

To create a plugin, your code must inherit from the ServerPlugin <http://
components.neo4j.org/server-api/1.8.M04/apidocs/org/neo4j/server/plugins/
ServerPlugin.html> class. Your plugin should also:

  * ensure that it can produce an (Iterable of) Node, Relationship or Path, or
    any Java primitive or String
  * specify parameters,
  * specify a point of extension and of course
  * contain the application logic.
  * make sure that the discovery point type in the @PluginTarget and the
    @Source parameter are of the same type.

An example of a plugin which augments the database (as opposed to nodes or
relationships) follows:

Get all nodes or relationships plugin. 

@Description( "An extension to the Neo4j Server for getting all nodes or relationships" )
public class GetAll extends ServerPlugin
{
    @Name( "get_all_nodes" )
    @Description( "Get all nodes from the Neo4j graph database" )
    @PluginTarget( GraphDatabaseService.class )
    public Iterable<Node> getAllNodes( @Source GraphDatabaseService graphDb )
    {
        return GlobalGraphOperations.at( graphDb ).getAllNodes();
    }

    @Description( "Get all relationships from the Neo4j graph database" )
    @PluginTarget( GraphDatabaseService.class )
    public Iterable<Relationship> getAllRelationships( @Source GraphDatabaseService graphDb )
    {
        return GlobalGraphOperations.at( graphDb ).getAllRelationships();
    }
}

The full source code is found here: GetAll.java <https://github.com/neo4j/
community/blob/1.8.M04/server-examples/src/main/java/org/neo4j/examples/server/
plugins/GetAll.java>

Find the shortest path between two nodes plugin. 

public class ShortestPath extends ServerPlugin
{
    @Description( "Find the shortest path between two nodes." )
    @PluginTarget( Node.class )
    public Iterable<Path> shortestPath(
            @Source Node source,
            @Description( "The node to find the shortest path to." )
                @Parameter( name = "target" ) Node target,
            @Description( "The relationship types to follow when searching for the shortest path(s). " +
                    "Order is insignificant, if omitted all types are followed." )
                @Parameter( name = "types", optional = true ) String[] types,
            @Description( "The maximum path length to search for, default value (if omitted) is 4." )
                @Parameter( name = "depth", optional = true ) Integer depth )
    {
        Expander expander;
        if ( types == null )
        {
            expander = Traversal.expanderForAllTypes();
        }
        else
        {
            expander = Traversal.emptyExpander();
            for ( int i = 0; i < types.length; i++ )
            {
                expander = expander.add( DynamicRelationshipType.withName( types[i] ) );
            }
        }
        PathFinder<Path> shortestPath = GraphAlgoFactory.shortestPath(
                expander, depth == null ? 4 : depth.intValue() );
        return shortestPath.findAllPaths( source, target );
    }
}

The full source code is found here: ShortestPath.java <https://github.com/neo4j
/community/blob/1.8.M04/server-examples/src/main/java/org/neo4j/examples/server
/plugins/ShortestPath.java>

To deploy the code, simply compile it into a .jar file and place it onto the
server classpath (which by convention is the plugins directory under the Neo4j
server home directory).

Tip

Make sure the directories listings are retained in the jarfile by either
building with default Maven, or with jar -cvf myext.jar *, making sure to jar
directories instead of specifying single files.

The .jar file must include the file META-INF/services/
org.neo4j.server.plugins.ServerPlugin with the fully qualified name of the
implementation class. This is an example with multiple entries, each on a
separate line:

org.neo4j.examples.server.plugins.GetAll
org.neo4j.examples.server.plugins.DepthTwo
org.neo4j.examples.server.plugins.ShortestPath

The code above makes an extension visible in the database representation (via
the @PluginTarget annotation) whenever it is served from the Neo4j Server.
Simply changing the @PluginTarget parameter to Node.class or Relationship.class
allows us to target those parts of the data model should we wish. The
functionality extensions provided by the plugin are automatically advertised in
representations on the wire. For example, clients can discover the extension
implemented by the above plugin easily by examining the representations they
receive as responses from the server, e.g. by performing a GET on the default
database URI:

curl -v http://localhost:7474/db/data/

The response to the GET request will contain (by default) a JSON container that
itself contains a container called "extensions" where the available plugins are
listed. In the following case, we only have the GetAll plugin registered with
the server, so only its extension functionality is available. Extension names
will be automatically assigned, based on method names, if not specifically
specified using the @Name annotation.

{
"extensions-info" : "http://localhost:7474/db/data/ext",
"node" : "http://localhost:7474/db/data/node",
"node_index" : "http://localhost:7474/db/data/index/node",
"relationship_index" : "http://localhost:7474/db/data/index/relationship",
"reference_node" : "http://localhost:7474/db/data/node/0",
"extensions_info" : "http://localhost:7474/db/data/ext",
"extensions" : {
  "GetAll" : {
    "get_all_nodes" : "http://localhost:7474/db/data/ext/GetAll/graphdb/get_all_nodes",
    "get_all_relationships" : "http://localhost:7474/db/data/ext/GetAll/graphdb/getAllRelationships"
  }
}

Performing a GET on one of the two extension URIs gives back the meta
information about the service:

curl http://localhost:7474/db/data/ext/GetAll/graphdb/get_all_nodes

{
  "extends" : "graphdb",
  "description" : "Get all nodes from the Neo4j graph database",
  "name" : "get_all_nodes",
  "parameters" : [ ]
}

To use it, just POST to this URL, with parameters as specified in the
description and encoded as JSON data content. F.ex for calling the shortest
path extension (URI gotten from a GET to http://localhost:7474/db/data/node/123
<http://localhost:7474/db/data/node/123>):

curl -X POST http://localhost:7474/db/data/ext/GetAll/node/123/shortestPath \
  -H "Content-Type: application/json" \
  -d '{"target":"http://localhost:7474/db/data/node/456&depth=5"}'

If everything is OK a response code 200 and a list of zero or more items will
be returned. If nothing is returned (null returned from extension) an empty
result and response code 204 will be returned. If the extension throws an
exception response code 500 and a detailed error message is returned.

Extensions that do any kind of write operation will have to manage their own
transactions, i.e. transactions aren’t managed automatically.

Through this model, any plugin can naturally fit into the general hypermedia
scheme that Neo4j espouses - meaning that clients can still take advantage of
abstractions like Nodes, Relationships and Paths with a straightforward upgrade
path as servers are enriched with plugins (old clients don’t break).

7.2. Unmanaged Extensions

Quick info

  * Danger: Men at Work! The unmanaged extensions are a way of deploying
    arbitrary JAX-RS code into the Neo4j server.
  * The unmanaged extensions are exactly that: unmanaged. If you drop poorly
    tested code into the server, it’s highly likely you’ll degrade its
    performance, so be careful.

Some projects want extremely fine control over their server-side code. For this
we’ve introduced an unmanaged extension API.

Warning

This is a sharp tool, allowing users to deploy arbitrary JAX-RS <http://
en.wikipedia.org/wiki/JAX-RS> classes to the server and so you should be
careful when thinking about using this. In particular you should understand
that it’s easy to consume lots of heap space on the server and hinder
performance if you’re not careful.

Still, if you understand the disclaimer, then you load your JAX-RS classes into
the Neo4j server simply by adding adding a @Context annotation to your code,
compiling against the JAX-RS jar and any Neo4j jars you’re making use of. Then
add your classes to the runtime classpath (just drop it in the lib directory of
the Neo4j server). In return you get access to the hosted environment of the
Neo4j server like logging through the org.neo4j.server.logging.Logger.

In your code, you get access to the underlying GraphDatabaseService through the
@Context annotation like so:

public MyCoolService( @Context GraphDatabaseService database )
{
  // Have fun here, but be safe!
}

Remember, the unmanaged API is a very sharp tool. It’s all to easy to
compromise the server by deploying code this way, so think first and see if you
can’t use the managed extensions in preference. However, a number of context
parameters can be automatically provided for you, like the reference to the
database.

In order to specify the mount point of your extension, a full class looks like
this:

Unmanaged extension example. 

@Path( "/helloworld" )
public class HelloWorldResource
{
    private final GraphDatabaseService database;

    public HelloWorldResource( @Context GraphDatabaseService database )
    {
        this.database = database;
    }

    @GET
    @Produces( MediaType.TEXT_PLAIN )
    @Path( "/{nodeId}" )
    public Response hello( @PathParam( "nodeId" ) long nodeId )
    {
        // Do stuff with the database
        return Response.status( Status.OK ).entity(
                ( "Hello World, nodeId=" + nodeId ).getBytes() ).build();
    }
}

The full source code is found here: HelloWorldResource.java <https://github.com
/neo4j/community/blob/1.8.M04/server-examples/src/main/java/org/neo4j/examples/
server/unmanaged/HelloWorldResource.java>

Build this code, and place the resulting jar file (and any custom dependencies)
into the $NEO4J_SERVER_HOME/plugins directory, and include this class in the
neo4j-server.properties file, like so:

Tip

Make sure the directories listings are retained in the jarfile by either
building with default Maven, or with jar -cvf myext.jar *, making sure to jar
directories instead of specifying single files.

#Comma separated list of JAXRS packages containing JAXRS Resource, one package name for each mountpoint.
org.neo4j.server.thirdparty_jaxrs_classes=org.neo4j.examples.server.unmanaged=/examples/unmanaged

Which binds the hello method to respond to GET requests at the URI: http://
{neo4j_server}:{neo4j_port}/examples/unmanaged/helloworld/{nodeId}

curl http://localhost:7474/examples/unmanaged/helloworld/123

which results in

Hello World, nodeId=123

Chapter 8. The Traversal Framework

The Neo4j Traversal API <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/
neo4j/graphdb/traversal/package-summary.html> is a callback based, lazily
executed way of specifying desired movements through a graph in Java. Some
traversal examples are collected under Section 4.5, “Traversal”.

Other options to traverse or query graphs in Neo4j are Cypher and Gremlin.

8.1. Main concepts

Here follows a short explanation of all different methods that can modify or
add to a traversal description.

  * Expanders — define what to traverse, typically in terms of relationships
    direction and type.
  * Order — for example depth-first or breadth-first.
  * Uniqueness — visit nodes (relationships, paths) only once.
  * Evaluator — decide what to return and whether to stop or continue traversal
    beyond the current position.
  * Starting nodes where the traversal will begin.

graphdb-traversal-description.svg

See Section 8.2, “Traversal Framework Java API” for more details.

8.2. Traversal Framework Java API

The traversal framework consists of a few main interfaces in addition to Node
and Relationship: TraversalDescription, Evaluator, Traverser and Uniqueness are
the main ones. The Path interface also has a special purpose in traversals,
since it is used to represent a position in the graph when evaluating that
position. Furthermore the PathExpander (replacing RelationshipExpander) and
Expander interfaces are central to traversals, but users of the API rarely need
to implement them. There are also a set of interfaces for advanced use, when
explicit control over the traversal order is required: BranchSelector,
BranchOrderingPolicy and TraversalBranch.

8.2.1. TraversalDescription

The TraversalDescription <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org
/neo4j/graphdb/traversal/TraversalDescription.html> is the main interface used
for defining and initializing traversals. It is not meant to be implemented by
users of the traversal framework, but rather to be provided by the
implementation of the traversal framework as a way for the user to describe
traversals. TraversalDescription instances are immutable and its methods
returns a new TraversalDescription that is modified compared to the object the
method was invoked on with the arguments of the method.

8.2.1.1. Relationships

Adds a relationship type to the list of relationship types to traverse. By
default that list is empty and it means that it will traverse all relationships
, irregardless of type. If one or more relationships are added to this list 
only the added types will be traversed. There are two methods, one including
direction <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
traversal/TraversalDescription.html#relationships> and another one excluding
direction <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
traversal/TraversalDescription.html#relationships>, where the latter traverses
relationships in both directions <http://components.neo4j.org/neo4j/1.8.M04/
apidocs/org/neo4j/graphdb/Direction.html#BOTH>.

8.2.2. Evaluator

Evaluator <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
traversal/Evaluator.html>s are used for deciding, at each position (represented
as a Path): should the traversal continue, and/or should the node be included
in the result. Given a Path, it asks for one of four actions for that branch of
the traversal:

  * Evaluation.INCLUDE_AND_CONTINUE: Include this node in the result and
    continue the traversal
  * Evaluation.INCLUDE_AND_PRUNE: Include this node in the result, but don’t
    continue the traversal
  * Evaluation.EXCLUDE_AND_CONTINUE: Exclude this node from the result, but
    continue the traversal
  * Evaluation.EXCLUDE_AND_PRUNE: Exclude this node from the result and don’t
    continue the traversal

More than one evaluator can be added. Note that evaluators will be called for
all positions the traverser encounters, even for the start node.

8.2.3. Traverser

The Traverser <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/
graphdb/traversal/Traverser.html> object is the result of invoking traverse()
<http://components.neo4j.org/neo4j-kernel/1.8.M04/apidocs/org/neo4j/graphdb/
traversal/TraversalDescription.html#traverse(org.neo4j.graphdb.Node)> of a
TraversalDescription object. It represents a traversal positioned in the graph,
and a specification of the format of the result. The actual traversal is
performed lazily each time the next()-method of the iterator of the Traverser
is invoked.

8.2.4. Uniqueness

Sets the rules for how positions can be revisited during a traversal as stated
in Uniqueness <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/
kernel/Uniqueness.html>. Default if not set is NODE_GLOBAL <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/Uniqueness.html#
NODE_GLOBAL>.

A Uniqueness can be supplied to the TraversalDescription to dictate under what
circumstances a traversal may revisit the same position in the graph. The
various uniqueness levels that can be used in Neo4j are:

  * NONE - any position in the graph may be revisited.
  * NODE_GLOBAL uniqueness - no node in the entire graph may be visited more
    than once. This could potentially consume a lot of memory since it requires
    keeping an in-memory data structure remembering all the visited nodes.
  * RELATIONSHIP_GLOBAL uniqueness - no relationship in the entire graph may be
    visited more than once. For the same reasons as NODE_GLOBAL uniqueness,
    this could use up a lot of memory. But since graphs typically have a larger
    number of relationships than nodes, the memory overhead of this uniqueness
    level could grow even quicker.
  * NODE_PATH uniqueness - a node may not occur previously in the path reaching
    up to it.
  * RELATIONSHIP_PATH uniqueness - a relationship may not occur previously in
    the path reaching up to it.
  * NODE_RECENT uniqueness - Similar to NODE_GLOBAL uniqueness in that there is
    a global collection of visited nodes each position is checked against. This
    uniqueness level does however have a cap on how much memory it may consume
    in the form of a collection that only contains the most recently visited
    nodes. The size of this collection can be specified by providing a number
    as the second argument to the TraversalDescription.uniqueness()-method
    along with the uniqueness level.
  * RELATIONSHIP_RECENT uniqueness - works like NODE_RECENT uniqueness, but
    with relationships instead of nodes.

8.2.4.1. Depth First / Breadth First

These are convenience methods for setting preorder depth-first <http://
en.wikipedia.org/wiki/Depth-first_search>/ breadth-first <http://
en.wikipedia.org/wiki/Breadth-first_search> BranchSelector|ordering policies.
The same result can be achieved by calling the order <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/traversal/
TraversalDescription.html#order> method with ordering policies from the
Traversal <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/
Traversal.html#preorderDepthFirst> factory <http://components.neo4j.org/
neo4j-kernel/1.8.M04/apidocs/org/neo4j/kernel/Traversal.html#
preorderBreadthFirst>, or to write your own BranchSelector/BranchOrderingPolicy
and pass in.

8.2.5. Order - How to move through branches?

A more generic version of depthFirst/breadthFirst methods in that it allows an
arbitrary BranchOrderingPolicy <http://components.neo4j.org/neo4j/1.8.M04/
apidocs/org/neo4j/graphdb/traversal/BranchOrderingPolicy.html> to be injected
into the description.

8.2.6. BranchSelector

A BranchSelector is used for selecting which branch of the traversal to attempt
next. This is used for implementing traversal orderings. The traversal
framework provides a few basic ordering implementations:

  * Traversal.preorderDepthFirst() - Traversing depth first, visiting each node
    before visiting its child nodes.
  * Traversal.postorderDepthFirst() - Traversing depth first, visiting each
    node after visiting its child nodes.
  * Traversal.preorderBreadthFirst() - Traversing breadth first, visiting each
    node before visiting its child nodes.
  * Traversal.postorderBreadthFirst() - Traversing breadth first, visiting each
    node after visiting its child nodes.

Note

Please note that breadth first traversals have a higher memory overhead than
depth first traversals.

BranchSelectors carries state and hence needs to be uniquely instantiated for
each traversal. Therefore it is supplied to the TraversalDescription through a
BranchOrderingPolicy interface, which is a factory of BranchSelector instances.

A user of the Traversal framework rarely needs to implement his own
BranchSelector or BranchOrderingPolicy, it is provided to let graph algorithm
implementors provide their own traversal orders. The Neo4j Graph Algorithms
package contains for example a BestFirst order BranchSelector/
BranchOrderingPolicy that is used in BestFirst search algorithms such as A* and
Dijkstra.

8.2.6.1. BranchOrderingPolicy

A factory for creating BranchSelectors to decide in what order branches are
returned (where a branch’s position is represented as a Path <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/Path.html> from
the start node to the current node). Common policies are depth-first <http://
components.neo4j.org/neo4j-kernel/1.8.M04/apidocs/org/neo4j/graphdb/traversal/
TraversalDescription.html#depthFirst()> and breadth-first <http://
components.neo4j.org/neo4j-kernel/1.8.M04/apidocs/org/neo4j/graphdb/traversal/
TraversalDescription.html#breadthFirst()> and that’s why there are convenience
methods for those. For example, calling TraversalDescription#depthFirst()
<http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/traversal/
TraversalDescription.html#depthFirst()> is equivalent to:

description.order( Traversal.preorderDepthFirst() );

8.2.6.2. TraversalBranch

An object used by the BranchSelector to get more branches from a certain
branch. In essence these are a composite of a Path and a RelationshipExpander
that can be used to get new TraversalBranch <http://components.neo4j.org/neo4j/
1.8.M04/apidocs/org/neo4j/graphdb/traversal/TraversalBranch.html>es from the
current one.

8.2.7. Path

A Path <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
Path.html> is a general interface that is part of the Neo4j API. In the
traversal API of Neo4j the use of Paths are twofold. Traversers can return
their results in the form of the Paths of the visited positions in the graph
that are marked for being returned. Path objects are also used in the
evaluation of positions in the graph, for determining if the traversal should
continue from a certain point or not, and whether a certain position should be
included in the result set or not.

8.2.8. PathExpander/RelationshipExpander

The traversal framework use PathExpanders (replacing RelationshipExpander) to
discover the relationships that should be followed from a particular path to
further branches in the traversal.

8.2.9. Expander

A more generic version of relationships where a RelationshipExpander is
injected, defining all relationships to be traversed for any given node. By
default (and when using relationships) a default expander <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/Traversal.html#
emptyExpander> is used, where any particular order of relationships isn’t
guaranteed. There’s another implementation which guarantees that relationships
are traversed in order of relationship type <http://components.neo4j.org/neo4j/
1.8.M04/apidocs/org/neo4j/kernel/OrderedByTypeExpander.html>, where types are
iterated in the order they were added.

The Expander interface is an extension of the RelationshipExpander interface
that makes it possible to build customized versions of an Expander. The
implementation of TraversalDescription uses this to provide methods for
defining which relationship types to traverse, this is the usual way a user of
the API would define a RelationshipExpander — by building it internally in the
TraversalDescription.

All the RelationshipExpanders provided by the Neo4j traversal framework also
implement the Expander interface. For a user of the traversal API it is easier
to implement the PathExpander/RelationshipExpander interface, since it only
contains one method — the method for getting the relationships from a path/
node, the methods that the Expander interface adds are just for building new
Expanders.

8.2.10. How to use the Traversal framework

In contrary to Node#traverse <http://components.neo4j.org/neo4j/1.8.M04/apidocs
/org/neo4j/graphdb/Node.html#traverse> a traversal description <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/traversal/
TraversalDescription.html> is built (using a fluent interface) and such a
description can spawn traversers <http://components.neo4j.org/neo4j/1.8.M04/
apidocs/org/neo4j/graphdb/traversal/Traverser.html>.

Figure 8.1. Traversal Example Graph

Traversal-Example-Graph-how-to-use-the-Traversal-framework.svg


With the definition of the RelationshipTypes as

private enum Rels implements RelationshipType
{
    LIKES, KNOWS
}

The graph can be traversed with for example the following traverser, starting
at the “Joe” node:

for ( Path position : Traversal.description()
        .depthFirst()
        .relationships( Rels.KNOWS )
        .relationships( Rels.LIKES, Direction.INCOMING )
        .evaluator( Evaluators.toDepth( 5 ) )
        .traverse( node ) )
{
    output += position + "\n";
}

The traversal will output:

(7)
(7)<--[LIKES,1]--(4)
(7)<--[LIKES,1]--(4)--[KNOWS,6]-->(1)
(7)<--[LIKES,1]--(4)--[KNOWS,6]-->(1)--[KNOWS,4]-->(6)
(7)<--[LIKES,1]--(4)--[KNOWS,6]-->(1)--[KNOWS,4]-->(6)--[KNOWS,3]-->(5)
(7)<--[LIKES,1]--(4)--[KNOWS,6]-->(1)--[KNOWS,4]-->(6)--[KNOWS,3]-->(5)--[KNOWS,2]-->(2)
(7)<--[LIKES,1]--(4)--[KNOWS,6]-->(1)<--[KNOWS,5]--(3)

Since TraversalDescription <http://components.neo4j.org/neo4j/1.8.M04/apidocs/
org/neo4j/graphdb/traversal/TraversalDescription.html>s are immutable it is
also useful to create template descriptions which holds common settings shared
by different traversals. For example, let’s start with this traverser:

final TraversalDescription FRIENDS_TRAVERSAL = Traversal.description()
        .depthFirst()
        .relationships( Rels.KNOWS )
        .uniqueness( Uniqueness.RELATIONSHIP_GLOBAL );

This traverser would yield the following output (we will keep starting from the
“Joe” node):

(7)
(7)--[KNOWS,0]-->(2)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)<--[KNOWS,4]--(1)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)<--[KNOWS,4]--(1)<--[KNOWS,5]--(3)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)<--[KNOWS,4]--(1)<--[KNOWS,6]--(4)

Now let’s create a new traverser from it, restricting depth to three:

for ( Path path : FRIENDS_TRAVERSAL
        .evaluator( Evaluators.toDepth( 3 ) )
        .traverse( node ) )
{
    output += path + "\n";
}

This will give us the following result:

(7)
(7)--[KNOWS,0]-->(2)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)

Or how about from depth two to four? That’s done like this:

for ( Path path : FRIENDS_TRAVERSAL
        .evaluator( Evaluators.fromDepth( 2 ) )
        .evaluator( Evaluators.toDepth( 4 ) )
        .traverse( node ) )
{
    output += path + "\n";
}

This traversal gives us:

(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)
(7)--[KNOWS,0]-->(2)<--[KNOWS,2]--(5)<--[KNOWS,3]--(6)<--[KNOWS,4]--(1)

For various useful evaluators, see the Evaluators <http://components.neo4j.org/
neo4j/1.8.M04/apidocs/org/neo4j/graphdb/traversal/Evaluators.html> Java API or
simply implement the Evaluator <http://components.neo4j.org/neo4j/1.8.M04/
apidocs/org/neo4j/graphdb/traversal/Evaluator.html> interface yourself.

If you’re not interested in the Path <http://components.neo4j.org/neo4j/1.8.M04
/apidocs/org/neo4j/graphdb/Path.html>s, but the Node <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/Node.html>s you
can transform the traverser into an iterable of nodes <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/traversal/
Traverser.html#nodes()> like this:

for ( Node currentNode : FRIENDS_TRAVERSAL
        .traverse( node )
        .nodes() )
{
    output += currentNode.getProperty( "name" ) + "\n";
}

In this case we use it to retrieve the names:

Joe
Sara
Peter
Dirk
Lars
Ed
Lisa

Relationships <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/
graphdb/traversal/Traverser.html#relationships()> are fine as well, here’s how
to get them:

for ( Relationship relationship : FRIENDS_TRAVERSAL
        .traverse( node )
        .relationships() )
{
    output += relationship.getType() + "\n";
}

Here the relationship types are written, and we get:

KNOWS
KNOWS
KNOWS
KNOWS
KNOWS
KNOWS

The source code for the traversers in this example is available at:
TraversalExample.java <https://github.com/neo4j/community/blob/1.8.M04/
embedded-examples/src/main/java/org/neo4j/examples/TraversalExample.java>

Chapter 9. Domain Modeling Gallery

The following chapters contain simplified examples of how different domains can
be modeled using Neo4j. The aim is not to give full examples, but to suggest
possible ways to think using the graph patterns and data locality in
traversals.

9.1. User roles in graphs

This is an example showing a hierarchy of roles. What’s interesting is that a
tree is not sufficient for storing this structure, as elaborated below.

roles.png

This is an implementation of an example found in the article A Model to
Represent Directed Acyclic Graphs (DAG) on SQL Databases <http://
www.codeproject.com/KB/database/Modeling_DAGs_on_SQL_DBs.aspx> by Kemal Erdogan
<http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=274518>.
The article discusses how to store directed acyclic graphs <http://
en.wikipedia.org/wiki/Directed_acyclic_graph> (DAGs) in SQL based DBs. DAGs are
almost trees, but with a twist: it may be possible to reach the same node
through different paths. Trees are restricted from this possibility, which
makes them much easier to handle. In our case it is "Ali" and "Engin", as they
are both admins and users and thus reachable through these group nodes. Reality
often looks this way and can’t be captured by tree structures.

In the article an SQL Stored Procedure solution is provided. The main idea,
that also have some support from scientists, is to pre-calculate all possible
(transitive) paths. Pros and cons of this approach:

  * decent performance on read
  * low performance on insert
  * wastes lots of space
  * relies on stored procedures

In Neo4j storing the roles is trivial. In this case we use PART_OF (green
edges) relationships to model the group hierarchy and MEMBER_OF (blue edges) to
model membership in groups. We also connect the top level groups to the
reference node by ROOT relationships. This gives us a useful partitioning of
the graph. Neo4j has no predefined relationship types, you are free to create
any relationship types and give them any semantics you want.

Lets now have a look at how to retrieve information from the graph. The Java
code is using the Neo4j Traversal API (see Section 8.2, “Traversal Framework
Java API”), the queries are done using Cypher.

9.1.1. Get the admins

Node admins = getNodeByName( "Admins" );
Traverser traverser = admins.traverse(
        Traverser.Order.BREADTH_FIRST,
        StopEvaluator.END_OF_GRAPH,
        ReturnableEvaluator.ALL_BUT_START_NODE,
        RoleRels.PART_OF, Direction.INCOMING,
        RoleRels.MEMBER_OF, Direction.INCOMING );

resulting in the output

Found: Ali at depth: 0
Found: HelpDesk at depth: 0
Found: Engin at depth: 1
Found: Demet at depth: 1

The result is collected from the traverser using this code:

String output = "";
for ( Node node : traverser )
{
    output += "Found: " + node.getProperty( NAME ) + " at depth: "
              + ( traverser.currentPosition().depth() - 1 ) + "\n";
}

In Cypher, a similar query would be:

START admins=node(14)
MATCH admins<-[:PART_OF*0..]-group<-[:MEMBER_OF]-user
RETURN user.name, group.name

resulting in:

+---------------------+
|user.name|group.name |
|---------------------|
|3 rows               |
|---------------------|
|3 ms                 |
|---------------------|
|"Ali"    |"Admins"   |
|---------+-----------|
|"Engin"  |"HelpDesk" |
|---------+-----------|
|"Demet"  |"HelpDesk" |
+---------------------+

9.1.2. Get the group memberships of a user

Using the Neo4j Java Traversal API, this query looks like:

Node jale = getNodeByName( "Jale" );
traverser = jale.traverse(
        Traverser.Order.DEPTH_FIRST,
        StopEvaluator.END_OF_GRAPH,
        ReturnableEvaluator.ALL_BUT_START_NODE,
        RoleRels.MEMBER_OF, Direction.OUTGOING,
        RoleRels.PART_OF, Direction.OUTGOING );

resuling in:

Found: ABCTechnicians at depth: 0
Found: Technicians at depth: 1
Found: Users at depth: 2

In Cypher:

START jale=node(10)
MATCH jale-[:MEMBER_OF]->()-[:PART_OF*0..]->group
RETURN group.name

+----------------+
|group.name      |
|----------------|
|3 rows          |
|----------------|
|1 ms            |
|----------------|
|"ABCTechnicians"|
|----------------|
|"Technicians"   |
|----------------|
|"Users"         |
+----------------+

9.1.3. Get all groups

In Java:

Node referenceNode = getNodeByName( "Reference_Node") ;
traverser = referenceNode.traverse(
        Traverser.Order.BREADTH_FIRST,
        StopEvaluator.END_OF_GRAPH,
        ReturnableEvaluator.ALL_BUT_START_NODE,
        RoleRels.ROOT, Direction.INCOMING,
        RoleRels.PART_OF, Direction.INCOMING );

resulting in:

Found: Admins at depth: 0
Found: Users at depth: 0
Found: HelpDesk at depth: 1
Found: Managers at depth: 1
Found: Technicians at depth: 1
Found: ABCTechnicians at depth: 2

In Cypher:

START refNode=node(16)
MATCH refNode<-[:ROOT]->()<-[:PART_OF*0..]-group
RETURN group.name

+----------------+
|group.name      |
|----------------|
|6 rows          |
|----------------|
|2 ms            |
|----------------|
|"Admins"        |
|----------------|
|"HelpDesk"      |
|----------------|
|"Users"         |
|----------------|
|"Managers"      |
|----------------|
|"Technicians"   |
|----------------|
|"ABCTechnicians"|
+----------------+

9.1.4. Get all members of all groups

Now, let’s try to find all users in the system being part of any group.

in Java:

traverser = referenceNode.traverse(
        Traverser.Order.BREADTH_FIRST,
        StopEvaluator.END_OF_GRAPH,
        new ReturnableEvaluator()
        {
            @Override
            public boolean isReturnableNode(
                    TraversalPosition currentPos )
            {
                if ( currentPos.isStartNode() )
                {
                    return false;
                }
                Relationship rel = currentPos.lastRelationshipTraversed();
                return rel.isType( RoleRels.MEMBER_OF );
            }
        },
        RoleRels.ROOT, Direction.INCOMING,
        RoleRels.PART_OF, Direction.INCOMING,
        RoleRels.MEMBER_OF, Direction.INCOMING );

Found: Ali at depth: 1
Found: Engin at depth: 1
Found: Burcu at depth: 1
Found: Can at depth: 1
Found: Demet at depth: 2
Found: Gul at depth: 2
Found: Fuat at depth: 2
Found: Hakan at depth: 2
Found: Irmak at depth: 2
Found: Jale at depth: 3

In Cypher, this looks like:

START refNode=node(16)
MATCH refNode<-[:ROOT]->root, p=root<-[PART_OF*0..]-()<-[:MEMBER_OF]-user
RETURN user.name, min(length(p))
ORDER BY min(length(p)), user.name

and results in the following output:

+-------------------------+
|user.name|min(length(p)) |
|-------------------------|
|10 rows                  |
|-------------------------|
|24 ms                    |
|-------------------------|
|"Ali"    |1              |
|---------+---------------|
|"Burcu"  |1              |
|---------+---------------|
|"Can"    |1              |
|---------+---------------|
|"Engin"  |1              |
|---------+---------------|
|"Demet"  |2              |
|---------+---------------|
|"Fuat"   |2              |
|---------+---------------|
|"Gul"    |2              |
|---------+---------------|
|"Hakan"  |2              |
|---------+---------------|
|"Irmak"  |2              |
|---------+---------------|
|"Jale"   |3              |
+-------------------------+

As seen above, querying even more complex scenarios can be done using
comparatively short constructs in Java and other query mechanisms.

9.2. ACL structures in graphs

This example gives a generic overview of an approach to handling Access Control
Lists (ACLs) in graphs, and a simplified example with concrete queries.

9.2.1. Generic approach

In many scenarios, an application needs to handle security on some form of
managed objects. This example describes one pattern to handle this through the
use of a graph structure and traversers that build a full permissions-structure
for any managed object with exclude and include overriding possibilities. This
results in a dynamic construction of ACLs based on the position and context of
the managed object.

The result is a complex security scheme that can easily be implemented in a
graph structure, supporting permissions overriding, principal and content
composition, without duplicating data anywhere.

ACL.png

9.2.1.1. Technique

As seen in the example graph layout, there are some key concepts in this domain
model:

  * The managed content (folders and files) that are connected by
    HAS_CHILD_CONTENT relationships
  * The Principal subtree pointing out principals that can act as ACL members,
    pointed out by the PRINCIPAL relationships.
  * The aggregation of principals into groups, connected by the IS_MEMBER_OF
    relationship. One principal (user or group) can be part of many groups at
    the same time.
  * The SECURITY - relationships, connecting the content composite structure to
    the principal composite structure, containing a addition/removal modifier
    property ("+RW")

9.2.1.2. Constructing the ACL

The calculation of the effective permissions (e.g. Read, Write, Execute) for a
principal for any given ACL-managed node (content) follows a number of rules
that will be encoded into the permissions-traversal:

9.2.1.3. Top-down-Traversal

This approach will let you define a generic permission pattern on the root
content, and then refine that for specific sub-content nodes and specific
principals.

 1. Start at the content node in question traverse upwards to the content root
    node to determine the path to it.
 2. Start with a effective optimistic permissions list of "all permitted" (111
    in a bit encoded ReadWriteExecute case) or 000 if you like pessimistic
    security handling (everything is forbidden unless explicitly allowed).
 3. Beginning from the topmost content node, look for any SECURITY
    relationships on it.
 4. If found, look if the principal in question is part of the end-principal of
    the SECURITY relationship.
 5. If yes, add the "+" permission modifiers to the existing permission
    pattern, revoke the "-" permission modifiers from the pattern.
 6. If two principal nodes link to the same content node, first apply the more
    generic prinipals modifiers.
 7. Repeat the security modifier search all the way down to the target content
    node, thus overriding more generic permissions with the set on nodes closer
    to the target node.

The same algorithm is applicable for the bottom-up approach, basically just
traversing from the target content node upwards and applying the security
modifiers dynamically as the traverser goes up.

9.2.1.4. Example

Now, to get the resulting access rights for e.g. "user 1" on the "My File.pdf"
in a Top-Down approach on the model in the graph above would go like:

 1. Traveling upward, we start with "Root folder", and set the permissions to
    11 initially (only considering Read, Write).
 2. There are two SECURITY relationships to that folder. User 1 is contained in
    both of them, but "root" is more generic, so apply it first then "All
    principals" +W +R → 11.
 3. "Home" has no SECURITY instructions, continue.
 4. "user1 Home" has SECURITY. First apply "Regular Users" (-R -W) → 00, Then
    "user 1" (+R +W) → 11.
 5. The target node "My File.pdf" has no SECURITY modifiers on it, so the
    effective permissions for "User 1" on "My File.pdf" are ReadWrite → 11.

9.2.2. Read-permission example

In this example, we are going to examine a tree structure of directories and
files. Also, there are users that own files and roles that can be assigned to
users. Roles can have permissions on directory or files structures (here we
model only canRead, as opposed to full rwx Unix permissions) and be nested. A
more thorough example of modeling ACL structures can be found at How to Build
Role-Based Access Control in SQL <http://www.xaprb.com/blog/2006/08/16/
how-to-build-role-based-access-control-in-sql/>.

The-Domain-Structure-ACL-structures-in-graphs.svg

9.2.2.1. Find all files in the directory structure

In order to find all files contained in this structure, we need a variable
length query that follows all contains relationships and retrieves the nodes at
the other end of the leaf relationships.

START root=node:node_auto_index(name = 'FileRoot')
MATCH root-[:contains*0..]->(parentDir)-[:leaf]->file
RETURN file

resulting in:

+----------------------+
|file                  |
|----------------------|
|2 rows                |
|----------------------|
|94 ms                 |
|----------------------|
|Node[11]{name:"File1"}|
|----------------------|
|Node[10]{name:"File2"}|
+----------------------+

9.2.2.2. What files are owned by whom?

If we introduce the concept of ownership on files, we then can ask for the
owners of the files we find — connected via owns relationships to file nodes.

START root=node:node_auto_index(name = 'FileRoot')
MATCH root-[:contains*0..]->()-[:leaf]->file<-[:owns]-user
RETURN file, user

Returning the owners of all files below the FileRoot node.

+--------------------------------------------+
|file                  |user                 |
|--------------------------------------------|
|2 rows                                      |
|--------------------------------------------|
|3 ms                                        |
|--------------------------------------------|
|Node[11]{name:"File1"}|Node[8]{name:"User1"}|
|----------------------+---------------------|
|Node[10]{name:"File2"}|Node[7]{name:"User2"}|
+--------------------------------------------+

9.2.2.3. Who has access to a File?

If we now want to check what users have read access to all Files, and define
our ACL as

  * The root directory has no access granted.
  * Any user having a role that has been granted canRead access to one of the
    parent folders of a File has read access.

In order to find users that can read any part of the parent folder hierarchy
above the files, Cypher provides optional variable length path.

START file=node:node_auto_index('name:File*')
MATCH file<-[:leaf]-()<-[:contains*0..]-dir<-[?:canRead]-role-[:member]->readUser
RETURN file.name, dir.name, role.name, readUser.name

This will return the file, and the directory where the user has the canRead
permission along with the user and their role.

+--------------------------------------------+
|file.name|dir.name  |role.name|readUser.name|
|--------------------------------------------|
|9 rows                                      |
|--------------------------------------------|
|45 ms                                       |
|--------------------------------------------|
|"File2"  |"Desktop" |<null>   |<null>       |
|---------+----------+---------+-------------|
|"File2"  |"HomeU2"  |<null>   |<null>       |
|---------+----------+---------+-------------|
|"File2"  |"Home"    |<null>   |<null>       |
|---------+----------+---------+-------------|
|"File2"  |"FileRoot"|"SUDOers"|"Admin1"     |
|---------+----------+---------+-------------|
|"File2"  |"FileRoot"|"SUDOers"|"Admin2"     |
|---------+----------+---------+-------------|
|"File1"  |"HomeU1"  |<null>   |<null>       |
|---------+----------+---------+-------------|
|"File1"  |"Home"    |<null>   |<null>       |
|---------+----------+---------+-------------|
|"File1"  |"FileRoot"|"SUDOers"|"Admin1"     |
|---------+----------+---------+-------------|
|"File1"  |"FileRoot"|"SUDOers"|"Admin2"     |
+--------------------------------------------+

The results listed above contain null values for optional path segments, which
can be mitigated by either asking several queries or returning just the really
needed values.

Chapter 10. Languages

The table below lists community contributed language- and framework bindings
for using Neo4j in embedded mode.

Table 10.1. Neo4j embedded drivers contributed by the community.

+-----------------------------------------------------------------------------+
|name       |language /|URL                                                   |
|           |framework |                                                      |
|-----------+----------+------------------------------------------------------|
|Neo4j.rb   |JRuby     |https://github.com/andreasronge/neo4j <https://       |
|           |          |github.com/andreasronge/neo4j>                        |
|-----------+----------+------------------------------------------------------|
|Neo4django |Python,   |https://github.com/scholrly/neo4django <https://      |
|           |Django    |github.com/scholrly/neo4django>                       |
|-----------+----------+------------------------------------------------------|
|Neo4js     |JavaScript|https://github.com/neo4j/neo4js <https://github.com/  |
|           |          |neo4j/neo4js>                                         |
|-----------+----------+------------------------------------------------------|
|Gremlin    |Java,     |Section 19.17, “Gremlin Plugin”, https://github.com/  |
|           |Groovy    |tinkerpop/gremlin/wiki <https://github.com/tinkerpop/ |
|           |          |gremlin/wiki>                                         |
|-----------+----------+------------------------------------------------------|
|Neo4j-Scala|Scala     |https://github.com/FaKod/neo4j-scala <https://        |
|           |          |github.com/FaKod/neo4j-scala>                         |
|-----------+----------+------------------------------------------------------|
|Borneo     |Clojure   |https://github.com/wagjo/borneo <https://github.com/  |
|           |          |wagjo/borneo>                                         |
+-----------------------------------------------------------------------------+


For information on REST clients for different languages, see Chapter 6, Neo4j
Remote Client Libraries.

Chapter 11. Using Neo4j embedded in Python applications

For instructions on how to install the Python Neo4j driver, see Section 20.1,
“Installation”.

For general information on the Python language binding, see Chapter 20, Python
embedded bindings.

11.1. Hello, world!

Here is a simple example to get you started.

from neo4j import GraphDatabase

# Create a database
db = GraphDatabase(folder_to_put_db_in)

# All write operations happen in a transaction
with db.transaction:
    firstNode = db.node(name='Hello')
    secondNode = db.node(name='world!')

    # Create a relationship with type 'knows'
    relationship = firstNode.knows(secondNode, name='graphy')

# Read operations can happen anywhere
message = ' '.join([firstNode['name'], relationship['name'], secondNode['name']])

print message

# Delete the data
with db.transaction:
    firstNode.knows.single.delete()
    firstNode.delete()
    secondNode.delete()

# Always shut down your database when your application exits
db.shutdown()

11.2. A sample app using traversals and indexes

For detailed documentation on the concepts use here, see Section 20.3,
“Indexes” and Section 20.5, “Traversals”.

This example shows you how to get started building something like a simple
invoice tracking application with Neo4j.

We start out by importing Neo4j, and creating some meta data that we will use
to organize our actual data with.

from neo4j import GraphDatabase, INCOMING, Evaluation

# Create a database
db = GraphDatabase(folder_to_put_db_in)

# All write operations happen in a transaction
with db.transaction:

    # A node to connect customers to
    customers = db.node()

    # A node to connect invoices to
    invoices = db.node()

    # Connected to the reference node, so
    # that we can always find them.
    db.reference_node.CUSTOMERS(customers)
    db.reference_node.INVOICES(invoices)

    # An index, helps us rapidly look up customers
    customer_idx = db.node.indexes.create('customers')

11.2.1. Domain logic

Then we define some domain logic that we want our application to be able to
perform. Our application has two domain objects, Customers and Invoices. Let’s
create methods to add new customers and invoices.

def create_customer(name):
    with db.transaction:
        customer = db.node(name=name)
        customer.INSTANCE_OF(customers)

        # Index the customer by name
        customer_idx['name'][name] = customer
    return customer

def create_invoice(customer, amount):
    with db.transaction:
        invoice = db.node(amount=amount)
        invoice.INSTANCE_OF(invoices)

        invoice.RECIPIENT(customer)
    return customer

In the customer case, we create a new node to represent the customer and
connect it to the customers node. This helps us find customers later on, as
well as determine if a given node is a customer.

We also index the name of the customer, to allow for quickly finding customers
by name.

In the invoice case, we do the same, except no indexing. We also connect each
new invoice to the customer it was sent to, using a relationship of type
SENT_TO.

Next, we want to be able to retrieve customers and invoices that we have added.
Because we are indexing customer names, finding them is quite simple.

def get_customer(name):
    return customer_idx['name'][name].single

Lets say we also like to do something like finding all invoices for a given
customer that are above some given amount. This could be done by writing a
traversal, like this:

def get_invoices_with_amount_over(customer, min_sum):
    def evaluator(path):
        node = path.end
        if node.has_key('amount') and node['amount'] > min_sum:
            return Evaluation.INCLUDE_AND_CONTINUE
        return Evaluation.EXCLUDE_AND_CONTINUE

    return db.traversal()\
             .relationships('RECIPIENT', INCOMING)\
             .evaluator(evaluator)\
             .traverse(customer)\
             .nodes

11.2.2. Creating data and getting it back

Putting it all together, we can create customers and invoices, and use the
search methods we wrote to find them.

for name in ['Acme Inc.', 'Example Ltd.']:
   create_customer(name)

# Loop through customers
for relationship in customers.INSTANCE_OF:
   customer = relationship.start
   for i in range(1,12):
       create_invoice(customer, 100 * i)

# Finding large invoices
large_invoices = get_invoices_with_amount_over(get_customer('Acme Inc.'), 500)

# Getting all invoices per customer:
for relationship in get_customer('Acme Inc.').RECIPIENT.incoming:
    invoice = relationship.start

Part III. Reference

The reference part is the authoritative source for details on Neo4j usage. It
covers details on capabilities, transactions, indexing and queries among other
topics.

Table of Contents

12. Capabilities

    12.1. Data Security
    12.2. Data Integrity

        12.2.1. Core Graph Engine
        12.2.2. Different Data Sources

    12.3. Data Integration

        12.3.1. Event-based Synchronization
        12.3.2. Periodic Synchronization
        12.3.3. Periodic Full Export/Import of Data

    12.4. Availability and Reliability

        12.4.1. Operational Availability
        12.4.2. Disaster Recovery/ Resiliency

    12.5. Capacity

        12.5.1. File Sizes
        12.5.2. Read speed
        12.5.3. Write speed
        12.5.4. Data size

13. Transaction Management

    13.1. Interaction cycle
    13.2. Isolation levels
    13.3. Default locking behavior
    13.4. Deadlocks
    13.5. Delete semantics
    13.6. Creating unique nodes

        13.6.1. Single thread
        13.6.2. Get or create
        13.6.3. Pessimistic locking

    13.7. Transaction events

14. Data Import

    14.1. Batch Insertion

        14.1.1. Batch Inserter Examples
        14.1.2. Batch Graph Database
        14.1.3. Index Batch Insertion

15. Indexing

    15.1. Introduction
    15.2. Create
    15.3. Delete
    15.4. Add
    15.5. Remove
    15.6. Update
    15.7. Search

        15.7.1. Get
        15.7.2. Query

    15.8. Relationship indexes
    15.9. Scores
    15.10. Configuration and fulltext indexes
    15.11. Extra features for Lucene indexes

        15.11.1. Numeric ranges
        15.11.2. Sorting
        15.11.3. Querying with Lucene Query objects
        15.11.4. Compound queries
        15.11.5. Default operator
        15.11.6. Caching

    15.12. Automatic Indexing

        15.12.1. Configuration
        15.12.2. Search
        15.12.3. Runtime Configuration
        15.12.4. Updating the Automatic Index

16. Cypher Query Language

    16.1. Operators
    16.2. Expressions
    16.3. Parameters
    16.4. Identifiers
    16.5. Comments
    16.6. Updating the graph with Cypher

        16.6.1. Updating query structure
        16.6.2. Query Parts & Structure
        16.6.3. Returning data

    16.7. Transactions and Cypher
    16.8. Patterns
    16.9. Start

        16.9.1. Node by id
        16.9.2. Relationship by id
        16.9.3. Multiple nodes by id
        16.9.4. All nodes
        16.9.5. Node by index lookup
        16.9.6. Relationship by index lookup
        16.9.7. Node by index query
        16.9.8. Multiple start points

    16.10. Match

        16.10.1. Introduction
        16.10.2. Related nodes
        16.10.3. Outgoing relationships
        16.10.4. Directed relationships and identifier
        16.10.5. Match by relationship type
        16.10.6. Match by multiple relationship types
        16.10.7. Match by relationship type and use an identifier
        16.10.8. Relationship types with uncommon characters
        16.10.9. Multiple relationships
        16.10.10. Variable length relationships
        16.10.11. Relationship identifier in variable length relationships
        16.10.12. Zero length paths
        16.10.13. Optional relationship
        16.10.14. Optional typed and named relationship
        16.10.15. Properties on optional elements
        16.10.16. Complex matching
        16.10.17. Shortest path
        16.10.18. All shortest paths
        16.10.19. Named path
        16.10.20. Matching on a bound relationship

    16.11. Where

        16.11.1. Boolean operations
        16.11.2. Filter on node property
        16.11.3. Regular expressions
        16.11.4. Escaping in regular expressions
        16.11.5. Case insensitive regular expressions
        16.11.6. Filtering on relationship type
        16.11.7. Property exists
        16.11.8. Default true if property is missing
        16.11.9. Default false if property is missing
        16.11.10. Filter on null values
        16.11.11. Filter on patterns
        16.11.12. IN operator

    16.12. Return

        16.12.1. Return nodes
        16.12.2. Return relationships
        16.12.3. Return property
        16.12.4. Return all elements
        16.12.5. Identifier with uncommon characters
        16.12.6. Column alias
        16.12.7. Optional properties
        16.12.8. Unique results

    16.13. Aggregation

        16.13.1. Introduction
        16.13.2. COUNT
        16.13.3. Count nodes
        16.13.4. Group Count Relationship Types
        16.13.5. Count entities
        16.13.6. Count non-null values
        16.13.7. SUM
        16.13.8. AVG
        16.13.9. MAX
        16.13.10. MIN
        16.13.11. COLLECT
        16.13.12. DISTINCT

    16.14. Order by

        16.14.1. Order nodes by property
        16.14.2. Order nodes by multiple properties
        16.14.3. Order nodes in descending order
        16.14.4. Ordering null

    16.15. Skip

        16.15.1. Skip first three
        16.15.2. Return middle two

    16.16. Limit

        16.16.1. Return first part

    16.17. With

        16.17.1. Filter on aggregate function results
        16.17.2. Alternative syntax of with

    16.18. Create

        16.18.1. Create single node
        16.18.2. Create single node and set properties
        16.18.3. Return created node
        16.18.4. Create a relationship between two nodes
        16.18.5. Create a relationship and set properties
        16.18.6. Create a full path
        16.18.7. Create single node from map
        16.18.8. Create multiple nodes from maps

    16.19. Delete

        16.19.1. Delete single node
        16.19.2. Remove a node and connected relationships
        16.19.3. Remove a property

    16.20. Set

        16.20.1. Set a property

    16.21. Relate

        16.21.1. Create relationship if it is missing
        16.21.2. Create node if missing
        16.21.3. Create nodes with values
        16.21.4. Create relationship with values
        16.21.5. Describe complex pattern

    16.22. Foreach

        16.22.1. Mark all nodes along a path

    16.23. Functions

        16.23.1. Predicates
        16.23.2. Scalar functions
        16.23.3. Iterable functions
        16.23.4. Mathematical functions

    16.24. Compatibility

17. Graph Algorithms

    17.1. Introduction

18. Neo4j Server

    18.1. Server Installation

        18.1.1. As a Windows service
        18.1.2. Linux Service
        18.1.3. Mac OSX
        18.1.4. Multiple Server instances on one machine

    18.2. Server Configuration

        18.2.1. Important server configurations parameters
        18.2.2. Neo4j Database performance configuration
        18.2.3. Server logging configuration
        18.2.4. HTTP logging configuration
        18.2.5. Other configuration options

    18.3. Setup for remote debugging
    18.4. Using the server (including web administration) with an embedded
        database

        18.4.1. Getting the libraries
        18.4.2. Starting the Server from Java
        18.4.3. Providing custom configuration

    18.5. Server Performance Tuning

        18.5.1. Specifying Neo4j tuning properties
        18.5.2. Specifying JVM tuning properties

    18.6. Server Installation in the Cloud

        18.6.1. Heroku

19. REST API

    19.1. Service root

        19.1.1. Get service root

    19.2. Nodes

        19.2.1. Create Node
        19.2.2. Create Node with properties
        19.2.3. Get node
        19.2.4. Get non-existent node
        19.2.5. Delete node
        19.2.6. Nodes with relationships can not be deleted

    19.3. Relationships

        19.3.1. Get Relationship by ID
        19.3.2. Create relationship
        19.3.3. Create a relationship with properties
        19.3.4. Delete relationship
        19.3.5. Get all properties on a relationship
        19.3.6. Set all properties on a relationship
        19.3.7. Get single property on a relationship
        19.3.8. Set single property on a relationship
        19.3.9. Get all relationships
        19.3.10. Get incoming relationships
        19.3.11. Get outgoing relationships
        19.3.12. Get typed relationships
        19.3.13. Get relationships on a node without relationships

    19.4. Relationship types

        19.4.1. Get relationship types

    19.5. Node properties

        19.5.1. Set property on node
        19.5.2. Update node properties
        19.5.3. Get properties for node
        19.5.4. Property values can not be null
        19.5.5. Property values can not be nested
        19.5.6. Delete all properties from node
        19.5.7. Delete a named property from a node

    19.6. Relationship properties

        19.6.1. Update relationship properties
        19.6.2. Remove property from a relationship
        19.6.3. Remove non-existent property from a relationship
        19.6.4. Remove properties from a non-existing relationship
        19.6.5. Remove property from a non-existing relationship

    19.7. Indexes

        19.7.1. Create node index
        19.7.2. Create node index with configuration
        19.7.3. Delete node index
        19.7.4. List node indexes
        19.7.5. Add node to index
        19.7.6. Remove all entries with a given node from an index
        19.7.7. Remove all entries with a given node and key from an index
        19.7.8. Remove all entries with a given node, key and value from an
            index
        19.7.9. Find node by exact match
        19.7.10. Find node by query

    19.8. Unique Indexes

        19.8.1. Create a unique node in an index
        19.8.2. Create a unique node in an index (the case where it exists)
        19.8.3. Add a node to an index unless a node already exists for the
            given mapping
        19.8.4. Create a unique relationship in an index
        19.8.5. Add a relationship to an index unless a relationship already
            exists for the given mapping

    19.9. Automatic Indexes

        19.9.1. Find node by exact match from an automatic index
        19.9.2. Find node by query from an automatic index

    19.10. Configurable Automatic Indexing

        19.10.1. Create an auto index for nodes with specific configuration
        19.10.2. Create an auto index for relationships with specific
            configuration
        19.10.3. Get current status for autoindexing on nodes
        19.10.4. Enable node autoindexing
        19.10.5. Lookup list of properties being autoindexed
        19.10.6. Add a property for autoindexing on nodes
        19.10.7. Remove a property for autoindexing on nodes

    19.11. Traversals

        19.11.1. Traversal using a return filter
        19.11.2. Return relationships from a traversal
        19.11.3. Return paths from a traversal
        19.11.4. Traversal returning nodes below a certain depth
        19.11.5. Creating a paged traverser
        19.11.6. Paging through the results of a paged traverser
        19.11.7. Paged traverser page size
        19.11.8. Paged traverser timeout

    19.12. Cypher queries

        19.12.1. Send a Query
        19.12.2. Return paths
        19.12.3. Send queries with parameters
        19.12.4. Nested results
        19.12.5. Server errors

    19.13. Built-in Graph Algorithms

        19.13.1. Find all shortest paths
        19.13.2. Find one of the shortest paths between nodes
        19.13.3. Execute a Dijkstra algorithm with similar weights on
            relationships
        19.13.4. Execute a Dijkstra algorithm with weights on relationships

    19.14. Batch operations

        19.14.1. Execute multiple operations in batch
        19.14.2. Refer to items created earlier in the same batch job
        19.14.3. Execute multiple operations in batch streaming

    19.15. WADL Support
    19.16. Cypher Plugin

        19.16.1. Send a Query
        19.16.2. Return paths
        19.16.3. Send queries with parameters
        19.16.4. Server errors

    19.17. Gremlin Plugin

        19.17.1. Send a Gremlin Script - URL encoded
        19.17.2. Load a sample graph
        19.17.3. Sort a result using raw Groovy operations
        19.17.4. Send a Gremlin Script - JSON encoded with table results
        19.17.5. Returning nested pipes
        19.17.6. Set script variables
        19.17.7. Send a Gremlin Script with variables in a JSON Map
        19.17.8. Return paths from a Gremlin script
        19.17.9. Send an arbitrary Groovy script - Lucene sorting
        19.17.10. Emit a sample graph
        19.17.11. HyperEdges - find user roles in groups
        19.17.12. Group count
        19.17.13. Collect multiple traversal results
        19.17.14. Collaborative filtering
        19.17.15. Chunking and offsetting in Gremlin
        19.17.16. Modify the graph while traversing
        19.17.17. Flow algorithms with Gremlin
        19.17.18. Script execution errors

20. Python embedded bindings

    20.1. Installation

        20.1.1. Installation on OSX/Linux
        20.1.2. Installation on Windows

    20.2. Core API

        20.2.1. Getting started
        20.2.2. Transactions
        20.2.3. Nodes
        20.2.4. Relationships
        20.2.5. Properties
        20.2.6. Paths

    20.3. Indexes

        20.3.1. Index management
        20.3.2. Indexing things
        20.3.3. Searching the index

    20.4. Cypher Queries

        20.4.1. Querying and reading the result
        20.4.2. Parameterized and prepared queries

    20.5. Traversals

        20.5.1. Basic traversals
        20.5.2. Traversal results
        20.5.3. Uniqueness
        20.5.4. Ordering
        20.5.5. Evaluators - advanced filtering

Chapter 12. Capabilities

12.1. Data Security

Some data may need to be protected from unauthorized access (e.g., theft,
modification). Neo4j does not deal with data encryption explicitly, but
supports all means built into the Java programming language and the JVM to
protect data by encrypting it before storing.

Furthermore, data can be easily secured by running on an encrypted datastore at
the file system level. Finally, data protection should be considered in the
upper layers of the surrounding system in order to prevent problems with
scraping, malicious data insertion, and other threats.

12.2. Data Integrity

In order to keep data consistent, there needs to be mechanisms and structures
that guarantee the integrity of all stored data. In Neo4j, data integrity is
maintained for the core graph engine together with other data sources - see
below.

12.2.1. Core Graph Engine

In Neo4j, the whole data model is stored as a graph on disk and persisted as
part of every committed transaction. In the storage layer, Relationships,
Nodes, and Properties have direct pointers to each other. This maintains
integrity without the need for data duplication between the different backend
store files.

12.2.2. Different Data Sources

In a number of scenarios, the core graph engine is combined with other systems
in order to achieve optimal performance for non-graph lookups. For example,
Apache Lucene is frequently used as an additional index system for text queries
that would otherwise be very processing-intensive in the graph layer.

To keep these external systems in synchronization with each other, Neo4j
provides full Two Phase Commit transaction management, with rollback support
over all data sources. Thus, failed index insertions into Lucene can be
transparently rolled back in all data sources and thus keep data up-to-date.

12.3. Data Integration

Most enterprises rely primarily on relational databases to store their data,
but this may cause performance limitations. In some of these cases, Neo4j can
be used as an extension to supplement search/lookup for faster decision making.
However, in any situation where multiple data repositories contain the same
data, synchronization can be an issue.

In some applications, it is acceptable for the search platform to be slightly
out of sync with the relational database. In others, tight data integrity (eg.,
between Neo4j and RDBMS) is necessary. Typically, this has to be addressed for
data changing in real-time and for bulk data changes happening in the RDBMS.

A few strategies for synchronizing integrated data follows.

12.3.1. Event-based Synchronization

In this scenario, all data stores, both RDBMS and Neo4j, are fed with
domain-specific events via an event bus. Thus, the data held in the different
backends is not actually synchronized but rather replicated.

12.3.2. Periodic Synchronization

Another viable scenario is the periodic export of the latest changes in the
RDBMS to Neo4j via some form of SQL query. This allows a small amount of
latency in the synchronization, but has the advantage of using the RDBMS as the
master for all data purposes. The same process can be applied with Neo4j as the
master data source.

12.3.3. Periodic Full Export/Import of Data

Using the Batch Inserter tools for Neo4j, even large amounts of data can be
imported into the database in very short times. Thus, a full export from the
RDBMS and import into Neo4j becomes possible. If the propagation lag between
the RDBMS and Neo4j is not a big issue, this is a very viable solution.

12.4. Availability and Reliability

Most mission-critical systems require the database subsystem to be accessible
at all times. Neo4j ensures availability and reliability through a few
different strategies.

12.4.1. Operational Availability

In order not to create a single point of failure, Neo4j supports different
approaches which provide transparent fallback and/or recovery from failures.

12.4.1.1. Online backup (Cold spare)

In this approach, a single instance of the master database is used, with Online
Backup enabled. In case of a failure, the backup files can be mounted onto a
new Neo4j instance and reintegrated into the application.

12.4.1.2. Online Backup High Availability (Hot spare)

Here, a Neo4j "backup" instance listens to online transfers of changes from the
master. In the event of a failure of the master, the backup is already running
and can directly take over the load.

12.4.1.3. High Availability cluster

This approach uses a cluster of database instances, with one (read/write)
master and a number of (read-only) slaves. Failing slaves can simply be
restarted and brought back online. Alternatively, a new slave may be added by
cloning an existing one. Should the master instance fail, a new master will be
elected by the remaining cluster nodes.

12.4.2. Disaster Recovery/ Resiliency

In cases of a breakdown of major part of the IT infrastructure, there need to
be mechanisms in place that enable the fast recovery and regrouping of the
remaining services and servers. In Neo4j, there are different components that
are suitable to be part of a disaster recovery strategy.

12.4.2.1. Prevention

  * Online Backup High Availability to other locations outside the current data
    center.
  * Online Backup to different file system locations: this is a simpler form of
    backup, applying changes directly to backup files; it is thus more suited
    for local backup scenarios.
  * Neo4j High Availability cluster: a cluster of one write-master Neo4j server
    and a number of read-slaves, getting transaction logs from the master.
    Write-master failover is handled by quorum election among the read-slaves
    for a new master.

12.4.2.2. Detection

  * SNMP and JMX monitoring can be used for the Neo4j database.

12.4.2.3. Correction

  * Online Backup: A new Neo4j server can be started directly on the backed-up
    files and take over new requests.
  * Neo4j High Availability cluster: A broken Neo4j read slave can be
    reinserted into the cluster, getting the latest updates from the master.
    Alternatively, a new server can be inserted by copying an existing server
    and applying the latest updates to it.

12.5. Capacity

12.5.1. File Sizes

Neo4j relies on Java’s Non-blocking I/O subsystem for all file handling.
Furthermore, while the storage file layout is optimized for interconnected
data, Neo4j does not require raw devices. Thus, filesizes are only limited by
the underlying operating system’s capacity to handle large files. Physically,
there is no built-in limit of the file handling capacity in Neo4j.

Neo4j tries to memory-map as much of the underlying store files as possible. If
the available RAM is not sufficient to keep all data in RAM, Neo4j will use
buffers in some cases, reallocating the memory-mapped high-performance I/O
windows to the regions with the most I/O activity dynamically. Thus, ACID speed
degrades gracefully as RAM becomes the limiting factor.

12.5.2. Read speed

Enterprises want to optimize the use of hardware to deliver the maximum
business value from available resources. Neo4j’s approach to reading data
provides the best possible usage of all available hardware resources. Neo4j
does not block or lock any read operations; thus, there is no danger for
deadlocks in read operations and no need for read transactions. With a threaded
read access to the database, queries can be run simultaneously on as many
processors as may be available. This provides very good scale-up scenarios with
bigger servers.

12.5.3. Write speed

Write speed is a consideration for many enterprise applications. However, there
are two different scenarios:

 1. sustained continuous operation and
 2. bulk access (e.g., backup, initial or batch loading).

To support the disparate requirements of these scenarios, Neo4j supports two
modes of writing to the storage layer.

In transactional, ACID-compliant normal operation, isolation level is
maintained and read operations can occur at the same time as the writing
process. At every commit, the data is persisted to disk and can be recovered to
a consistent state upon system failures. This requires disk write access and a
real flushing of data. Thus, the write speed of Neo4j on a single server in
continuous mode is limited by the I/O capacity of the hardware. Consequently,
the use of fast SSDs is highly recommended for production scenarios.

Neo4j has a Batch Inserter that operates directly on the store files. This mode
does not provide transactional security, so it can only be used when there is a
single write thread. Because data is written sequentially, and never flushed to
the logical logs, huge performance boosts are achieved. The Batch Inserter is
optimized for non-transactional bulk import of large amounts of data.

12.5.4. Data size

In Neo4j, data size is mainly limited by the address space of the primary keys
for Nodes, Relationships, Properties and RelationshipTypes. Currently, the
address space is as follows:

  * 2ˆ35 (~ 34 billion) nodes
  * 2ˆ35 (~ 34 billion) relationships
  * 2ˆ36 (~ 68 billion) properties
  * 2ˆ15 (~ 32 000) relationship types

Chapter 13. Transaction Management

In order to fully maintain data integrity and ensure good transactional
behavior, Neo4j supports the ACID properties:

  * atomicity - if any part of a transaction fails, the database state is left
    unchanged
  * consistency - any transaction will leave the database in a consistent state
  * isolation - during a transaction, modified data cannot be accessed by other
    operations
  * durability - the DBMS can always recover the results of a committed
    transaction

Specifically:

  * All modifications to Neo4j data must be wrapped in transactions.
  * The default isolation level is READ_COMMITTED.
  * Data retrieved by traversals is not protected from modification by other
    transactions.
  * Non-repeatable reads may occur (i.e., only write locks are acquired and
    held until the end of the transaction).
  * One can manually acquire write locks on nodes and relationships to achieve
    higher level of isolation (SERIALIZABLE).
  * Locks are acquired at the Node and Relationship level.
  * Deadlock detection is built into the core transaction management.

13.1. Interaction cycle

All write operations that work with the graph must be performed in a
transaction. Transactions are thread confined and can be nested as “flat nested
transactions”. Flat nested transactions means that all nested transactions are
added to the scope of the top level transaction. A nested transaction can mark
the top level transaction for rollback, meaning the entire transaction will be
rolled back. To only rollback changes made in a nested transaction is not
possible.

When working with transactions the interaction cycle looks like this:

 1. Begin a transaction.
 2. Operate on the graph performing write operations.
 3. Mark the transaction as successful or not.
 4. Finish the transaction.

It is very important to finish each transaction. The transaction will not
release the locks or memory it has acquired until it has been finished. The
idiomatic use of transactions in Neo4j is to use a try-finally block, starting
the transaction and then try to perform the write operations. The last
operation in the try block should mark the transaction as successful while the
finally block should finish the transaction. Finishing the transaction will
perform commit or rollback depending on the success status.

Caution

All modifications performed in a transaction are kept in memory. This means
that very large updates have to be split into several top level transactions to
avoid running out of memory. It must be a top level transaction since splitting
up the work in many nested transactions will just add all the work to the top
level transaction.

In an environment that makes use of thread pooling other errors may occur when
failing to finish a transaction properly. Consider a leaked transaction that
did not get finished properly. It will be tied to a thread and when that thread
gets scheduled to perform work starting a new (what looks to be a) top level
transaction it will actually be a nested transaction. If the leaked transaction
state is “marked for rollback” (which will happen if a deadlock was detected)
no more work can be performed on that transaction. Trying to do so will result
in error on each call to a write operation.

13.2. Isolation levels

By default a read operation will read the last committed value unless a local
modification within the current transaction exist. The default isolation level
is very similar to READ_COMMITTED: reads do not block or take any locks so
non-repeatable reads can occur. It is possible to achieve a stronger isolation
level (such as REPETABLE_READ and SERIALIZABLE) by manually acquiring read and
write locks.

13.3. Default locking behavior

  * When adding, changing or removing a property on a node or relationship a
    write lock will be taken on the specific node or relationship.
  * When creating or deleting a node a write lock will be taken for the
    specific node.
  * When creating or deleting a relationship a write lock will be taken on the
    specific relationship and both its nodes.

The locks will be added to the transaction and released when the transaction
finishes.

13.4. Deadlocks

Since locks are used it is possible for deadlocks to happen. Neo4j will however
detect any deadlock (caused by acquiring a lock) before they happen and throw
an exception. Before the exception is thrown the transaction is marked for
rollback. All locks acquired by the transaction are still being held but will
be released when the transaction is finished (in the finally block as pointed
out earlier). Once the locks are released other transactions that were waiting
for locks held by the transaction causing the deadlock can proceed. The work
performed by the transaction causing the deadlock can then be retried by the
user if needed.

Experiencing frequent deadlocks is an indication of concurrent write requests
happening in such a way that it is not possible to execute them while at the
same time live up to the intended isolation and consistency. The solution is to
make sure concurrent updates happen in a reasonable way. For example given two
specific nodes (A and B), adding or deleting relationships to both these nodes
in random order for each transaction will result in deadlocks when there are
two or more transactions doing that concurrently. One solution is to make sure
that updates always happens in the same order (first A then B). Another
solution is to make sure that each thread/transaction does not have any
conflicting writes to a node or relationship as some other concurrent
transaction. This can for example be achieved by letting a single thread do all
updates of a specific type.

Important

Deadlocks caused by the use of other synchronization than the locks managed by
Neo4j can still happen. Since all operations in the Neo4j API are thread safe
unless specified otherwise, there is no need for external synchronization.
Other code that requires synchronization should be synchronized in such a way
that it never performs any Neo4j operation in the synchronized block.

13.5. Delete semantics

When deleting a node or a relationship all properties for that entity will be
automatically removed but the relationships of a node will not be removed.

Caution

Neo4j enforces a constraint (upon commit) that all relationships must have a
valid start node and end node. In effect this means that trying to delete a
node that still has relationships attached to it will throw an exception upon
commit. It is however possible to choose in which order to delete the node and
the attached relationships as long as no relationships exist when the
transaction is committed.

The delete semantics can be summarized in the following bullets:

  * All properties of a node or relationship will be removed when it is
    deleted.
  * A deleted node can not have any attached relationships when the transaction
    commits.
  * It is possible to acquire a reference to a deleted relationship or node
    that has not yet been committed.
  * Any write operation on a node or relationship after it has been deleted
    (but not yet committed) will throw an exception
  * After commit trying to acquire a new or work with an old reference to a
    deleted node or relationship will throw an exception.

13.6. Creating unique nodes

In many use cases, a certain level of uniqueness is desired among entities. You
could for instance imagine that only one user with a certain e-mail address may
exist in a system. If multiple concurrent threads naively try to create the
user, duplicates will be created. There are three main strategies for ensuring
uniqueness, and they all work across HA and single-instance deployments.

13.6.1. Single thread

By using a single thread, no two threads will even try to create a particular
entity simultaneously. On HA, an external single-threaded client can perform
the operations on the cluster.

13.6.2. Get or create

By using put-if-absent <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/
neo4j/graphdb/index/Index.html#
putIfAbsent%28T,%20java.lang.String,%20java.lang.Object%29> functionality,
entity uniqueness can be guaranteed using an index. Here the index acts as the
lock and will only lock the smallest part needed to guaranteed uniqueness
across threads and transactions. To get the more high-level get-or-create
functionality make use of UniqueFactory <http://components.neo4j.org/neo4j/
1.8.M04/apidocs/org/neo4j/graphdb/index/UniqueFactory.html> as seen in the
example below.

Example code:

public Node getOrCreateUserWithUniqueFactory( String username, GraphDatabaseService graphDb )
{
    UniqueFactory<Node> factory = new UniqueFactory.UniqueNodeFactory( graphDb, "users" )
    {
        @Override
        protected void initialize( Node created, Map<String, Object> properties )
        {
            created.setProperty( "name", properties.get( "name" ) );
        }
    };

    return factory.getOrCreate( "name", username );
}

13.6.3. Pessimistic locking

Important

While this is a working solution, please consider using the preferred
Section 13.6.2, “Get or create” instead.

By using explicit, pessimistic locking, unique creation of entities can be
achieved in a multi-threaded environment. It is most commonly done by locking
on a single or a set of common nodes.

One might be tempted to use Java synchronization for this, but it is dangerous.
By mixing locks in the Neo4j kernel and in the Java runtime, it is easy to
produce deadlocks that are not detectable by Neo4j. As long as all locking is
done by Neo4j, all deadlocks will be detected and avoided. Also, a solution
using manual synchronization doesn’t ensure uniqueness in an HA environment.

Example code:

public Node getOrCreateUserPessimistically( String username, GraphDatabaseService graphDb, Node lockNode )
{
    Index<Node> usersIndex = graphDb.index().forNodes( "users" );
    Node userNode = usersIndex.get( "name", username ).getSingle();
    if ( userNode != null ) return userNode;
    Transaction tx = graphDb.beginTx();
    try
    {
        tx.acquireWriteLock( lockNode );
        userNode = usersIndex.get( "name", username ).getSingle();
        if ( userNode == null )
        {
            userNode = graphDb.createNode();
            userNode.setProperty( "name", username );
            usersIndex.add( userNode, "name", username );
        }
        tx.success();
        return userNode;
    }
    finally
    {
        tx.finish();
    }
}

13.7. Transaction events

Transaction event handlers can be registered to receive Neo4j Transaction
events. Once it has been registered at a GraphDatabaseService instance it will
receive events about what has happened in each transaction which is about to be
committed. Handlers won’t get notified about transactions which haven’t
performed any write operation or won’t be committed (either if Transaction#
success() hasn’t been called or the transaction has been marked as failed
Transaction#failure(). Right before a transaction is about to be committed the
beforeCommit method is called with the entire diff of modifications made in the
transaction. At this point the transaction is still running so changes can
still be made. However there’s no guarantee that other handlers will see such
changes since the order in which handlers are executed is undefined. This
method can also throw an exception and will, in such a case, prevent the
transaction from being committed (where a call to afterRollback will follow).
If beforeCommit is successfully executed the transaction will be committed and
the afterCommit method will be called with the same transaction data as well as
the object returned from beforeCommit. This assumes that all other handlers (if
more were registered) also executed beforeCommit successfully.

Chapter 14. Data Import

For high-performance data import, the batch insert facilities described in this
chapter are recommended.

Other ways to import data into Neo4j include using Gremlin graph import (see
Section 19.17.2, “Load a sample graph”) or using the Geoff notation (see http:/
/geoff.nigelsmall.net/ <http://geoff.nigelsmall.net/>).

14.1. Batch Insertion

Neo4j has a batch insertion facility intended for initial imports, which
bypasses transactions and other checks in favor of performance. This is useful
when you have a big dataset that needs to be loaded once.

Batch insertion is inlcuded in the neo4j-kernel <http://search.maven.org/#
search|ga|1|neo4j-kernel> component, which is part of all Neo4j distributions
and editions.

Be aware of the following points when using batch insertion:

  * The intended use is for initial import of data.
  * Batch insertion is not thread safe.
  * Batch insertion is non-transactional.
  * Unless shutdown is successfully invoked at the end of the import, the
    database files will be corrupt.

Warning

Always perform batch insertion in a single thread (or use synchronization to
make only one thread at a time access the batch inserter) and invoke shutdown
when finished.

14.1.1. Batch Inserter Examples

Creating a batch inserter is similar to how you normally create data in the
database, but in this case the low-level BatchInserter <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/unsafe/batchinsert/
BatchInserter.html> interface is used. As we have already pointed out, you
can’t have multiple threads using the batch inserter concurrently without
external synchronization.

Tip

The source code of the examples is found here: BatchInsertExampleTest.java
<https://github.com/neo4j/community/blob/1.8.M04/kernel/src/test/java/examples/
BatchInsertExampleTest.java>

To get hold of a BatchInseter, use BatchInserters <http://components.neo4j.org/
neo4j/1.8.M04/apidocs/org/neo4j/unsafe/batchinsert/BatchInserters.html> and
then go from there:

BatchInserter inserter = BatchInserters.inserter( "target/batchinserter-example" );
Map<String, Object> properties = new HashMap<String, Object>();
properties.put( "name", "Mattias" );
long mattiasNode = inserter.createNode( properties );
properties.put( "name", "Chris" );
long chrisNode = inserter.createNode( properties );
RelationshipType knows = DynamicRelationshipType.withName( "KNOWS" );
// To set properties on the relationship, use a properties map
// instead of null as the last parameter.
inserter.createRelationship( mattiasNode, chrisNode, knows, null );
inserter.shutdown();

To gain good performance you probably want to set some configuration settings
for the batch inserter. Read Section 22.7.2, “Batch insert example” for
information on configuring a batch inserter. This is how to start a batch
inserter with configuration options:

Map<String, String> config = new HashMap<String, String>();
config.put( "neostore.nodestore.db.mapped_memory", "90M" );
BatchInserter inserter = BatchInserters.inserter(
        "target/batchinserter-example-config", config );
// Insert data here ... and then shut down:
inserter.shutdown();

In case you have stored the configuration in a file, you can load it like this:

Map<String, String> config = MapUtil.load( new File(
        "target/batchinsert-config" ) );
BatchInserter inserter = BatchInserters.inserter(
        "target/batchinserter-example-config", config );
// Insert data here ... and then shut down:
inserter.shutdown();

14.1.2. Batch Graph Database

In case you already have code for data import written against the normal Neo4j
API, you could consider using a batch inserter exposing that API.

Note

This will not perform as good as using the BatchInserter API directly.

Also be aware of the following:

  * Starting a transaction or invoking Transaction.finish() or
    Transaction.success() will do nothing.
  * Invoking the Transaction.failure() method will generate a NotInTransaction
    exception.
  * Node.delete() and Node.traverse() are not supported.
  * Relationship.delete() is not supported.
  * Event handlers and indexes are not supported.
  * GraphDatabaseService.getRelationshipTypes(), getAllNodes() and
    getAllRelationships() are not supported.

With these precautions in mind, this is how to do it:

GraphDatabaseService batchDb =
        BatchInserters.batchDatabase( "target/batchdb-example" );
Node mattiasNode = batchDb.createNode();
mattiasNode.setProperty( "name", "Mattias" );
Node chrisNode = batchDb.createNode();
chrisNode.setProperty( "name", "Chris" );
RelationshipType knows = DynamicRelationshipType.withName( "KNOWS" );
mattiasNode.createRelationshipTo( chrisNode, knows );
batchDb.shutdown();

Tip

The source code of the example is found here: BatchInsertExampleTest.java
<https://github.com/neo4j/community/blob/1.8.M04/kernel/src/test/java/examples/
BatchInsertExampleTest.java>

14.1.3. Index Batch Insertion

For general notes on batch insertion, see Section 14.1, “Batch Insertion”.

Indexing during batch insertion is done using BatchInserterIndex <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/unsafe/batchinsert/
BatchInserterIndex.html> which are provided via BatchInserterIndexProvider
<http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/unsafe/batchinsert
/BatchInserterIndexProvider.html>. An example:

BatchInserter inserter = BatchInserters.inserter( "target/neo4jdb-batchinsert" );
BatchInserterIndexProvider indexProvider =
        new LuceneBatchInserterIndexProvider( inserter );
BatchInserterIndex actors =
        indexProvider.nodeIndex( "actors", MapUtil.stringMap( "type", "exact" ) );
actors.setCacheCapacity( "name", 100000 );

Map<String, Object> properties = MapUtil.map( "name", "Keanu Reeves" );
long node = inserter.createNode( properties );
actors.add( node, properties );

//make the changes visible for reading, use this sparsely, requires IO!
actors.flush();

// Make sure to shut down the index provider as well
indexProvider.shutdown();
inserter.shutdown();

The configuration parameters are the same as mentioned in Section 15.10,
“Configuration and fulltext indexes”.

14.1.3.1. Best practices

Here are some pointers to get the most performance out of BatchInserterIndex:

  * Try to avoid flushing <http://components.neo4j.org/neo4j/1.8.M04/apidocs/
    org/neo4j/unsafe/batchinsert/BatchInserterIndex.html#flush%28%29> too often
    because each flush will result in all additions (since last flush) to be
    visible to the querying methods, and publishing those changes can be a
    performance penalty.
  * Have (as big as possible) phases where one phase is either only writes or
    only reads, and don’t forget to flush after a write phase so that those
    changes becomes visible to the querying methods.
  * Enable caching <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j
    /unsafe/batchinsert/BatchInserterIndex.html#
    setCacheCapacity%28java.lang.String,%20int%29> for keys you know you’re
    going to do lookups for later on to increase performance significantly
    (though insertion performance may degrade slightly).

Note

Changes to the index are available for reading first after they are flushed to
disk. Thus, for optimal performance, read and lookup operations should be kept
to a minimum during batchinsertion since they involve IO and impact speed
negatively.

Chapter 15. Indexing

Indexing in Neo4j can be done in two different ways:

 1. The database itself is a natural index consisting of its relationships of
    different types between nodes. For example a tree structure can be layered
    on top of the data and used for index lookups performed by a traverser.
 2. Separate index engines can be used, with Apache Lucene <http://
    lucene.apache.org/java/3_5_0/index.html> being the default backend included
    with Neo4j.

This chapter demonstrate how to use the second type of indexing, focusing on
Lucene.

15.1. Introduction

Indexing operations are part of the Neo4j index API <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/
package-summary.html>.

Each index is tied to a unique, user-specified name (for example "first_name"
or "books") and can index either nodes <http://components.neo4j.org/neo4j/
1.8.M04/apidocs/org/neo4j/graphdb/Node.html> or relationships <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
Relationship.html>.

The default index implementation is provided by the neo4j-lucene-index
component, which is included in the standard Neo4j download. It can also be
downloaded separately from http://repo1.maven.org/maven2/org/neo4j/
neo4j-lucene-index/ <http://repo1.maven.org/maven2/org/neo4j/neo4j-lucene-index
/> . For Maven users, the neo4j-lucene-index component has the coordinates
org.neo4j:neo4j-lucene-index and should be used with the same version of
org.neo4j:neo4j-kernel. Different versions of the index and kernel components
are not compatible in the general case. Both components are included
transitively by the org.neo4j:neo4j:pom artifact which makes it simple to keep
the versions in sync.

For initial import of data using indexes, see Section 14.1.3, “Index Batch
Insertion”.

Note

All modifying index operations must be performed inside a transaction, as with
any mutating operation in Neo4j.

15.2. Create

An index is created if it doesn’t exist when you ask for it. Unless you give it
a custom configuration, it will be created with default configuration and
backend.

To set the stage for our examples, let’s create some indexes to begin with:

IndexManager index = graphDb.index();
Index<Node> actors = index.forNodes( "actors" );
Index<Node> movies = index.forNodes( "movies" );
RelationshipIndex roles = index.forRelationships( "roles" );

This will create two node indexes and one relationship index with default
configuration. See Section 15.8, “Relationship indexes” for more information
specific to relationship indexes.

See Section 15.10, “Configuration and fulltext indexes” for how to create 
fulltext indexes.

You can also check if an index exists like this:

IndexManager index = graphDb.index();
boolean indexExists = index.existsForNodes( "actors" );

15.3. Delete

Indexes can be deleted. When deleting, the entire contents of the index will be
removed as well as its associated configuration. A new index can be created
with the same name at a later point in time.

IndexManager index = graphDb.index();
Index<Node> actors = index.forNodes( "actors" );
actors.delete();

Note that the actual deletion of the index is made during the commit of the
surrounding transaction. Calls made to such an index instance after delete()
<http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/
Index.html#delete%28%29> has been called are invalid inside that transaction as
well as outside (if the transaction is successful), but will become valid again
if the transaction is rolled back.

15.4. Add

Each index supports associating any number of key-value pairs with any number
of entities (nodes or relationships), where each association between entity and
key-value pair is performed individually. To begin with, let’s add a few nodes
to the indexes:

// Actors
Node reeves = graphDb.createNode();
reeves.setProperty( "name", "Keanu Reeves" );
actors.add( reeves, "name", reeves.getProperty( "name" ) );
Node bellucci = graphDb.createNode();
bellucci.setProperty( "name", "Monica Bellucci" );
actors.add( bellucci, "name", bellucci.getProperty( "name" ) );
// multiple values for a field, in this case for search only
// and not stored as a property.
actors.add( bellucci, "name", "La Bellucci" );
// Movies
Node theMatrix = graphDb.createNode();
theMatrix.setProperty( "title", "The Matrix" );
theMatrix.setProperty( "year", 1999 );
movies.add( theMatrix, "title", theMatrix.getProperty( "title" ) );
movies.add( theMatrix, "year", theMatrix.getProperty( "year" ) );
Node theMatrixReloaded = graphDb.createNode();
theMatrixReloaded.setProperty( "title", "The Matrix Reloaded" );
theMatrixReloaded.setProperty( "year", 2003 );
movies.add( theMatrixReloaded, "title", theMatrixReloaded.getProperty( "title" )  );
movies.add( theMatrixReloaded, "year", 2003 );
Node malena = graphDb.createNode();
malena.setProperty( "title", "Malèna" );
malena.setProperty( "year", 2000 );
movies.add( malena, "title", malena.getProperty( "title" ) );
movies.add( malena, "year", malena.getProperty( "year" ) );

Note that there can be multiple values associated with the same entity and key.

Next up, we’ll create relationships and index them as well:

// we need a relationship type
DynamicRelationshipType ACTS_IN = DynamicRelationshipType.withName( "ACTS_IN" );
// create relationships
Relationship role1 = reeves.createRelationshipTo( theMatrix, ACTS_IN );
role1.setProperty( "name", "Neo" );
roles.add( role1, "name", role1.getProperty( "name" ) );
Relationship role2 = reeves.createRelationshipTo( theMatrixReloaded, ACTS_IN );
role2.setProperty( "name", "Neo" );
roles.add( role2, "name", role2.getProperty( "name" ) );
Relationship role3 = bellucci.createRelationshipTo( theMatrixReloaded, ACTS_IN );
role3.setProperty( "name", "Persephone" );
roles.add( role3, "name", role3.getProperty( "name" ) );
Relationship role4 = bellucci.createRelationshipTo( malena, ACTS_IN );
role4.setProperty( "name", "Malèna Scordia" );
roles.add( role4, "name", role4.getProperty( "name" ) );

After these operations, our example graph looks like this:

Figure 15.1. Movie and Actor Graph

Movie-and-Actor-Graph-initial.svg


15.5. Remove

Removing <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
index/Index.html#remove%28T,%20java.lang.String,%20java.lang.Object%29> from an
index is similar to adding, but can be done by supplying one of the following
combinations of arguments:

  * entity
  * entity, key
  * entity, key, value

// completely remove bellucci from the actors index
actors.remove( bellucci );
// remove any "name" entry of bellucci from the actors index
actors.remove( bellucci, "name" );
// remove the "name" -> "La Bellucci" entry of bellucci
actors.remove( bellucci, "name", "La Bellucci" );

15.6. Update

Important

To update an index entry, the old one must be removed and a new one added. For
details on removing index entries, see Section 15.5, “Remove”.

Remember that a node or relationship can be associated with any number of
key-value pairs in an index. This means that you can index a node or
relationship with many key-value pairs that have the same key. In the case
where a property value changes and you’d like to update the index, it’s not
enough to just index the new value - you’ll have to remove the old value as
well.

Here’s a code example for that demonstrates how it’s done:

// create a node with a property
// so we have something to update later on
Node fishburn = graphDb.createNode();
fishburn.setProperty( "name", "Fishburn" );
// index it
actors.add( fishburn, "name", fishburn.getProperty( "name" ) );
// update the index entry
// when the property value changes
actors.remove( fishburn, "name", fishburn.getProperty( "name" ) );
fishburn.setProperty( "name", "Laurence Fishburn" );
actors.add( fishburn, "name", fishburn.getProperty( "name" ) );

15.7. Search

An index can be searched in two ways, get <http://components.neo4j.org/neo4j/
1.8.M04/apidocs/org/neo4j/graphdb/index/Index.html#
get%28java.lang.String,%20java.lang.Object%29> and query <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/Index.html#
query%28java.lang.String,%20java.lang.Object%29>. The get method will return
exact matches to the given key-value pair, whereas query exposes querying
capabilities directly from the backend used by the index. For example the
Lucene query syntax <http://lucene.apache.org/java/3_5_0/
queryparsersyntax.html> can be used directly with the default indexing backend.

15.7.1. Get

This is how to search for a single exact match:

IndexHits<Node> hits = actors.get( "name", "Keanu Reeves" );
Node reeves = hits.getSingle();

IndexHits <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
index/IndexHits.html> is an Iterable with some additional useful methods. For
example getSingle() <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/
neo4j/graphdb/index/IndexHits.html#getSingle%28%29> returns the first and only
item from the result iterator, or null if there isn’t any hit.

Here’s how to get a single relationship by exact matching and retrieve its
start and end nodes:

Relationship persephone = roles.get( "name", "Persephone" ).getSingle();
Node actor = persephone.getStartNode();
Node movie = persephone.getEndNode();

Finally, we can iterate over all exact matches from a relationship index:

for ( Relationship role : roles.get( "name", "Neo" ) )
{
    // this will give us Reeves twice
    Node reeves = role.getStartNode();
}

Important

In you don’t iterate through all the hits, IndexHits.close() <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/
IndexHits.html#close%28%29> must be called explicitly.

15.7.2. Query

There are two query methods, one which uses a key-value signature where the
value represents a query for values with the given key only. The other method
is more generic and supports querying for more than one key-value pair in the
same query.

Here’s an example using the key-query option:

for ( Node actor : actors.query( "name", "*e*" ) )
{
    // This will return Reeves and Bellucci
}

In the following example the query uses multiple keys:

for ( Node movie : movies.query( "title:*Matrix* AND year:1999" ) )
{
    // This will return "The Matrix" from 1999 only.
}

Note

Beginning a wildcard search with "*" or "?" is discouraged by Lucene, but will
nevertheless work.

Caution

You can’t have any whitespace in the search term with this syntax. See
Section 15.11.3, “Querying with Lucene Query objects” for how to do that.

15.8. Relationship indexes

An index for relationships is just like an index for nodes, extended by
providing support to constrain a search to relationships with a specific start
and/or end nodes These extra methods reside in the RelationshipIndex <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/
RelationshipIndex.html> interface which extends Index<Relationship> <http://
components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/Index.html>.

Example of querying a relationship index:

// find relationships filtering on start node
// using exact matches
IndexHits<Relationship> reevesAsNeoHits;
reevesAsNeoHits = roles.get( "name", "Neo", reeves, null );
Relationship reevesAsNeo = reevesAsNeoHits.iterator().next();
reevesAsNeoHits.close();
// find relationships filtering on end node
// using a query
IndexHits<Relationship> matrixNeoHits;
matrixNeoHits = roles.query( "name", "*eo", null, theMatrix );
Relationship matrixNeo = matrixNeoHits.iterator().next();
matrixNeoHits.close();

And here’s an example for the special case of searching for a specific
relationship type:

// find relationships filtering on end node
// using a relationship type.
// this is how to add it to the index:
roles.add( reevesAsNeo, "type", reevesAsNeo.getType().name() );
// Note that to use a compound query, we can't combine committed
// and uncommitted index entries, so we'll commit before querying:
tx.success();
tx.finish();
// and now we can search for it:
IndexHits<Relationship> typeHits;
typeHits = roles.query( "type:ACTS_IN AND name:Neo", null, theMatrix );
Relationship typeNeo = typeHits.iterator().next();
typeHits.close();

Such an index can be useful if your domain has nodes with a very large number
of relationships between them, since it reduces the search time for a
relationship between two nodes. A good example where this approach pays
dividends is in time series data, where we have readings represented as a
relationship per occurrence.

15.9. Scores

The IndexHits interface exposes scoring <http://components.neo4j.org/neo4j/
1.8.M04/apidocs/org/neo4j/graphdb/index/IndexHits.html#currentScore%28%29> so
that the index can communicate scores for the hits. Note that the result is not
sorted by the score unless you explicitly specify that. See Section 15.11.2,
“Sorting” for how to sort by score.

IndexHits<Node> hits = movies.query( "title", "The*" );
for ( Node movie : hits )
{
    System.out.println( movie.getProperty( "title" ) + " " + hits.currentScore() );
}

15.10. Configuration and fulltext indexes

At the time of creation extra configuration can be specified to control the
behavior of the index and which backend to use. For example to create a Lucene
fulltext index:

IndexManager index = graphDb.index();
Index<Node> fulltextMovies = index.forNodes( "movies-fulltext",
        MapUtil.stringMap( IndexManager.PROVIDER, "lucene", "type", "fulltext" ) );
fulltextMovies.add( theMatrix, "title", "The Matrix" );
fulltextMovies.add( theMatrixReloaded, "title", "The Matrix Reloaded" );
// search in the fulltext index
Node found = fulltextMovies.query( "title", "reloAdEd" ).getSingle();

Here’s an example of how to create an exact index which is case-insensitive:

Index<Node> index = graphDb.index().forNodes( "my-case-insensitive-index",
        stringMap( "analyzer", LowerCaseKeywordAnalyzer.class.getName() ) );

Node node = graphDb.createNode();
index.add( node, "name", "Thomas Anderson" );
assertContains( index.query( "name", "\"Thomas Anderson\"" ), node );
assertContains( index.query( "name", "\"thoMas ANDerson\"" ), node );

Tip

In order to search for tokenized words, the query method has to be used. The
get method will only match the full string value, not the tokens.

The configuration of the index is persisted once the index has been created.
The provider configuration key is interpreted by Neo4j, but any other
configuration is passed onto the backend index (e.g. Lucene) to interpret.

Table 15.1. Lucene indexing configuration parameters

Parameter     Possible values             Effect
type          exact, fulltext             exact is the default and uses a
                                          Lucene keyword analyzer <http://
                                          lucene.apache.org/java/3_5_0/api/core
                                          /org/apache/lucene/analysis/
                                          KeywordAnalyzer.html>. fulltext uses
                                          a white-space tokenizer in its
                                          analyzer.

to_lower_case true, false                 This parameter goes together with
                                          type: fulltext and converts values to
                                          lower case during both additions and
                                          querying, making the index case
                                          insensitive. Defaults to true.

analyzer      the full class name of an   Overrides the type so that a custom
              Analyzer <http://           analyzer can be used. Note:
              lucene.apache.org/java/     to_lower_case still affects
              3_5_0/api/core/org/apache/  lowercasing of string queries. If the
              lucene/analysis/            custom analyzer uppercases the
              Analyzer.html>              indexed tokens, string queries will
                                          not match as expected.


15.11. Extra features for Lucene indexes

15.11.1. Numeric ranges

Lucene supports smart indexing of numbers, querying for ranges and sorting such
results, and so does its backend for Neo4j. To mark a value so that it is
indexed as a numeric value, we can make use of the ValueContext <http://
components.neo4j.org/neo4j-lucene-index/1.8.M04/apidocs/org/neo4j/index/lucene/
ValueContext.html> class, like this:

movies.add( theMatrix, "year-numeric", new ValueContext( 1999 ).indexNumeric() );
movies.add( theMatrixReloaded, "year-numeric", new ValueContext( 2003 ).indexNumeric() );
movies.add( malena, "year-numeric",  new ValueContext( 2000 ).indexNumeric() );

int from = 1997;
int to = 1999;
hits = movies.query( QueryContext.numericRange( "year-numeric", from, to ) );

Note

The same type must be used for indexing and querying. That is, you can’t index
a value as a Long and then query the index using an Integer.

By giving null as from/to argument, an open ended query is created. In the
following example we are doing that, and have added sorting to the query as
well:

hits = movies.query(
        QueryContext.numericRange( "year-numeric", from, null )
          .sortNumeric( "year-numeric", false ) );

From/to in the ranges defaults to be inclusive, but you can change this
behavior by using two extra parameters:

movies.add( theMatrix, "score", new ValueContext( 8.7 ).indexNumeric() );
movies.add( theMatrixReloaded, "score", new ValueContext( 7.1 ).indexNumeric() );
movies.add( malena, "score", new ValueContext( 7.4 ).indexNumeric() );

// include 8.0, exclude 9.0
hits = movies.query( QueryContext.numericRange( "score", 8.0, 9.0, true, false ) );

15.11.2. Sorting

Lucene performs sorting very well, and that is also exposed in the index
backend, through the QueryContext <http://components.neo4j.org/
neo4j-lucene-index/1.8.M04/apidocs/org/neo4j/index/lucene/QueryContext.html>
class:

hits = movies.query( "title", new QueryContext( "*" ).sort( "title" ) );
for ( Node hit : hits )
{
    // all movies with a title in the index, ordered by title
}
// or
hits = movies.query( new QueryContext( "title:*" ).sort( "year", "title" ) );
for ( Node hit : hits )
{
    // all movies with a title in the index, ordered by year, then title
}

We sort the results by relevance (score) like this:

hits = movies.query( "title", new QueryContext( "The*" ).sortByScore() );
for ( Node movie : hits )
{
    // hits sorted by relevance (score)
}

15.11.3. Querying with Lucene Query objects

Instead of passing in Lucene query syntax queries, you can instantiate such
queries programmatically and pass in as argument, for example:

// a TermQuery will give exact matches
Node actor = actors.query( new TermQuery( new Term( "name", "Keanu Reeves" ) ) ).getSingle();

Note that the TermQuery <http://lucene.apache.org/java/3_5_0/api/core/org/
apache/lucene/search/TermQuery.html> is basically the same thing as using the
get method on the index.

This is how to perform wildcard searches using Lucene Query Objects:

hits = movies.query( new WildcardQuery( new Term( "title", "The Matrix*" ) ) );
for ( Node movie : hits )
{
    System.out.println( movie.getProperty( "title" ) );
}

Note that this allows for whitespace in the search string.

15.11.4. Compound queries

Lucene supports querying for multiple terms in the same query, like so:

hits = movies.query( "title:*Matrix* AND year:1999" );

Caution

Compound queries can’t search across committed index entries and those who
haven’t got committed yet at the same time.

15.11.5. Default operator

The default operator (that is whether AND or OR is used in between different
terms) in a query is OR. Changing that behavior is also done via the
QueryContext <http://components.neo4j.org/neo4j-lucene-index/1.8.M04/apidocs/
org/neo4j/index/lucene/QueryContext.html> class:

QueryContext query = new QueryContext( "title:*Matrix* year:1999" )
        .defaultOperator( Operator.AND );
hits = movies.query( query );

15.11.6. Caching

If your index lookups becomes a performance bottle neck, caching can be enabled
for certain keys in certain indexes (key locations) to speed up get requests.
The caching is implemented with an LRU <http://en.wikipedia.org/wiki/
Cache_algorithms#Least_Recently_Used> cache so that only the most recently
accessed results are cached (with "results" meaning a query result of a get
request, not a single entity). You can control the size of the cache (the
maximum number of results) per index key.

Index<Node> index = graphDb.index().forNodes( "actors" );
( (LuceneIndex<Node>) index ).setCacheCapacity( "name", 300000 );

Caution

This setting is not persisted after shutting down the database. This means: set
this value after each startup of the database if you want to keep it.

15.12. Automatic Indexing

Neo4j provides a single index for nodes and one for relationships in each
database that automatically follow property values as they are added, deleted
and changed on database primitives. This functionality is called auto indexing
and is controlled both from the database configuration Map and through its own
API.

Caution

This is an experimental feature. Expect changes in the API and do not rely on
it for production data handling.

15.12.1. Configuration

By default Auto Indexing is off for both Nodes and Relationships. To enable it
on database startup set the configuration options Config.NODE_AUTO_INDEXING and
Config.RELATIONSHIP_AUTO_INDEXING to the string "true".

If you just enable auto indexing as above, then still no property will be auto
indexed. To define which property names you want the auto indexer to monitor as
a configuration parameter, set the Config.{NODE,RELATIONSHIP}_KEYS_INDEXABLE
option to a String that is a comma separated concatenation of the property
names you want auto indexed.

/*
 * Creating the configuration, adding nodeProp1 and nodeProp2 as
 * auto indexed properties for Nodes and relProp1 and relProp2 as
 * auto indexed properties for Relationships. Only those will be
 * indexed. We also have to enable auto indexing for both these
 * primitives explicitly.
 */
GraphDatabaseService graphDb = new GraphDatabaseFactory().
    newEmbeddedDatabaseBuilder( storeDirectory ).
    setConfig( GraphDatabaseSettings.node_keys_indexable, "nodeProp1,nodeProp2" ).
    setConfig( GraphDatabaseSettings.relationship_keys_indexable, "relProp1,relProp2" ).
    setConfig( GraphDatabaseSettings.node_auto_indexing, GraphDatabaseSetting.TRUE ).
    setConfig( GraphDatabaseSettings.relationship_auto_indexing, GraphDatabaseSetting.TRUE ).
    newGraphDatabase();

Transaction tx = graphDb.beginTx();
Node node1 = null, node2 = null;
Relationship rel = null;
try
{
    // Create the primitives
    node1 = graphDb.createNode();
    node2 = graphDb.createNode();
    rel = node1.createRelationshipTo( node2,
            DynamicRelationshipType.withName( "DYNAMIC" ) );

    // Add indexable and non-indexable properties
    node1.setProperty( "nodeProp1", "nodeProp1Value" );
    node2.setProperty( "nodeProp2", "nodeProp2Value" );
    node1.setProperty( "nonIndexed", "nodeProp2NonIndexedValue" );
    rel.setProperty( "relProp1", "relProp1Value" );
    rel.setProperty( "relPropNonIndexed", "relPropValueNonIndexed" );

    // Make things persistent
    tx.success();
}
catch ( Exception e )
{
    tx.failure();
}
finally
{
    tx.finish();
}

15.12.2. Search

The usefulness of the auto indexing functionality comes of course from the
ability to actually query the index and retrieve results. To that end, you can
acquire a ReadableIndex object from the AutoIndexer that exposes all the query
and get methods of a full Index <http://components.neo4j.org/neo4j/1.8.M04/
apidocs/org/neo4j/graphdb/index/Index.html> with exactly the same
functionality. Continuing from the previous example, accessing the index is
done like this:

// Get the Node auto index
ReadableIndex<Node> autoNodeIndex = graphDb.index()
        .getNodeAutoIndexer()
        .getAutoIndex();
// node1 and node2 both had auto indexed properties, get them
assertEquals( node1,
        autoNodeIndex.get( "nodeProp1", "nodeProp1Value" ).getSingle() );
assertEquals( node2,
        autoNodeIndex.get( "nodeProp2", "nodeProp2Value" ).getSingle() );
// node2 also had a property that should be ignored.
assertFalse( autoNodeIndex.get( "nonIndexed",
        "nodeProp2NonIndexedValue" ).hasNext() );

// Get the relationship auto index
ReadableIndex<Relationship> autoRelIndex = graphDb.index()
        .getRelationshipAutoIndexer()
        .getAutoIndex();
// One property was set for auto indexing
assertEquals( rel,
        autoRelIndex.get( "relProp1", "relProp1Value" ).getSingle() );
// The rest should be ignored
assertFalse( autoRelIndex.get( "relPropNonIndexed",
        "relPropValueNonIndexed" ).hasNext() );

15.12.3. Runtime Configuration

The same options that are available during database creation via the
configuration can also be set during runtime via the AutoIndexer API.

Gaining access to the AutoIndexer API and adding two Node and one Relationship
properties to auto index is done like so:

// Start without any configuration
GraphDatabaseService graphDb = new GraphDatabaseFactory().
        newEmbeddedDatabase( storeDirectory );

// Get the Node AutoIndexer, set nodeProp1 and nodeProp2 as auto
// indexed.
AutoIndexer<Node> nodeAutoIndexer = graphDb.index()
        .getNodeAutoIndexer();
nodeAutoIndexer.startAutoIndexingProperty( "nodeProp1" );
nodeAutoIndexer.startAutoIndexingProperty( "nodeProp2" );

// Get the Relationship AutoIndexer
AutoIndexer<Relationship> relAutoIndexer = graphDb.index()
        .getRelationshipAutoIndexer();
relAutoIndexer.startAutoIndexingProperty( "relProp1" );

// None of the AutoIndexers are enabled so far. Do that now
nodeAutoIndexer.setEnabled( true );
relAutoIndexer.setEnabled( true );


Parameters to the AutoIndexers passed through the Configuration and settings
made through the API are cumulative. So you can set some beforehand known
settings, do runtime checks to augment the initial configuration and then
enable the desired auto indexers - the final configuration is the same
regardless of the method used to reach it.

15.12.4. Updating the Automatic Index

Updates to the auto indexed properties happen of course automatically as you
update them. Removal of properties from the auto index happens for two reasons.
One is that you actually removed the property. The other is that you stopped
autoindexing on a property. When the latter happens, any primitive you touch
and it has that property, it is removed from the auto index, regardless of any
operations on the property. When you start or stop auto indexing on a property,
no auto update operation happens currently. If you need to change the set of
auto indexed properties and have them re-indexed, you currently have to do this
by hand. An example will illustrate the above better:

/*
 * Creating the configuration
 */
GraphDatabaseService graphDb = new GraphDatabaseFactory().
    newEmbeddedDatabaseBuilder( storeDirectory ).
    setConfig( GraphDatabaseSettings.node_keys_indexable, "nodeProp1,nodeProp2" ).
    setConfig( GraphDatabaseSettings.node_auto_indexing, GraphDatabaseSetting.TRUE ).
    newGraphDatabase();

Transaction tx = graphDb.beginTx();
Node node1 = null, node2 = null, node3 = null, node4 = null;
try
{
    // Create the primitives
    node1 = graphDb.createNode();
    node2 = graphDb.createNode();
    node3 = graphDb.createNode();
    node4 = graphDb.createNode();

    // Add indexable and non-indexable properties
    node1.setProperty( "nodeProp1", "nodeProp1Value" );
    node2.setProperty( "nodeProp2", "nodeProp2Value" );
    node3.setProperty( "nodeProp1", "nodeProp3Value" );
    node4.setProperty( "nodeProp2", "nodeProp4Value" );

    // Make things persistent
    tx.success();
}
catch ( Exception e )
{
    tx.failure();
}
finally
{
    tx.finish();
}

/*
 *  Here both nodes are indexed. To demonstrate removal, we stop
 *  autoindexing nodeProp1.
 */
AutoIndexer<Node> nodeAutoIndexer = graphDb.index().getNodeAutoIndexer();
nodeAutoIndexer.stopAutoIndexingProperty( "nodeProp1" );

tx = graphDb.beginTx();
try
{
    /*
     * nodeProp1 is no longer auto indexed. It will be
     * removed regardless. Note that node3 will remain.
     */
    node1.setProperty( "nodeProp1", "nodeProp1Value2" );
    /*
     * node2 will be auto updated
     */
    node2.setProperty( "nodeProp2", "nodeProp2Value2" );
    /*
     * remove node4 property nodeProp2 from index.
     */
    node4.removeProperty( "nodeProp2" );
    // Make things persistent
    tx.success();
}
catch ( Exception e )
{
    tx.failure();
}
finally
{
    tx.finish();
}

// Verify
ReadableIndex<Node> nodeAutoIndex = nodeAutoIndexer.getAutoIndex();
// node1 is completely gone
assertFalse( nodeAutoIndex.get( "nodeProp1", "nodeProp1Value" ).hasNext() );
assertFalse( nodeAutoIndex.get( "nodeProp1", "nodeProp1Value2" ).hasNext() );
// node2 is updated
assertFalse( nodeAutoIndex.get( "nodeProp2", "nodeProp2Value" ).hasNext() );
assertEquals( node2,
        nodeAutoIndex.get( "nodeProp2", "nodeProp2Value2" ).getSingle() );
/*
 * node3 is still there, despite its nodeProp1 property not being monitored
 * any more because it was not touched, in contrast with node1.
 */
assertEquals( node3,
        nodeAutoIndex.get( "nodeProp1", "nodeProp3Value" ).getSingle() );
// Finally, node4 is removed because the property was removed.
assertFalse( nodeAutoIndex.get( "nodeProp2", "nodeProp4Value" ).hasNext() );

Caution

If you start the database with auto indexing enabled but different auto indexed
properties than the last run, then already auto-indexed entities will be
deleted as you work with them. Make sure that the monitored set is what you
want before enabling the functionality.

Chapter 16. Cypher Query Language

Cypher is a declarative graph query language that allows for expressive and
efficient querying and updating of the graph store without having to write
traversals through the graph structure in code. Cypher is still growing and
maturing, and that means that there probably will be breaking syntax changes.
It also means that it has not undergone the same rigorous performance testing
as the other components.

Cypher is designed to be a humane query language, suitable for both developers
and (importantly, we think) operations professionals who want to make ad-hoc
queries on the database. Our guiding goal is to make the simple things simple,
and the complex things possible. Its constructs are based on English prose and
neat iconography, which helps to make it (somewhat) self-explanatory.

Cypher is inspired by a number of different approaches and builds upon
established practices for expressive querying. Most of the keywords like WHERE
and ORDER BY are inspired by SQL <http://en.wikipedia.org/wiki/SQL>. Pattern
matching borrows expression approaches from SPARQL <http://en.wikipedia.org/
wiki/SPARQL>.

Being a declarative language, Cypher focuses on the clarity of expressing what
to retrieve from a graph, not how to do it, in contrast to imperative languages
like Java, and scripting languages like Gremlin <http://gremlin.tinkerpop.com>
(supported via the Section 19.17, “Gremlin Plugin”) and the JRuby Neo4j
bindings <http://neo4j.rubyforge.org/>. This makes the concern of how to
optimize queries an implementation detail not exposed to the user.

The query language is comprised of several distinct clauses.

  * START: Starting points in the graph, obtained via index lookups or by
    element IDs.
  * MATCH: The graph pattern to match, bound to the starting points in START.
  * WHERE: Filtering criteria.
  * RETURN: What to return.
  * CREATE: Creates nodes and relationships.
  * DELETE: Removes nodes, relationships and properties.
  * SET: Set values to properties.
  * FOREACH: Performs updating actions once per element in a list.
  * WITH: Divides a query into multiple, distinct parts.

Let’s see three of them in action:

Imagine an example graph like

Figure 16.1. Example Graph

Example-Graph-cypher-intro.svg


For example, here is a query which finds a user called John in an index and
then traverses the graph looking for friends of Johns friends (though not his
direct friends) before returning both John and any friends-of-friends that are
found.

START john=node:node_auto_index(name = 'John')
MATCH john-[:friend]->()-[:friend]->fof
RETURN john, fof

Resulting in

+------------------------------------------+
|john                |fof                  |
|------------------------------------------|
|2 rows                                    |
|------------------------------------------|
|2 ms                                      |
|------------------------------------------|
|Node[4]{name:"John"}|Node[2]{name:"Maria"}|
|--------------------+---------------------|
|Node[4]{name:"John"}|Node[3]{name:"Steve"}|
+------------------------------------------+

Next up we will add filtering to set all four parts in motion:

In this next example, we take a list of users (by node ID) and traverse the
graph looking for those other users that have an outgoing friend relationship,
returning only those followed users who have a name property starting with S.

START user=node(5,4,1,2,3)
MATCH user-[:friend]->follower
WHERE follower.name =~ /S.*/
RETURN user, follower.name

Resulting in

+----------------------------------+
|user                |follower.name|
|----------------------------------|
|2 rows                            |
|----------------------------------|
|0 ms                              |
|----------------------------------|
|Node[5]{name:"Joe"} |"Steve"      |
|--------------------+-------------|
|Node[4]{name:"John"}|"Sara"       |
+----------------------------------+

To use Cypher from Java, see Section 4.10, “Execute Cypher Queries from Java”.
For more Cypher examples, see even Chapter 5, Cypher Cookbook.

16.1. Operators

Operators in Cypher are of three different varieties - mathematical, equality
and relationships.

The mathematical operators are +, -, *, / and %. Of these, only the plus-sign
works on strings and collections.

The equality operators are =, <>, <, >, <=, >=.

Since Neo4j is a schema-less graph database, Cypher has two special
operators — ? and !.

They are used on properties, and are used to deal with missing values. A
comparison on a property that does not exist will cause an error. Instead of
having to always check if the property exists before comparing its value with
something else, the question mark make the comparison always return true if the
property is missing, and the exclamation mark makes the comparator return
false.

This predicate will evaluate to true if n.prop is missing.

WHERE n.prop? = "foo"

This predicate will evaluate to false if n.prop is missing.

WHERE n.prop! = "foo"

Warning: Mixing the two in the same comparison will lead to unpredictable
results.

This is really syntactic sugar that expands to this:

WHERE n.prop? = "foo" ⇒ WHERE (not(has(n.prop)) OR n.prop = "foo")

WHERE n.prop! = "foo" ⇒ WHERE (has(n.prop) AND n.prop = "foo")

16.2. Expressions

An expression in Cypher can be:

  * A numeric literal (integer or double) — 13, 40000, 3.14
  * A string literal — "Hello", 'World'
  * A boolean literal —  true, false, TRUE, FALSE
  * An identifier — n, x, rel, myFancyIdentifier, `A name with weird stuff in
    it[]!`
  * A property — n.prop, x.prop, rel.thisProperty, myFancyIdentifier.`(weird
    property name)`
  * A nullable property — it’s a property, with a question mark or exclamation
    mark — n.prop?, rel.thisProperty!
  * A parameter — {param}, {0}
  * A collection of expressions — ["a", "b"], [1,2,3], ["a", 2, n.property,
    {param}], [ ]
  * A function call — length(p), nodes(p)
  * An aggregate function — avg(x.prop), count(*)
  * Relationship types — :REL_TYPE, :`REL TYPE`, :REL1|REL2
  * A path-pattern: a-→()←-b

16.3. Parameters

Cypher supports querying with parameters. This allows developers to not to have
to do string building to create a query, and it also makes caching of execution
plans much easier for Cypher.

Parameters can be used for literals in the WHERE clause, for the index key and
index value in the START clause, index queries, and finally for node/
relationship ids.

Accepted names for parameter are letters and number, and any combination of
these.

Here follows a few examples of how you can use parameters from Java.

Parameter for node id. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "id", 0 );
ExecutionResult result = engine.execute( "start n=node({id}) return n.name", params );

Parameter for node object. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "node", andreasNode );
ExecutionResult result = engine.execute( "start n=node({node}) return n.name", params );

Parameter for multiple node ids. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "id", Arrays.asList( 0, 1, 2 ) );
ExecutionResult result = engine.execute( "start n=node({id}) return n.name", params );

Parameter for string literal. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "name", "Johan" );
ExecutionResult result =
        engine.execute( "start n=node(0,1,2) where n.name = {name} return n", params );

Parameter for index key and value. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "key", "name" );
params.put( "value", "Michaela" );
ExecutionResult result =
        engine.execute( "start n=node:people({key} = {value}) return n", params );

Parameter for index query. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "query", "name:Andreas" );
ExecutionResult result = engine.execute( "start n=node:people({query}) return n", params );

Numeric parameters for SKIP and LIMIT. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "s", 1 );
params.put( "l", 1 );
ExecutionResult result =
        engine.execute( "start n=node(0,1,2) return n.name skip {s} limit {l}", params );

Parameter for regular expression. 

Map<String, Object> params = new HashMap<String, Object>();
params.put( "regex", ".*h.*" );
ExecutionResult result =
        engine.execute( "start n=node(0,1,2) where n.name =~ {regex} return n.name", params );

16.4. Identifiers

When you reference parts of the pattern, you do so by naming them. The names
you give the different parts are called identifiers.

In this example:

START n=node(1) MATCH n-->b RETURN b

The identifiers are n and b.

Identifiers can be lower or upper case, and may contain underscore. If other
characters are needed, you can use the ` sign. The same rules apply to property
names.

16.5. Comments

To add comments to your queries, use double slash. Examples:

START n=node(1) RETURN b //This is an end of line comment

START n=node(1)
//This is a whole line comment
RETURN b

START n=node(1) WHERE n.property = "//This is NOT a comment" RETURN b

16.6. Updating the graph with Cypher

Cypher can be used for both querying and updating your graph.

16.6.1. Updating query structure

A Cypher query part can’t both match and update the graph at the same time.
Every part can either read and match on the graph, or make updates on it.

16.6.2. Query Parts & Structure

If you read from the graph, and then update the graph, your query implicitly
has two parts — the reading is the first part, and the writing is the second.
If your query is read-only, Cypher will be lazy, and not actually pattern match
until you ask for the results. Here, the semantics are that all the reading
will be done before any writing actually happens. This is very
important — without this it’s easy to find cases where the pattern matcher runs
into data that is being created by the very same query, and all bets are off.
That road leads to Heisenbugs, Brownian motion and cats that are dead and alive
at the same time.

First reading, and then writing, is the only pattern where the query parts are
implicit — any other order and you have to be explicit about your query parts.
The parts are separated using the WITH statement. WITH is like the event
horizon — it’s a barrier between a plan and the finished execution of that
plan.

When you want filter using aggregated data, you have to chain together two
reading query parts — the first one does the aggregating, and the second query
filters on the results coming from the first one.

START n=node(...)
MATCH n-[:friend]-friend
WITH n, count(friend) as friendsCount
WHERE friendsCount > 3
RETURN n, friendsCount

Using WITH, you specify how you want the aggregation to happen, and that the
aggregation has to be finished before Cypher can start filtering.

You can chain together as many query parts as you have JVM heap for.

16.6.3. Returning data

Any query can return data. If your query is read only, it has to return
data — it serves no purpose if it doesn’t, and it is not a valid Cypher query.
Queries that update the graph don’t have to return anything, but they can.

After all the parts of the query, comes one final RETURN statement. RETURN is
not part of any query part — it is a period symbol after an eloquent statement.
When RETURN is legal, it’s also legal to use SKIP/LIMIT and ORDER BY.

If you return graph elements from a query that has just deleted them — beware,
you are holding a pointer that is no longer valid. Operations on that node
might fail mysteriously and unpredictably.

16.7. Transactions and Cypher

Any query that updates the graph will run in a transaction. An updating query
will always either fully succeed, or not succeed at all.

Cypher will either create a new transaction, and commit it once the query
finishes. Or if a transaction already exists in the running context, the query
will run inside it, and nothing will be persisted to disk until the transaction
is successfully committed.

This can be used to have multiple queries be committed as a single transaction:

 1. Open a transaction,
 2. run multiple updating Cypher queries,
 3. and commit all of them in one go.

Note that a query will hold the changes in heap until the whole query has
finished executing. A large query will consequently need a JVM with lots of
heap space.

16.8. Patterns

Patterns are at the very core of Cypher, and are used for a lot of different
reasons. Patterns are used in the MATCH clause. Path patterns are expressions.
Since these expressions are collections, they can also be used as predicates (a
non-empty collection signifies true). They are also used to CREATE the graph,
and by the RELATE clause.

So, understanding patterns is important, to be able to be effective with
Cypher.

You describe the pattern, and Cypher will figure out how to get that data for
you. The idea is for you to draw your query on a whiteboard, naming the
interesting parts of the pattern, so you can then use values from these parts
to create the result set you are looking for.

The description of the pattern is made up of one or more paths, separated by
commas. A path is a sequence of nodes and relationships that always start and
end in nodes. An example path would be:

(a)-->(b)

This is a path starting from the pattern node a, with an outgoing relationship
from it to pattern node b.

Paths can be of arbitrary length, and the same node may appear in multiple
places in the path.

Node identifiers can be used with or without surrounding parenthesis. The
following match is semantically identical to the one we saw above — the
difference is purely aesthetic.

a-->b

If you don’t care about a node, you don’t need to name it. Empty parenthesis
are used for these nodes, like so:

a-->()<--b

If you need to work with the relationship between two nodes, you can name it.

a-[r]->b

If you don’t care about the direction of the relationship, you can omit the
arrow at either end of the relationship, like:

a--b

Relationships have types. When you are only interested in a specific
relationship type, you can specify this like so:

a-[:REL_TYPE]->b

If multiple relationships are acceptable, you can list them, separating them
with the pipe symbol |

a-[r:TYPE1|TYPE2]->b

This pattern matches a relationship of type TYPE1 or TYPE2, going from a to b.
The relationship is named r. Multiple relationship types do not work with
CREATE or RELATE.

An optional relationship is a relationship that when it is found is matched,
but if it is missing, a null will be placed in place of the relationship.
Normally, if no matching relationship is found, that sub graph is not matched.

This allows you to write queries like this:

START me=node(1)
MATCH me-->friend-[?:parent_of]->children
RETURN friend, children

The query above says “give me all my friends, and their children, if they have
any.”

Optionality is transitive — if a part of the pattern can only be reached from a
bound point through an optional relationship, that part is also optional. In
the pattern above, the only bound point in the pattern is me. Since the
relationship between friend and children is optional, children is an optional
part of the graph.

Also, named paths that contain optional parts are also optional — if any part
of the path is null, the whole path is null.

In these examples, b and p are all optional and can contain null:

START a=node(1)
MATCH p = a-[?]->b
RETURN b

START a=node(1)
MATCH p = a-[?*]->b
RETURN b

START a=node(1)
MATCH p = a-[?]->x-->b
RETURN b

START a=node(1), x=node(2)
MATCH p = shortestPath( a-[?*]->x )
RETURN p

A pattern relationship can span multiple graph relationships. These are called
variable length relationships, and are marked as such using an asterix:

(a)-[*]->(b)

This signifies a path starting on the pattern node a, following only outgoing
relationships, until it reaches pattern node b. Any number of relationships can
be followed searching for a path to b, so this can be a very expensive query,
depending on what your graph looks like.

You can set a minimum set of steps that can be taken, and/or the max number of
steps:

(a)-[*3..5]->(b)

This is a variable length relationship containing at least three graph
relationships, and at most five.

Variable length relationships do not work with CREATE and RELATE.

As a simple example, let’s take the following query, executed on the graph
pictured below.

Query

START me=node(1)
MATCH me-->friend-[?:parent_of]->children
RETURN friend, children

This returns the a friend node, and no children, since there are no such
relationships in the graph.

Table 16.1. Result

+-------------------------------+
|friend                |children|
|-------------------------------|
|1 row                          |
|-------------------------------|
|1 ms                           |
|-------------------------------|
|Node[3]{name:"Anders"}|<null>  |
+-------------------------------+


16.9. Start

Every query describes a pattern, and in that pattern one can have multiple
start points. A start point is a relationship or a node that form the starting
points for a pattern match. You can either introduce start points by id, or by
index lookups. Note that trying to use an index that doesn’t exist will throw
an exception.

Graph

cypher-start-graph.svg

16.9.1. Node by id

Binding a node as a start point is done with the node(*) function .

Query

START n=node(1)
RETURN n

The corresponding node is returned.

Table 16.2. Result

+-----------------+
|n                |
|-----------------|
|1 row            |
|-----------------|
|0 ms             |
|-----------------|
|Node[1]{name:"A"}|
+-----------------+


16.9.2. Relationship by id

Binding a relationship as a start point is done with the relationship(*)
function, which can also be abbreviated rel(*).

Query

START r=relationship(0)
RETURN r

The relationship with id 0 is returned.

Table 16.3. Result

+------------+
|r           |
|------------|
|1 row       |
|------------|
|0 ms        |
|------------|
|:KNOWS[0] {}|
+------------+


16.9.3. Multiple nodes by id

Multiple nodes are selected by listing them separated by commas.

Query

START n=node(1, 2, 3)
RETURN n

This returns the nodes listed in the `START statement.

Table 16.4. Result

+-----------------+
|n                |
|-----------------|
|3 rows           |
|-----------------|
|0 ms             |
|-----------------|
|Node[1]{name:"A"}|
|-----------------|
|Node[2]{name:"B"}|
|-----------------|
|Node[3]{name:"C"}|
+-----------------+


16.9.4. All nodes

To get all the nodes, use an asterisk. This can be done with relationships as
well.

Query

START n=node(*)
RETURN n

This query returns all the nodes in the graph.

Table 16.5. Result

+-----------------+
|n                |
|-----------------|
|3 rows           |
|-----------------|
|0 ms             |
|-----------------|
|Node[1]{name:"A"}|
|-----------------|
|Node[2]{name:"B"}|
|-----------------|
|Node[3]{name:"C"}|
+-----------------+


16.9.5. Node by index lookup

If the start point can be found by index lookups, it can be done like this:
node:index-name(key = "value"). In this example, there exists a node index
named nodes.

Query

START n=node:nodes(name = "A")
RETURN n

The node indexed with name "A" is returned.

Table 16.6. Result

+-----------------+
|n                |
|-----------------|
|1 row            |
|-----------------|
|0 ms             |
|-----------------|
|Node[1]{name:"A"}|
+-----------------+


16.9.6. Relationship by index lookup

If the start point can be found by index lookups, it can be done like this:
relationship:index-name(key = "value").

Query

START r=relationship:rels(property = "some_value")
RETURN r

The relationship indexed with property "some_value" is returned.

Table 16.7. Result

+---------------------------------+
|r                                |
|---------------------------------|
|1 row                            |
|---------------------------------|
|0 ms                             |
|---------------------------------|
|:KNOWS[0] {property:"some_value"}|
+---------------------------------+


16.9.7. Node by index query

If the start point can be found by index more complex Lucene queries:
node:index-name("query").This allows you to write more advanced index queries.

Query

START n=node:nodes("name:A")
RETURN n

The node indexed with name "A" is returned.

Table 16.8. Result

+-----------------+
|n                |
|-----------------|
|1 row            |
|-----------------|
|0 ms             |
|-----------------|
|Node[1]{name:"A"}|
+-----------------+


16.9.8. Multiple start points

Sometimes you want to bind multiple start points. Just list them separated by
commas.

Query

START a=node(1), b=node(2)
RETURN a,b

Both the A and the B node are returned.

Table 16.9. Result

+-----------------------------------+
|a                |b                |
|-----------------------------------|
|1 row                              |
|-----------------------------------|
|0 ms                               |
|-----------------------------------|
|Node[1]{name:"A"}|Node[2]{name:"B"}|
+-----------------------------------+


16.10. Match

16.10.1. Introduction

Pattern matching is one of the pillars of Cypher. The pattern is used to
describe the shape of the data that we are looking for. Cypher will then try to
find patterns in the graph — these are called matching subgraphs.

Patterns have bound points, or start points. They are the parts of the pattern
that are already “bound” to a set of graph nodes or relationships. All parts of
the pattern must be directly or indirectly connected to a start point — a
pattern where parts of the pattern are not reachable from any start point will
be rejected.

The optional relationship is a way to describe parts of the pattern that can
evaluate to null if it can not be matched to the graph. It’s the equivalent of
SQL outer join — if Cypher finds one or more matches, they will be returned. If
no matches are found, Cypher will return a null. Only relationships can be
marked as optional, and it’s done with a question mark.

Optional relationships of the pattern are used to answer queries like this:

START me=node(1)
MATCH me-->friend-[?:parent_of]->children
RETURN friend, children

The query above says “give me all my friends, and their children, if they have
any.”

Optionality is transitive — if a part of the pattern can only be reached from a
bound point through an optional relationship, that part is also optional. In
the pattern above, the only bound point in the pattern is me. Since the
relationship between friend and children is optional, children is an optional
part of the graph.

Also, named paths that contain optional parts are also optional — if any part
of the path is null, the whole path is null.

In these examples, b and p are all optional and can contain null:

START a=node(1)
MATCH p = a-[?]->b
RETURN b

START a=node(1)
MATCH p = a-[?*]->b
RETURN b

START a=node(1)
MATCH p = a-[?]->x-->b
RETURN b

START a=node(1), x=node(2)
MATCH p = shortestPath( a-[?*]->x )
RETURN p

As a simple example, let’s take the following query, executed on the graph
pictured below.

Query

START me=node(1)
MATCH me-->friend-[?:parent_of]->children
RETURN friend, children

This returns the a friend node, and no children, since there are no such
relatoinships in the graph.

Table 16.10. Result

+-------------------------------+
|friend                |children|
|-------------------------------|
|1 row                          |
|-------------------------------|
|1 ms                           |
|-------------------------------|
|Node[3]{name:"Anders"}|<null>  |
+-------------------------------+


For the examples given in the sections below, the follwoing graph is the base:

Graph

cypher-match-graph.svg

16.10.2. Related nodes

The symbol -- means related to, without regard to type or direction.

Query

START n=node(3)
MATCH (n)--(x)
RETURN x

All nodes related to A (Anders) are returned.

Table 16.11. Result

+-----------------------+
|x                      |
|-----------------------|
|3 rows                 |
|-----------------------|
|0 ms                   |
|-----------------------|
|Node[4]{name:"Bossman"}|
|-----------------------|
|Node[1]{name:"David"}  |
|-----------------------|
|Node[5]{name:"Cesar"}  |
+-----------------------+


16.10.3. Outgoing relationships

When the direction of a relationship is interesting, it is shown by using -->
or <--, like this:

Query

START n=node(3)
MATCH (n)-->(x)
RETURN x

All nodes that A has outgoing relationships to.

Table 16.12. Result

+-----------------------+
|x                      |
|-----------------------|
|2 rows                 |
|-----------------------|
|0 ms                   |
|-----------------------|
|Node[4]{name:"Bossman"}|
|-----------------------|
|Node[5]{name:"Cesar"}  |
+-----------------------+


16.10.4. Directed relationships and identifier

If an identifier is needed, either for filtering on properties of the
relationship, or to return the relationship, this is how you introduce the
identifier.

Query

START n=node(3)
MATCH (n)-[r]->()
RETURN r

All outgoing relationships from node A.

Table 16.13. Result

+-------------+
|r            |
|-------------|
|2 rows       |
|-------------|
|0 ms         |
|-------------|
|:KNOWS[0] {} |
|-------------|
|:BLOCKS[1] {}|
+-------------+


16.10.5. Match by relationship type

When you know the relationship type you want to match on, you can specify it by
using a colon.

Query

START n=node(3)
MATCH (n)-[:BLOCKS]->(x)
RETURN x

All nodes that are BLOCKed by A.

Table 16.14. Result

+---------------------+
|x                    |
|---------------------|
|1 row                |
|---------------------|
|0 ms                 |
|---------------------|
|Node[5]{name:"Cesar"}|
+---------------------+


16.10.6. Match by multiple relationship types

If multiple types are acceptable, you can specify this by chaining them with
the pipe symbol |.

Query

START n=node(3)
MATCH (n)-[:BLOCKS|KNOWS]->(x)
RETURN x

All nodes with a BLOCK or KNOWS relationship to A.

Table 16.15. Result

+-----------------------+
|x                      |
|-----------------------|
|2 rows                 |
|-----------------------|
|0 ms                   |
|-----------------------|
|Node[5]{name:"Cesar"}  |
|-----------------------|
|Node[4]{name:"Bossman"}|
+-----------------------+


16.10.7. Match by relationship type and use an identifier

If you both want to introduce an identifier to hold the relationship, and
specify the relationship type you want, just add them both, like this.

Query

START n=node(3)
MATCH (n)-[r:BLOCKS]->()
RETURN r

All BLOCKS relationship going out from A.

Table 16.16. Result

+-------------+
|r            |
|-------------|
|1 row        |
|-------------|
|0 ms         |
|-------------|
|:BLOCKS[1] {}|
+-------------+


16.10.8. Relationship types with uncommon characters

Sometime your database will have types with non-letter characters, or with
spaces in them. Use ` to escape these.

Query

START n=node(3)
MATCH (n)-[r:`TYPE
WITH SPACE IN IT`]->()
RETURN r

This returns a relationship of a type with spaces in it.

Table 16.17. Result

+----------------------------+
|r                           |
|----------------------------|
|1 row                       |
|----------------------------|
|0 ms                        |
|----------------------------|
|:TYPE WITH SPACE IN IT[6] {}|
+----------------------------+


16.10.9. Multiple relationships

Relationships can be expressed by using multiple statements in the form of ()--
(), or they can be strung together, like this:

Query

START a=node(3)
MATCH (a)-[:KNOWS]->(b)-[:KNOWS]->(c)
RETURN a,b,c

The three nodes in the path are returned.

Table 16.18. Result

+-------------------------------------------------------------------+
|a                     |b                      |c                   |
|-------------------------------------------------------------------|
|1 row                                                              |
|-------------------------------------------------------------------|
|0 ms                                                               |
|-------------------------------------------------------------------|
|Node[3]{name:"Anders"}|Node[4]{name:"Bossman"}|Node[2]{name:"Emil"}|
+-------------------------------------------------------------------+


16.10.10. Variable length relationships

Nodes that are a variable number of relationship→node hops away can be found
using -[:TYPE*minHops..maxHops]->.

Query

START a=node(3), x=node(2, 4)
MATCH a-[:KNOWS*1..3]->x
RETURN a,x

Returns the start and end point, if there is a path between 1 and 3
relationships away.

Table 16.19. Result

+----------------------------------------------+
|a                     |x                      |
|----------------------------------------------|
|2 rows                                        |
|----------------------------------------------|
|0 ms                                          |
|----------------------------------------------|
|Node[3]{name:"Anders"}|Node[2]{name:"Emil"}   |
|----------------------+-----------------------|
|Node[3]{name:"Anders"}|Node[4]{name:"Bossman"}|
+----------------------------------------------+


16.10.11. Relationship identifier in variable length relationships

When the connection between two nodes is of variable length, a relationship
identifier becomes an iterable of relationships.

Query

START a=node(3), x=node(2, 4)
MATCH a-[r:KNOWS*1..3]->x
RETURN r

Returns the relationships, if there is a path between 1 and 3 relationships
away.

Table 16.20. Result

+---------------------------+
|r                          |
|---------------------------|
|2 rows                     |
|---------------------------|
|0 ms                       |
|---------------------------|
|[:KNOWS[0] {},:KNOWS[3] {}]|
|---------------------------|
|[:KNOWS[0] {}]             |
+---------------------------+


16.10.12. Zero length paths

When using variable length paths that have the lower bound zero, it means that
two identifiers can point to the same node. If the distance between two nodes
is zero, they are, by definition, the same node.

Query

START a=node(3)
MATCH p1=a-[:KNOWS*0..1]->b, p2=b-[:BLOCKS*0..1]->c
RETURN a,b,c, length(p1), length(p2)

This query will return four paths, some of them with length zero.

Table 16.21. Result

+----------------------------------------------------------------------------+
|a                 |b                  |c                  |length  |length  |
|                  |                   |                   |(p1)    |(p2)    |
|----------------------------------------------------------------------------|
|4 rows                                                                      |
|----------------------------------------------------------------------------|
|0 ms                                                                        |
|----------------------------------------------------------------------------|
|Node[3]           |Node[3]            |Node[3]            |0       |0       |
|{name:"Anders"}   |{name:"Anders"}    |{name:"Anders"}    |        |        |
|------------------+-------------------+-------------------+--------+--------|
|Node[3]           |Node[3]            |Node[5]            |0       |1       |
|{name:"Anders"}   |{name:"Anders"}    |{name:"Cesar"}     |        |        |
|------------------+-------------------+-------------------+--------+--------|
|Node[3]           |Node[4]            |Node[4]            |1       |0       |
|{name:"Anders"}   |{name:"Bossman"}   |{name:"Bossman"}   |        |        |
|------------------+-------------------+-------------------+--------+--------|
|Node[3]           |Node[4]            |Node[1]            |1       |1       |
|{name:"Anders"}   |{name:"Bossman"}   |{name:"David"}     |        |        |
+----------------------------------------------------------------------------+


16.10.13. Optional relationship

If a relationship is optional, it can be marked with a question mark. This is
similar to how a SQL outer join works. If the relationship is there, it is
returned. If it’s not, null is returned in it’s place. Remember that anything
hanging off an optional relationship, is in turn optional, unless it is
connected with a bound node through some other path.

Query

START a=node(2)
MATCH a-[?]->x
RETURN a,x

A node, and null, since the node has no outgoing relationships.

Table 16.22. Result

+----------------------------+
|a                    |x     |
|----------------------------|
|1 row                       |
|----------------------------|
|0 ms                        |
|----------------------------|
|Node[2]{name:"Emil"} |<null>|
+----------------------------+


16.10.14. Optional typed and named relationship

Just as with a normal relationship, you can decide which identifier it goes
into, and what relationship type you need.

Query

START a=node(3)
MATCH a-[r?:LOVES]->()
RETURN a,r

This returns a node, and null, since the node has no outgoing LOVES
relationships.

Table 16.23. Result

+------------------------------+
|a                      |r     |
|------------------------------|
|1 row                         |
|------------------------------|
|0 ms                          |
|------------------------------|
|Node[3]{name:"Anders"} |<null>|
+------------------------------+


16.10.15. Properties on optional elements

Returning a property from an optional element that is null will also return
null.

Query

START a=node(2)
MATCH a-[?]->x
RETURN x, x.name

This returns the element x (null in this query), and null as it’s name.

Table 16.24. Result

+-------------+
|x     |x.name|
|-------------|
|1 row        |
|-------------|
|0 ms         |
|-------------|
|<null>|<null>|
+-------------+


16.10.16. Complex matching

Using Cypher, you can also express more complex patterns to match on, like a
diamond shape pattern.

Query

START a=node(3)
MATCH (a)-[:KNOWS]->(b)-[:KNOWS]->(c), (a)-[:BLOCKS]-(d)-[:KNOWS]-(c)
RETURN a,b,c,d

This returns the four nodes in the paths.

Table 16.25. Result

+-----------------------------------------------------------------------------+
|a                  |b                   |c                |d                 |
|-----------------------------------------------------------------------------|
|1 row                                                                        |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|Node[3]            |Node[4]             |Node[2]          |Node[5]           |
|{name:"Anders"}    |{name:"Bossman"}    |{name:"Emil"}    |{name:"Cesar"}    |
+-----------------------------------------------------------------------------+


16.10.17. Shortest path

Finding a single shortest path between two nodes is as easy as using the
shortestPath function, like this:

Query

START d=node(1), e=node(2)
MATCH p = shortestPath( d-[*..15]->e )
RETURN p

This means: find a single shortest path between two nodes, as long as the path
is max 15 relationships long. Inside of the parenthesis you write a single link
of a path — the starting node, the connecting relationship and the end node.
Characteristics describing the relationship like relationship type, max hops
and direction are all used when finding the shortest path. You can also mark
the path as optional.

Table 16.26. Result

+-----------------------------------------------------------------------------+
|p                                                                            |
|-----------------------------------------------------------------------------|
|1 row                                                                        |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|[Node[1]{name:"David"},:KNOWS[2] {},Node[3]{name:"Anders"},:KNOWS[0] {},Node |
|[4]{name:"Bossman"},:KNOWS[3] {},Node[2]{name:"Emil"}]                       |
+-----------------------------------------------------------------------------+


16.10.18. All shortest paths

Finds all the shortest paths between two nodes.

Query

START d=node(1), e=node(2)
MATCH p = allShortestPaths( d-[*..15]->e )
RETURN p

This will find the two directed paths between David and Emil.

Table 16.27. Result

+-----------------------------------------------------------------------------+
|p                                                                            |
|-----------------------------------------------------------------------------|
|2 rows                                                                       |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|[Node[1]{name:"David"},:KNOWS[2] {},Node[3]{name:"Anders"},:KNOWS[0] {},Node |
|[4]{name:"Bossman"},:KNOWS[3] {},Node[2]{name:"Emil"}]                       |
|-----------------------------------------------------------------------------|
|[Node[1]{name:"David"},:KNOWS[2] {},Node[3]{name:"Anders"},:BLOCKS[1] {},Node|
|[5]{name:"Cesar"},:KNOWS[4] {},Node[2]{name:"Emil"}]                         |
+-----------------------------------------------------------------------------+


16.10.19. Named path

If you want to return or filter on a path in your pattern graph, you can a
introduce a named path.

Query

START a=node(3)
MATCH p = a-->b
RETURN p

This returns the two paths starting from the first node.

Table 16.28. Result

+-------------------------------------------------------------+
|p                                                            |
|-------------------------------------------------------------|
|2 rows                                                       |
|-------------------------------------------------------------|
|0 ms                                                         |
|-------------------------------------------------------------|
|[Node[3]{name:"Anders"},:KNOWS[0] {},Node[4]{name:"Bossman"}]|
|-------------------------------------------------------------|
|[Node[3]{name:"Anders"},:BLOCKS[1] {},Node[5]{name:"Cesar"}] |
+-------------------------------------------------------------+


16.10.20. Matching on a bound relationship

When your pattern contains a bound relationship, and that relationship pattern
doesn’t specify direction, Cypher will try to match the relationship where the
connected nodes switch sides.

Query

START a=node(3), b=node(2)
MATCH a-[?:KNOWS]-x-[?:KNOWS]-b
RETURN x

This returns the two connected nodes, once as the start node, and once as the
end node

Table 16.29. Result

+-----------------------+
|x                      |
|-----------------------|
|3 rows                 |
|-----------------------|
|0 ms                   |
|-----------------------|
|Node[4]{name:"Bossman"}|
|-----------------------|
|Node[5]{name:"Cesar"}  |
|-----------------------|
|Node[1]{name:"David"}  |
+-----------------------+


16.11. Where

If you need filtering apart from the pattern of the data that you are looking
for, you can add clauses in the where part of the query.

Graph

cypher-where-graph.svg

16.11.1. Boolean operations

You can use the expected boolean operators AND and OR, and also the boolean
function NOT().

Query

START n=node(3, 1)
WHERE (n.age < 30 and n.name = "Tobias") or not(n.name = "Tobias")
RETURN n

The node.

Table 16.30. Result

+------------------------------------------+
|n                                         |
|------------------------------------------|
|2 rows                                    |
|------------------------------------------|
|0 ms                                      |
|------------------------------------------|
|Node[3]{name:"Andres",age:36,belt:"white"}|
|------------------------------------------|
|Node[1]{name:"Tobias",age:25}             |
+------------------------------------------+


16.11.2. Filter on node property

To filter on a property, write your clause after the WHERE keyword.

Query

START n=node(3, 1)
WHERE n.age < 30
RETURN n

The node.

Table 16.31. Result

+-----------------------------+
|n                            |
|-----------------------------|
|1 row                        |
|-----------------------------|
|0 ms                         |
|-----------------------------|
|Node[1]{name:"Tobias",age:25}|
+-----------------------------+


16.11.3. Regular expressions

You can match on regular expressions by using =~ /regexp/, like this:

Query

START n=node(3, 1)
WHERE n.name =~ /Tob.*/
RETURN n

The node named Tobias.

Table 16.32. Result

+-----------------------------+
|n                            |
|-----------------------------|
|1 row                        |
|-----------------------------|
|0 ms                         |
|-----------------------------|
|Node[1]{name:"Tobias",age:25}|
+-----------------------------+


16.11.4. Escaping in regular expressions

If you need a forward slash inside of your regular expression, escape it just
like you expect to.

Query

START n=node(3, 1)
WHERE n.name =~ /Some\/thing/
RETURN n

No nodes match this regular expression.

Table 16.33. Result

+--------------+
|n             |
|--------------|
|0 row         |
|--------------|
|0 ms          |
|--------------|
|(empty result)|
+--------------+


16.11.5. Case insensitive regular expressions

By pre-pending a regular expression with (?i), the whole expression becomes
case insensitive.

Query

START n=node(3, 1)
WHERE n.name =~ /(?i)ANDR.*/
RETURN n

The node with name Andres is returned.

Table 16.34. Result

+------------------------------------------+
|n                                         |
|------------------------------------------|
|1 row                                     |
|------------------------------------------|
|0 ms                                      |
|------------------------------------------|
|Node[3]{name:"Andres",age:36,belt:"white"}|
+------------------------------------------+


16.11.6. Filtering on relationship type

You can put the exact relationship type in the MATCH pattern, but sometimes you
want to be able to do more advanced filtering on the type. You can use the
special property TYPE to compare the type with something else. In this example,
the query does a regular expression comparison with the name of the
relationship type.

Query

START n=node(3)
MATCH (n)-[r]->()
WHERE type(r) =~ /K.*/
RETURN r

The relationship that has a type whose name starts with K.

Table 16.35. Result

+------------+
|r           |
|------------|
|2 rows      |
|------------|
|0 ms        |
|------------|
|:KNOWS[0] {}|
|------------|
|:KNOWS[1] {}|
+------------+


16.11.7. Property exists

To only include nodes/relationships that have a property, just write out the
identifier and the property you expect it to have.

Query

START n=node(3, 1)
WHERE has(n.belt)
RETURN n

The node named Andres.

Table 16.36. Result

+------------------------------------------+
|n                                         |
|------------------------------------------|
|1 row                                     |
|------------------------------------------|
|0 ms                                      |
|------------------------------------------|
|Node[3]{name:"Andres",age:36,belt:"white"}|
+------------------------------------------+


16.11.8. Default true if property is missing

If you want to compare a property on a graph element, but only if it exists,
use the nullable property syntax. You can use a question mark if you want
missing property to return true, like:

Query

START n=node(3, 1)
WHERE n.belt? = 'white'
RETURN n

All nodes, even those without the belt property

Table 16.37. Result

+------------------------------------------+
|n                                         |
|------------------------------------------|
|2 rows                                    |
|------------------------------------------|
|0 ms                                      |
|------------------------------------------|
|Node[3]{name:"Andres",age:36,belt:"white"}|
|------------------------------------------|
|Node[1]{name:"Tobias",age:25}             |
+------------------------------------------+


16.11.9. Default false if property is missing

When you need missing property to evaluate to false, use the exclamation mark.

Query

START n=node(3, 1)
WHERE n.belt! = 'white'
RETURN n

No nodes without the belt property are returned.

Table 16.38. Result

+------------------------------------------+
|n                                         |
|------------------------------------------|
|1 row                                     |
|------------------------------------------|
|0 ms                                      |
|------------------------------------------|
|Node[3]{name:"Andres",age:36,belt:"white"}|
+------------------------------------------+


16.11.10. Filter on null values

Sometimes you might want to test if a value or an identifier is null. This is
done just like SQL does it, with IS NULL. Also like SQL, the negative is IS NOT
NULL, althought NOT(IS NULL x) also works.

Query

START a=node(1), b=node(3, 2)
MATCH a<-[r?]-b
WHERE r is null
RETURN b

Nodes that Tobias is not connected to

Table 16.39. Result

+----------------------------+
|b                           |
|----------------------------|
|1 row                       |
|----------------------------|
|0 ms                        |
|----------------------------|
|Node[2]{name:"Peter",age:34}|
+----------------------------+


16.11.11. Filter on patterns

Patterns are expressions in Cypher, expressions that return a collection of
paths. Collection expressions are also predicates - an empty collection
represents false, and a non-empty represents true.

So, patterns are not only expressions, they are also predicates. The only
limitation to your pattern is that you must be able to express it in a single
path. You can’t use comas between multiple paths like you do in MATCH. You can
achieve the same effect by combining multiple patterns with AND.

Note that you can not introduce new identifiers here. Although it might look
very similar to the MATCH patterns, the WHERE clause is all about eliminating
matched subgraphs. MATCH a-[*]->b is very different from WHERE a-[*]->b; the
first will produce a subgraph for every path it can find between a and b, and
the latter will eliminate any matched subgraphs where a and b do not have a
directed relationship chain between them.

Query

START a=node(1), b=node(3, 2)
WHERE a<--b
RETURN b

Nodes that Tobias is not connected to

Table 16.40. Result

+------------------------------------------+
|b                                         |
|------------------------------------------|
|1 row                                     |
|------------------------------------------|
|0 ms                                      |
|------------------------------------------|
|Node[3]{name:"Andres",age:36,belt:"white"}|
+------------------------------------------+


16.11.12. IN operator

To check if an element exists in a collection, you can use the IN operator.

Query

START a=node(3, 1, 2)
WHERE a.name IN ["Peter", "Tobias"]
RETURN a

This query shows how to check if a property exists in a literal collection.

Table 16.41. Result

+-----------------------------+
|a                            |
|-----------------------------|
|2 rows                       |
|-----------------------------|
|0 ms                         |
|-----------------------------|
|Node[1]{name:"Tobias",age:25}|
|-----------------------------|
|Node[2]{name:"Peter",age:34} |
+-----------------------------+


16.12. Return

In the return part of your query, you define which parts of the pattern you are
interested in. It can be nodes, relationships, or properties on these.

Graph

cypher-return-graph.svg

16.12.1. Return nodes

To return a node, list it in the return statemenet.

Query

START n=node(2)
RETURN n

The node.

Table 16.42. Result

+-----------------+
|n                |
|-----------------|
|1 row            |
|-----------------|
|0 ms             |
|-----------------|
|Node[2]{name:"B"}|
+-----------------+


16.12.2. Return relationships

To return a relationship, just include it in the return list.

Query

START n=node(1)
MATCH (n)-[r:KNOWS]->(c)
RETURN r

The relationship.

Table 16.43. Result

+------------+
|r           |
|------------|
|1 row       |
|------------|
|0 ms        |
|------------|
|:KNOWS[0] {}|
+------------+


16.12.3. Return property

To return a property, use the dot separator, like this:

Query

START n=node(1)
RETURN n.name

The the value of the property name.

Table 16.44. Result

+------+
|n.name|
|------|
|1 row |
|------|
|0 ms  |
|------|
|"A"   |
+------+


16.12.4. Return all elements

When you want to return all nodes, relationships and paths found in a query,
you can use the * symbol.

Query

START a=node(1)
MATCH p=a-[r]->b
RETURN *

Returns the two nodes, the relationship and the path used in the query

Table 16.45. Result

+-----------------------------------------------------------------------------+
|a                    |b         |r      |p                                   |
|-----------------------------------------------------------------------------|
|2 rows                                                                       |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|Node[1]              |Node[2]   |:KNOWS |[Node[1]{name:"A",happy:"Yes!       |
|{name:"A",happy:"Yes!|{name:"B"}|[0] {} |",age:55},:KNOWS[0] {},Node[2]      |
|",age:55}            |          |       |{name:"B"}]                         |
|---------------------+----------+-------+------------------------------------|
|Node[1]              |Node[2]   |:BLOCKS|[Node[1]{name:"A",happy:"Yes!       |
|{name:"A",happy:"Yes!|{name:"B"}|[1] {} |",age:55},:BLOCKS[1] {},Node[2]     |
|",age:55}            |          |       |{name:"B"}]                         |
+-----------------------------------------------------------------------------+


16.12.5. Identifier with uncommon characters

To introduce a placeholder that is made up of characters that are outside of
the english alphabet, you can use the ` to enclose the identifier, like this:

Query

START `This isn't a common identifier`=node(1)
RETURN `This isn't a common identifier`.happy

The node indexed with name "A" is returned

Table 16.46. Result

+------------------------------------+
|This isn't a common identifier.happy|
|------------------------------------|
|1 row                               |
|------------------------------------|
|0 ms                                |
|------------------------------------|
|"Yes!"                              |
+------------------------------------+


16.12.6. Column alias

If the name of the column should be different from the expression used, you can
rename it by using AS <new name>.

Query

START a=node(1)
RETURN a.age AS SomethingTotallyDifferent

Returns the age property of a node, but renames the column.

Table 16.47. Result

+-------------------------+
|SomethingTotallyDifferent|
|-------------------------|
|1 row                    |
|-------------------------|
|0 ms                     |
|-------------------------|
|55                       |
+-------------------------+


16.12.7. Optional properties

If a property might or might not be there, you can select it optionally by
adding a questionmark to the identifier, like this:

Query

START n=node(1, 2)
RETURN n.age?

The age when the node has that property, or null if the property is not there.

Table 16.48. Result

+------+
|n.age?|
|------|
|2 rows|
|------|
|0 ms  |
|------|
|55    |
|------|
|<null>|
+------+


16.12.8. Unique results

DISTINCT retrieves only unique rows depending on the columns that have been
selected to output.

Query

START a=node(1)
MATCH (a)-->(b)
RETURN distinct b

The node named B, but only once.

Table 16.49. Result

+-----------------+
|b                |
|-----------------|
|1 row            |
|-----------------|
|0 ms             |
|-----------------|
|Node[2]{name:"B"}|
+-----------------+


16.13. Aggregation

16.13.1. Introduction

To calculate aggregated data, Cypher offers aggregation, much like SQL’s GROUP
BY.

Aggregate functions take multiple input values and calculate an aggregated
value from them. Examples are AVG that calculate the average of multiple
numeric values, or MIN that finds the smallest numeric value in a set of
values.

Aggregation can be done over all the matching sub graphs, or it can be further
divided by introducing key values. These are non-aggregate expressions, that
are used to group the values going into the aggregate functions.

So, if the return statement looks something like this:

RETURN n, count(*)

We have two return expressions — n, and count(*). The first, n, is no aggregate
function, and so it will be the grouping key. The latter, count(*) is an
aggregate expression. So the matching subgraphs will be divided into different
buckets, depending on the grouping key. The aggregate function will then run on
these buckets, calculating the aggregate values.

The last piece of the puzzle is the DISTINCT keyword. It is used to make all
values unique before running them through an aggregate function.

An example might be helpful:

Query

START me=node(1)
MATCH me-->friend-->friend_of_friend
RETURN count(distinct friend_of_friend), count(friend_of_friend)

In this example we are trying to find all our friends of friends, and count
them. The first aggregate function, count(distinct friend_of_friend), will only
see a friend_of_friend once — DISTINCT removes the duplicates. The latter
aggregate function, count(friend_of_friend), might very well see the same
friend_of_friend multiple times. Since there is no real data in this case, an
empty result is returned. See the sections below for real data.

Table 16.50. Result

+--------------------------------------------------------+
|count(distinct friend_of_friend)|count(friend_of_friend)|
|--------------------------------------------------------|
|1 row                                                   |
|--------------------------------------------------------|
|1 ms                                                    |
|--------------------------------------------------------|
|0                               |0                      |
+--------------------------------------------------------+


The following examples are assuming the example graph structure below.

Graph

cypher-aggregation-graph.svg

16.13.2. COUNT

COUNT is used to count the number of rows. COUNT can be used in two
forms — COUNT(*) which just counts the number of matching rows, and COUNT
(<identifier>), which counts the number of non-null values in <identifier>.

16.13.3. Count nodes

To count the number of nodes, for example the number of nodes connected to one
node, you can use count(*).

Query

START n=node(2)
MATCH (n)-->(x)
RETURN n, count(*)

The start node and the count of related nodes.

Table 16.51. Result

+--------------------------------------+
|n                            |count(*)|
|--------------------------------------|
|1 row                                 |
|--------------------------------------|
|0 ms                                  |
|--------------------------------------|
|Node[2]{name:"A",property:13}|3       |
+--------------------------------------+


16.13.4. Group Count Relationship Types

To count the groups of relationship types, return the types and count them with
count(*).

Query

START n=node(2)
MATCH (n)-[r]->()
RETURN type(r), count(*)

The relationship types and their group count.

Table 16.52. Result

+-----------------+
|type(r)|count(*) |
|-----------------|
|1 row            |
|-----------------|
|0 ms             |
|-----------------|
|"KNOWS"|3        |
+-----------------+


16.13.5. Count entities

Instead of counting the number of results with count(*), it might be more
expressive to include the name of the identifier you care about.

Query

START n=node(2)
MATCH (n)-->(x)
RETURN count(x)

The number of connected nodes from the start node.

Table 16.53. Result

+--------+
|count(x)|
|--------|
|1 row   |
|--------|
|0 ms    |
|--------|
|3       |
+--------+


16.13.6. Count non-null values

You can count the non-null values by using count(<identifier>).

Query

START n=node(2,3,4,1)
RETURN count(n.property?)

The count of related nodes.

Table 16.54. Result

+------------------+
|count(n.property?)|
|------------------|
|1 row             |
|------------------|
|0 ms              |
|------------------|
|3                 |
+------------------+


16.13.7. SUM

The SUM aggregation function simply sums all the numeric values it encounters.
Nulls are silently dropped. This is an example of how you can use SUM.

Query

START n=node(2,3,4)
RETURN sum(n.property)

The sum of all the values in the property property.

Table 16.55. Result

+---------------+
|sum(n.property)|
|---------------|
|1 row          |
|---------------|
|0 ms           |
|---------------|
|90             |
+---------------+


16.13.8. AVG

AVG calculates the average of a numeric column.

Query

START n=node(2,3,4)
RETURN avg(n.property)

The average of all the values in the property property.

Table 16.56. Result

+---------------+
|avg(n.property)|
|---------------|
|1 row          |
|---------------|
|0 ms           |
|---------------|
|30.0           |
+---------------+


16.13.9. MAX

MAX find the largets value in a numeric column.

Query

START n=node(2,3,4)
RETURN max(n.property)

The largest of all the values in the property property.

Table 16.57. Result

+---------------+
|max(n.property)|
|---------------|
|1 row          |
|---------------|
|0 ms           |
|---------------|
|44             |
+---------------+


16.13.10. MIN

MIN takes a numeric property as input, and returns the smallest value in that
column.

Query

START n=node(2,3,4)
RETURN min(n.property)

The smallest of all the values in the property property.

Table 16.58. Result

+---------------+
|min(n.property)|
|---------------|
|1 row          |
|---------------|
|0 ms           |
|---------------|
|13             |
+---------------+


16.13.11. COLLECT

COLLECT collects all the values into a list.

Query

START n=node(2,3,4)
RETURN collect(n.property)

Returns a single row, with all the values collected.

Table 16.59. Result

+-------------------+
|collect(n.property)|
|-------------------|
|1 row              |
|-------------------|
|0 ms               |
|-------------------|
|[13,33,44]         |
+-------------------+


16.13.12. DISTINCT

All aggregation functions also take the DISTINCT modifier, which removes
duplicates from the values. So, to count the number of unique eye colors from
nodes related to a, this query can be used:

Query

START a=node(2)
MATCH a-->b
RETURN count(distinct b.eyes)

Returns the number of eye colors.

Table 16.60. Result

+----------------------+
|count(distinct b.eyes)|
|----------------------|
|1 row                 |
|----------------------|
|0 ms                  |
|----------------------|
|2                     |
+----------------------+


16.14. Order by

To sort the output, use the ORDER BY clause. Note that you can not sort on
nodes or relationships, just on properties on these.

Graph

cypher-orderby-graph.svg

16.14.1. Order nodes by property

ORDER BY is used to sort the output

Query

START n=node(3,1,2)
RETURN n
ORDER BY n.name

The nodes, sorted by their name.

Table 16.61. Result

+-----------------------------------+
|n                                  |
|-----------------------------------|
|3 rows                             |
|-----------------------------------|
|0 ms                               |
|-----------------------------------|
|Node[1]{name:"A",age:34,length:170}|
|-----------------------------------|
|Node[2]{name:"B",age:34}           |
|-----------------------------------|
|Node[3]{name:"C",age:32,length:185}|
+-----------------------------------+


16.14.2. Order nodes by multiple properties

You can order by multiple properties by stating each identifier in the ORDER BY
statement. Cypher will sort the result by the first identifier listed, and for
equals values, go to the next property in the order by, and so on.

Query

START n=node(3,1,2)
RETURN n
ORDER BY n.age, n.name

The nodes, sorted first by their age, and then by their name.

Table 16.62. Result

+-----------------------------------+
|n                                  |
|-----------------------------------|
|3 rows                             |
|-----------------------------------|
|0 ms                               |
|-----------------------------------|
|Node[3]{name:"C",age:32,length:185}|
|-----------------------------------|
|Node[1]{name:"A",age:34,length:170}|
|-----------------------------------|
|Node[2]{name:"B",age:34}           |
+-----------------------------------+


16.14.3. Order nodes in descending order

By adding DESC[ENDING] after the identifier to sort on, the sort will be done
in reverse order.

Query

START n=node(3,1,2)
RETURN n
ORDER BY n.name DESC

The nodes, sorted by their name reversely.

Table 16.63. Result

+-----------------------------------+
|n                                  |
|-----------------------------------|
|3 rows                             |
|-----------------------------------|
|0 ms                               |
|-----------------------------------|
|Node[3]{name:"C",age:32,length:185}|
|-----------------------------------|
|Node[2]{name:"B",age:34}           |
|-----------------------------------|
|Node[1]{name:"A",age:34,length:170}|
+-----------------------------------+


16.14.4. Ordering null

When sorting the result set, null will always come at the end of the result set
for ascending sorting, and first when doing descending sort.

Query

START n=node(3,1,2)
RETURN n.length?, n
ORDER BY n.length?

The nodes sorted by the length property, with a node without that property
last.

Table 16.64. Result

+---------------------------------------------+
|n.length?|n                                  |
|---------------------------------------------|
|3 rows                                       |
|---------------------------------------------|
|0 ms                                         |
|---------------------------------------------|
|170      |Node[1]{name:"A",age:34,length:170}|
|---------+-----------------------------------|
|185      |Node[3]{name:"C",age:32,length:185}|
|---------+-----------------------------------|
|<null>   |Node[2]{name:"B",age:34}           |
+---------------------------------------------+


16.15. Skip

SKIP enables the return of only subsets of the total result. By using SKIP, the
result set will trimmed from the top. Please note that no guarantees are made
on the order of the result unless the query specifies the ORDER BY clause.

Graph

cypher-skip-graph.svg

16.15.1. Skip first three

To return a subset of the result, starting from third result, use this syntax:

Query

START n=node(3, 4, 5, 1, 2)
RETURN n
ORDER BY n.name
SKIP 3

The first three nodes are skipped, and only the last two are returned.

Table 16.65. Result

+-----------------+
|n                |
|-----------------|
|2 rows           |
|-----------------|
|0 ms             |
|-----------------|
|Node[1]{name:"D"}|
|-----------------|
|Node[2]{name:"E"}|
+-----------------+


16.15.2. Return middle two

To return a subset of the result, starting from somewhere in the middle, use
this syntax:

Query

START n=node(3, 4, 5, 1, 2)
RETURN n
ORDER BY n.name
SKIP 1
LIMIT 2

Two nodes from the middle are returned

Table 16.66. Result

+-----------------+
|n                |
|-----------------|
|2 rows           |
|-----------------|
|0 ms             |
|-----------------|
|Node[4]{name:"B"}|
|-----------------|
|Node[5]{name:"C"}|
+-----------------+


16.16. Limit

LIMIT enables the return of only subsets of the total result.

Graph

cypher-limit-graph.svg

16.16.1. Return first part

To return a subset of the result, starting from the top, use this syntax:

Query

START n=node(3, 4, 5, 1, 2)
RETURN n
LIMIT 3

The top three items are returned

Table 16.67. Result

+-----------------+
|n                |
|-----------------|
|3 rows           |
|-----------------|
|0 ms             |
|-----------------|
|Node[3]{name:"A"}|
|-----------------|
|Node[4]{name:"B"}|
|-----------------|
|Node[5]{name:"C"}|
+-----------------+


16.17. With

The ability to chain queries together allows for powerful constructs. In
Cypher, the WITH clause is used to pipe the result from one query to the next.

WITH is also used to separate reading from updating of the graph. Every
sub-query of a query must either be a read-only or a write-only.

Graph

cypher-with-graph.svg

16.17.1. Filter on aggregate function results

Aggregated results have to pass through a WITH clause to be able to filter on.

Query

START david=node(1)
MATCH david--otherPerson-->()
WITH otherPerson, count(*) as foaf
WHERE foaf > 1
RETURN otherPerson

The person connected to David with the at least more than one outgoing
relationship.

Table 16.68. Result

+----------------------+
|otherPerson           |
|----------------------|
|1 row                 |
|----------------------|
|0 ms                  |
|----------------------|
|Node[3]{name:"Anders"}|
+----------------------+


16.17.2. Alternative syntax of with

If you prefer a more visual way of writing your query, you can use equal-signs
as delimiters before and after the column list. Use at least three before the
column list, and at least after.

Query

START david=node(1)
MATCH david--otherPerson-->()
========== otherPerson, count(*) as foaf ==========
SET otherPerson.connection_count = foaf

The person connected to David with the at least more than one outgoing
relationship.

Table 16.69. Result

+-----------------+
|Properties set: 2|
|-----------------|
|1 ms             |
|-----------------|
|(empty result)   |
+-----------------+


16.18. Create

Creating graph elements - nodes and relationships, is done with CREATE.

16.18.1. Create single node

Creating a single node is done by issuing the following query.

Query

CREATE n

Nothing is returned from this query, except the count of affected nodes.

Table 16.70. Result

+----------------+
|Nodes created: 1|
|----------------|
|0 ms            |
|----------------|
|(empty result)  |
+----------------+


16.18.2. Create single node and set properties

The values for the properties can be any scalar expressions.

Query

CREATE n = {name : 'Andres', title : 'Developer'}

Nothing is returned from this query.

Table 16.71. Result

+-----------------+
|Nodes created: 1 |
|-----------------|
|Properties set: 2|
|-----------------|
|1 ms             |
|-----------------|
|(empty result)   |
+-----------------+


16.18.3. Return created node

Creating a single node is done by issuing the following query.

Query

CREATE (a {name : 'Andres'})
RETURN a

The newly created node is returned. This query uses the alternative syntax,
which fits with how RELATE looks.

Table 16.72. Result

+----------------------+
|a                     |
|----------------------|
|1 row                 |
|----------------------|
|Nodes created: 1      |
|----------------------|
|Properties set: 1     |
|----------------------|
|1 ms                  |
|----------------------|
|Node[1]{name:"Andres"}|
+----------------------+


16.18.4. Create a relationship between two nodes

To create a relationship between two nodes, we first get the two nodes. Once
the nodes are loaded, we simply create a relationship between them.

Query

START a=node(1), b=node(2)
CREATE a-[r:REL]->b
RETURN r

The created relationship is returned.

Table 16.73. Result

+------------------------+
|r                       |
|------------------------|
|1 row                   |
|------------------------|
|Relationships created: 1|
|------------------------|
|2 ms                    |
|------------------------|
|:REL[0] {}              |
+------------------------+


16.18.5. Create a relationship and set properties

Setting properties on relationships is done in a similar manner to how it’s
done when creating nodes.Note that the values can be any expression.

Query

START a=node(1), b=node(2)
CREATE a-[r:REL {name : a.name + '<->' + b.name }]->b
RETURN r

The newly created relationship is returned.

Table 16.74. Result

+---------------------------------+
|r                                |
|---------------------------------|
|1 row                            |
|---------------------------------|
|Relationships created: 1         |
|---------------------------------|
|Properties set: 1                |
|---------------------------------|
|2 ms                             |
|---------------------------------|
|:REL[0] {name:"Andres<->Michael"}|
+---------------------------------+


16.18.6. Create a full path

When you use CREATE and a pattern, all parts of the pattern that are not
already in scope at this time will be created.

Query

CREATE (andres {name:'Andres'})-[:WORKS_AT]->neo<-[:WORKS_AT]-(michael {name:'Michael'})
RETURN andres,michael

This query creates three nodes and two relationships in one go, and returns the
end point of the created path

Table 16.75. Result

+----------------------------------------------+
|andres                |michael                |
|----------------------------------------------|
|1 row                                         |
|----------------------------------------------|
|Nodes created: 3                              |
|----------------------------------------------|
|Relationships created: 2                      |
|----------------------------------------------|
|Properties set: 2                             |
|----------------------------------------------|
|3 ms                                          |
|----------------------------------------------|
|Node[1]{name:"Andres"}|Node[3]{name:"Michael"}|
+----------------------------------------------+


16.18.7. Create single node from map

You can also create a graph entity from a Map<String,Object> map. All the key/
value pairs in the map will be set as properties on the created relationship or
node.

Query

create node {props}

This query can be used in the following fashion:

Map<String, Object> props = new HashMap<String, Object>();
props.put( "name", "Andres" );
props.put( "position", "Developer" );

Map<String, Object> params = new HashMap<String, Object>();
params.put( "props", props );
engine.execute( "create ({props})", params );

16.18.8. Create multiple nodes from maps

By providing an iterable of maps (Iterable<Map<String,Object>>), Cypher will
create a node for each map in the iterable. When you do this, you can’t create
anything else in the same create statement.

Query

create node {props}

This query can be used in the following fashion:

Map<String, Object> n1 = new HashMap<String, Object>();
n1.put( "name", "Andres" );
n1.put( "position", "Developer" );

Map<String, Object> n2 = new HashMap<String, Object>();
n2.put( "name", "Michael" );
n2.put( "position", "Developer" );

Map<String, Object> params = new HashMap<String, Object>();
List<Map<String, Object>> maps = Arrays.asList(n1, n2);
params.put( "props", maps);
engine.execute("create (n {props}) return n", params);

16.19. Delete

Removing graph elements - nodes, relationships and properties, is done with
DELETE.

16.19.1. Delete single node

To remove a node from the graph, you can delete it with the DELETE clause.

Query

START n = node(4)
DELETE n

Nothing is returned from this query, except the count of affected nodes.

Table 16.76. Result

+----------------+
|Nodes deleted: 1|
|----------------|
|0 ms            |
|----------------|
|(empty result)  |
+----------------+


16.19.2. Remove a node and connected relationships

If you are trying to remove a node with relationships on it, you have to remove
these as well.

Query

START n = node(3)
MATCH n-[r]-()
DELETE n, r

Nothing is returned from this query, except the count of affected nodes.

Table 16.77. Result

+------------------------+
|Nodes deleted: 1        |
|------------------------|
|Relationships deleted: 2|
|------------------------|
|2 ms                    |
|------------------------|
|(empty result)          |
+------------------------+


16.19.3. Remove a property

Neo4j doesn’t allow storing null in properties. Instead, if no value exists,
the property isjust not there. So, to remove a property value on a node or a
relationship, is also done with DELETE.

Query

START andres = node(3)
DELETE andres.age
RETURN andres

The node is returned, and no property age exists on it.

Table 16.78. Result

+----------------------+
|andres                |
|----------------------|
|1 row                 |
|----------------------|
|Properties set: 1     |
|----------------------|
|2 ms                  |
|----------------------|
|Node[3]{name:"Andres"}|
+----------------------+


16.20. Set

Updating properties on nodes and relationships is done with the SET clause.

16.20.1. Set a property

To set a property on a node or relationship, use SET

Query

START n = node(2)
SET n.surname = 'Taylor'
RETURN n

The newly changes node is returned

Table 16.79. Result

+----------------------------------------------+
|n                                             |
|----------------------------------------------|
|1 row                                         |
|----------------------------------------------|
|Properties set: 1                             |
|----------------------------------------------|
|1 ms                                          |
|----------------------------------------------|
|Node[2]{name:"Andres",age:36,surname:"Taylor"}|
+----------------------------------------------+


16.21. Relate

RELATE is in the middle of MATCH and CREATE - it will match what it can, and
create what is missing. RELATE will always make the least change possible to
the graph - if it can use parts of the existing graph, it will.

Another difference to MATCH is that RELATE assumes the pattern to be unique. If
multiple matching subgraphs are found an exception will be thrown.

16.21.1. Create relationship if it is missing

RELATE is used to describe the pattern that should be found or created.

Query

START left=node(1), right=node(3,4)
RELATE left-[r:KNOWS]->right
RETURN r

The left node is matched agains the two right nodes. One relationship already
exists and can be matched, and the other relationship is created before it is
returned.

Table 16.80. Result

+------------------------+
|r                       |
|------------------------|
|2 rows                  |
|------------------------|
|Relationships created: 1|
|------------------------|
|16 ms                   |
|------------------------|
|:KNOWS[4] {}            |
|------------------------|
|:KNOWS[3] {}            |
+------------------------+


16.21.2. Create node if missing

If the pattern described needs a node, and it can’t be matched, a new node will
be created.

Query

START root=node(2)
RELATE root-[:LOVES]-someone
RETURN someone

The root node doesn’t have any LOVES relationships, and so a node is created,
and also a relationship to that node.

Table 16.81. Result

+------------------------+
|someone                 |
|------------------------|
|1 row                   |
|------------------------|
|Nodes created: 1        |
|------------------------|
|Relationships created: 1|
|------------------------|
|4 ms                    |
|------------------------|
|Node[5]{}               |
+------------------------+


16.21.3. Create nodes with values

The pattern described can also contain values on the node. These are given
using the JSON-like prop : <expression> syntax.

Query

START root=node(2)
RELATE root-[:X]-(leaf {name:'D'} )
RETURN leaf

Node node connected with the root node has the name D, and so a new node needs
to be created to match the pattern.

Table 16.82. Result

+------------------------+
|leaf                    |
|------------------------|
|1 row                   |
|------------------------|
|Nodes created: 1        |
|------------------------|
|Relationships created: 1|
|------------------------|
|Properties set: 1       |
|------------------------|
|30 ms                   |
|------------------------|
|Node[5]{name:"D"}       |
+------------------------+


16.21.4. Create relationship with values

Relationships created can also be matched on values.

Query

START root=node(2)
RELATE root-[r:X {since:'forever'}]-()
RETURN r

In this example, we want the relationship to have a value, and since no such
relationship can be found, a new node and relationship are created. Note that
since we are not interested in the created node, we don’t name it.

Table 16.83. Result

+------------------------+
|r                       |
|------------------------|
|1 row                   |
|------------------------|
|Nodes created: 1        |
|------------------------|
|Relationships created: 1|
|------------------------|
|Properties set: 1       |
|------------------------|
|3 ms                    |
|------------------------|
|:X[4] {since:"forever"} |
+------------------------+


16.21.5. Describe complex pattern

The pattern described by RELATE can be separated by commas, just like in MATCH
and CREATE

Query

START root=node(2)
RELATE root-[:FOO]->x, root-[:BAR]->x
RETURN x

This example pattern uses two paths, separated by a comma.

Table 16.84. Result

+------------------------+
|x                       |
|------------------------|
|1 row                   |
|------------------------|
|Nodes created: 1        |
|------------------------|
|Relationships created: 2|
|------------------------|
|3 ms                    |
|------------------------|
|Node[5]{}               |
+------------------------+


16.22. Foreach

Collections and paths are key concepts in Cypher. To use them for updating
data, you can use the FOREACH construct. It allows you to do updating commands
on elements in a collection - a path, or a collection created by aggregation.

16.22.1. Mark all nodes along a path

This query will set the property marked to true on all nodes along a path.

Query

START begin = node(2), end = node(1)
MATCH p = begin -[*]-> end foreach(n in nodes(p) :
SET n.marked = true)

Nothing is returned from this query

Table 16.85. Result

+-----------------+
|Properties set: 4|
|-----------------|
|4 ms             |
|-----------------|
|(empty result)   |
+-----------------+


16.23. Functions

Most functions in Cypher will return null if the input parameter is null.

Here is a list of the functions in Cypher, seperated into three different
sections: Predicates, Scalar functions and Aggregated functions

Graph

cypher-functions-graph.svg

16.23.1. Predicates

Predicates are boolean functions that return true or false for a given set of
input. They are most commonly used to filter out subgraphs in the WHERE part of
a query.

16.23.1.1. ALL

Tests whether a predicate holds for all element of this iterable collection.

Syntax: ALL(identifier in iterable WHERE predicate)

Arguments:

  * iterable: An array property, or an iterable symbol, or an iterable
    function.
  * identifier: This is the identifier that can be used from the predicate.
  * predicate: A predicate that is tested against all items in iterable

Query

START a=node(3), b=node(1)
MATCH p=a-[*1..3]->b
WHERE all(x in nodes(p)
WHERE x.age > 30)
RETURN p

All nodes in the path.

Table 16.86. Result

+-----------------------------------------------------------------------------+
|p                                                                            |
|-----------------------------------------------------------------------------|
|1 row                                                                        |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|[Node[3]{name:"A",age:38,eyes:"brown"},:KNOWS[1] {},Node[5]                  |
|{name:"C",age:53,eyes:"green"},:KNOWS[3] {},Node[1]                          |
|{name:"D",age:54,eyes:"brown"}]                                              |
+-----------------------------------------------------------------------------+


16.23.1.2. ANY

Tests whether a predicate holds for at least one element of this iterable
collection.

Syntax: ANY(identifier in iterable WHERE predicate)

Arguments:

  * iterable: An array property, or an iterable symbol, or an iterable
    function.
  * identifier: This is the identifier that can be used from the predicate.
  * predicate: A predicate that is tested against all items in iterable

Query

START a=node(2)
WHERE any(x in a.array
WHERE x = "one")
RETURN a

All nodes in the path.

Table 16.87. Result

+----------------------------------------------------------------+
|a                                                               |
|----------------------------------------------------------------|
|1 row                                                           |
|----------------------------------------------------------------|
|0 ms                                                            |
|----------------------------------------------------------------|
|Node[2]{name:"E",age:41,eyes:"blue",array:["one","two","three"]}|
+----------------------------------------------------------------+


16.23.1.3. NONE

Returns true if the predicate holds for no element in the iterable.

Syntax: NONE(identifier in iterable WHERE predicate)

Arguments:

  * iterable: An array property, or an iterable symbol, or an iterable
    function.
  * identifier: This is the identifier that can be used from the predicate.
  * predicate: A predicate that is tested against all items in iterable

Query

START n=node(3)
MATCH p=n-[*1..3]->b
WHERE NONE(x in nodes(p)
WHERE x.age = 25)
RETURN p

All nodes in the path.

Table 16.88. Result

+-----------------------------------------------------------------------------+
|p                                                                            |
|-----------------------------------------------------------------------------|
|2 rows                                                                       |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|[Node[3]{name:"A",age:38,eyes:"brown"},:KNOWS[1] {},Node[5]                  |
|{name:"C",age:53,eyes:"green"}]                                              |
|-----------------------------------------------------------------------------|
|[Node[3]{name:"A",age:38,eyes:"brown"},:KNOWS[1] {},Node[5]                  |
|{name:"C",age:53,eyes:"green"},:KNOWS[3] {},Node[1]                          |
|{name:"D",age:54,eyes:"brown"}]                                              |
+-----------------------------------------------------------------------------+


16.23.1.4. SINGLE

Returns true if the predicate holds for exactly one of the elements in the
iterable.

Syntax: SINGLE(identifier in iterable WHERE predicate)

Arguments:

  * iterable: An array property, or an iterable symbol, or an iterable
    function.
  * identifier: This is the identifier that can be used from the predicate.
  * predicate: A predicate that is tested against all items in iterable

Query

START n=node(3)
MATCH p=n-->b
WHERE SINGLE(var in nodes(p)
WHERE var.eyes = "blue")
RETURN p

All nodes in the path.

Table 16.89. Result

+-----------------------------------------------------------------------------+
|p                                                                            |
|-----------------------------------------------------------------------------|
|1 row                                                                        |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|[Node[3]{name:"A",age:38,eyes:"brown"},:KNOWS[0] {},Node[4]                  |
|{name:"B",age:25,eyes:"blue"}]                                               |
+-----------------------------------------------------------------------------+


16.23.2. Scalar functions

Scalar functions return a single value.

16.23.2.1. LENGTH

To return or filter on the length of a path, use the special property LENGTH

Syntax: LENGTH( iterable )

Arguments:

  * iterable: An iterable, value or function call

Query

START a=node(3)
MATCH p=a-->b-->c
RETURN length(p)

The length of the path p.

Table 16.90. Result

+---------+
|length(p)|
|---------|
|3 rows   |
|---------|
|0 ms     |
|---------|
|2        |
|---------|
|2        |
|---------|
|2        |
+---------+


16.23.2.2. TYPE

Returns a string representation of the relationship type.

Syntax: TYPE( relationship )

Arguments:

  * relationship: A relationship

Query

START n=node(3)
MATCH (n)-[r]->()
RETURN type(r)

The relationship type of r.

Table 16.91. Result

+-------+
|type(r)|
|-------|
|2 rows |
|-------|
|0 ms   |
|-------|
|"KNOWS"|
|-------|
|"KNOWS"|
+-------+


16.23.2.3. ID

Returns the id of the relationship or node

Syntax: ID( property-container )

Arguments:

  * property-container: A node or a relationship

Query

START a=node(3, 4, 5)
RETURN ID(a)

The node id for three nodes.

Table 16.92. Result

+------+
|ID(a) |
|------|
|3 rows|
|------|
|0 ms  |
|------|
|3     |
|------|
|4     |
|------|
|5     |
+------+


16.23.2.4. COALESCE

Returns the first non-null value in the list of expressions passed to it.

Syntax: COALESCE( expression [, expression]* )

Arguments:

  * expression: The expression that might return null

Query

START a=node(3)
RETURN coalesce(a.hairColour?, a.eyes?)

Table 16.93. Result

+--------------------------------+
|coalesce(a.hairColour?, a.eyes?)|
|--------------------------------|
|1 row                           |
|--------------------------------|
|0 ms                            |
|--------------------------------|
|"brown"                         |
+--------------------------------+


16.23.2.5. HEAD

HEAD returns the first element in a collection.

Syntax: HEAD( expression )

Arguments:

  * expression: This expression should return a collection of some sort.

Query

START a=node(2)
RETURN a.array, head(a.array)

The first node in the path

Table 16.94. Result

+-----------------------------------+
|a.array              |head(a.array)|
|-----------------------------------|
|1 row                              |
|-----------------------------------|
|0 ms                               |
|-----------------------------------|
|["one","two","three"]|"one"        |
+-----------------------------------+


16.23.2.6. LAST

LAST returns the last element in a collection.

Syntax: LAST( expression )

Arguments:

  * expression: This expression should return a collection of some sort.

Query

START a=node(2)
RETURN a.array, last(a.array)

The first node in the path

Table 16.95. Result

+-----------------------------------+
|a.array              |last(a.array)|
|-----------------------------------|
|1 row                              |
|-----------------------------------|
|0 ms                               |
|-----------------------------------|
|["one","two","three"]|"three"      |
+-----------------------------------+


16.23.3. Iterable functions

Iterable functions return an iterable of things - nodes in a path, and so on.

16.23.3.1. NODES

Returns all nodes in a path

Syntax: NODES( path )

Arguments:

  * path: A path

Query

START a=node(3), c=node(2)
MATCH p=a-->b-->c
RETURN NODES(p)

All the nodes in the path p.

Table 16.96. Result

+-----------------------------------------------------------------------------+
|NODES(p)                                                                     |
|-----------------------------------------------------------------------------|
|1 row                                                                        |
|-----------------------------------------------------------------------------|
|0 ms                                                                         |
|-----------------------------------------------------------------------------|
|[Node[3]{name:"A",age:38,eyes:"brown"},Node[4]                               |
|{name:"B",age:25,eyes:"blue"},Node[2]{name:"E",age:41,eyes:"blue",array:     |
|["one","two","three"]}]                                                      |
+-----------------------------------------------------------------------------+


16.23.3.2. RELATIONSHIPS

Returns all relationships in a path

Syntax: RELATIONSHIPS( path )

Arguments:

  * path: A path

Query

START a=node(3), c=node(2)
MATCH p=a-->b-->c
RETURN RELATIONSHIPS(p)

All the nodes in the path p.

Table 16.97. Result

+-----------------------------+
|RELATIONSHIPS(p)             |
|-----------------------------|
|1 row                        |
|-----------------------------|
|0 ms                         |
|-----------------------------|
|[:KNOWS[0] {},:MARRIED[4] {}]|
+-----------------------------+


16.23.3.3. EXTRACT

To return a single property, or the value of a function from an iterable of
nodes or relationships, you can use EXTRACT. It will go through all enitities
in the iterable, and run an expression, and return the results in an iterable
with these values. It works like the map method in functional languages such as
Lisp and Scala.

Syntax: EXTRACT( identifier in iterable : expression )

Arguments:

  * iterable: An array property, or an iterable identifier, or an iterable
    function.
  * identifier: The closure will have an identifier introduced in it’s context.
    Here you decide which identifier to use.
  * expression: This expression will run once per value in the iterable, and
    produces the result iterable.

Query

START a=node(3), b=node(4), c=node(1)
MATCH p=a-->b-->c
RETURN extract(n in nodes(p) : n.age)

The age property of all nodes in the path.

Table 16.98. Result

+------------------------------+
|extract(n in nodes(p) : n.age)|
|------------------------------|
|1 row                         |
|------------------------------|
|0 ms                          |
|------------------------------|
|[38,25,54]                    |
+------------------------------+


16.23.3.4. FILTER

FILTER returns all the elements in an iterable that comply to a predicate.

Syntax: FILTER(identifier in iterable : predicate)

Arguments:

  * iterable: An array property, or an iterable symbol, or an iterable
    function.
  * identifier: This is the identifier that can be used from the predicate.
  * predicate: A predicate that is tested against all items in iterable

Query

START a=node(2)
RETURN a.array, filter(x in a.array : length(x) = 3)

The first node in the path

Table 16.99. Result

+----------------------------------------------------------+
|a.array              |filter(x in a.array : length(x) = 3)|
|----------------------------------------------------------|
|1 row                                                     |
|----------------------------------------------------------|
|0 ms                                                      |
|----------------------------------------------------------|
|["one","two","three"]|["one","two"]                       |
+----------------------------------------------------------+


16.23.3.5. TAIL

TAIL returns all but the first element in a collection.

Syntax: TAIL( expression )

Arguments:

  * expression: This expression should return a collection of some sort.

Query

START a=node(2)
RETURN a.array, tail(a.array)

The first node in the path

Table 16.100. Result

+-------------------------------------+
|a.array              |tail(a.array)  |
|-------------------------------------|
|1 row                                |
|-------------------------------------|
|0 ms                                 |
|-------------------------------------|
|["one","two","three"]|["two","three"]|
+-------------------------------------+


16.23.3.6. RANGE

Returns numerical values in range [start;end) with non-zero step value step.
Range is inclusive in both ends.

Syntax: RANGE( start, end [, step] )

Arguments:

  * start: A numerical expression
  * end: A numerical expression
  * step: A numerical expression

Query

START n=node(1)
RETURN range(0,10), range(2,18,3)

Two lists of numbers.

Table 16.101. Result

+-----------------------------------------+
|range(0,10)             |range(2,18,3)   |
|-----------------------------------------|
|1 row                                    |
|-----------------------------------------|
|0 ms                                     |
|-----------------------------------------|
|[0,1,2,3,4,5,6,7,8,9,10]|[2,5,8,11,14,17]|
+-----------------------------------------+


16.23.4. Mathematical functions

These functions all operate on numerical expressions only, and will return an
error if used on any other values.

16.23.4.1. ABS

Returns the absolute value of a number

Syntax: ABS( expression )

Arguments:

  * expression: A numeric expression

Query

START a=node(3), c=node(2)
RETURN a.age, c.age, abs(a.age - c.age)

The absolute value of age difference

Table 16.102. Result

+-------------------------------+
|a.age|c.age|abs(a.age - c.age) |
|-------------------------------|
|1 row                          |
|-------------------------------|
|0 ms                           |
|-------------------------------|
|38   |41   |3.0                |
+-------------------------------+


16.23.4.2. ROUND

ROUND returns the numerical expression, rounded to the nearest integer.

Syntax: ROUND( expression )

Arguments:

  * expression: A numerical expression

Query

START a=node(1)
RETURN round(3.141592)

Table 16.103. Result

+---------------+
|round(3.141592)|
|---------------|
|1 row          |
|---------------|
|0 ms           |
|---------------|
|3              |
+---------------+


16.23.4.3. SQRT

SQRT returns the square root of a number

Syntax: SQRT( expression )

Arguments:

  * expression: A numerical expression

Query

START a=node(1)
RETURN sqrt(256)

All the nodes in the path p.

Table 16.104. Result

+---------+
|sqrt(256)|
|---------|
|1 row    |
|---------|
|0 ms     |
|---------|
|16.0     |
+---------+


16.23.4.4. SIGN

Returns the signum of a number - zero if the expression is zero, -1 for any
negative number, and 1 for any positive number.

Syntax: SIGN( expression )

Arguments:

  * expression: A numerical expression

Query

START n=node(1)
RETURN sign(-17), sign(0.1)

All the nodes in the path p.

Table 16.105. Result

+-------------------+
|sign(-17)|sign(0.1)|
|-------------------|
|1 row              |
|-------------------|
|0 ms               |
|-------------------|
|-1.0     |1.0      |
+-------------------+


16.24. Compatibility

Cypher is still changing rather rapidly. Parts of the changes are internal - we
add new pattern matchers, aggregators and other optimizations, which hopefully
makes your queries run faster.

Other changes are directly visible to our users - the syntax is still changing.
New concepts are being added and old ones changed to fit into new
possibilities. To guard you from having to keep up with our syntax changes,
Cypher allows you to use an older parser, but still gain the speed from new
optimizations.

There are two ways you can select which parser to use. You can configure your
database with the configuration parameter cypher_parser_version, and enter
which parser you’d like to use (1.6 and 1.7 are supported now). Any Cypher
query that doesn’t explicitly say anything else, will get the parser you have
configured.

The other way is on a query by query basis. By simply pre-pending your query
with "CYPHER 1.6", that particular query will be parsed with the 1.6 version of
the parser. Example:

CYPHER 1.6 START n=node(0)
WHERE n.foo = "bar"
RETURN n

Chapter 17. Graph Algorithms

Neo4j graph algorithms is a component that contains Neo4j implementations of
some common algorithms for graphs. It includes algorithms like:

  * Shortest paths,
  * all paths,
  * all simple paths,
  * Dijkstra and
  * A*.

17.1. Introduction

The graph algorithms are found in the neo4j-graph-algo component, which is
included in the standard Neo4j download.

  * Javadocs <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/
    graphalgo/package-summary.html>
  * Download <http://search.maven.org/#
    search%7Cgav%7C1%7Cg%3A%22org.neo4j%22%20AND%20a%3A%22neo4j-graph-algo%22>
  * Source code <https://github.com/neo4j/community/tree/1.8.M04/graph-algo>

For information on how to use neo4j-graph-algo as a dependency with Maven and
other dependency management tools, see org.neo4j:neo4j-graph-algo <http://
search.maven.org/#
search%7Cgav%7C1%7Cg%3A%22org.neo4j%22%20AND%20a%3A%22neo4j-graph-algo%22> Note
that it should be used with the same version of org.neo4j:neo4j-kernel <http://
search.maven.org/#
search%7Cgav%7C1%7Cg%3A%22org.neo4j%22%20AND%20a%3A%22neo4j-kernel%22>.
Different versions of the graph-algo and kernel components are not compatible
in the general case. Both components are included transitively by the
org.neo4j:neo4j <http://search.maven.org/#
search%7Cgav%7C1%7Cg%3A%22org.neo4j%22%20AND%20a%3A%22neo4j%22> artifact which
makes it simple to keep the versions in sync.

The starting point to find and use graph algorithms is GraphAlgoFactory <http:/
/components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphalgo/
GraphAlgoFactory.html>.

For examples, see Section 4.7, “Graph Algorithm examples” (embedded database)
and Section 19.13, “Built-in Graph Algorithms” (REST API).

Chapter 18. Neo4j Server

18.1. Server Installation

Neo4j can be installed as a server, running either as a headless application or
system service.

 1. Download the latest release from http://neo4j.org/download <http://
    neo4j.org/download>

      * select the appropriate version for your platform
 2. Extract the contents of the archive

      * refer to the top-level extracted directory as NEO4J_HOME
 3. Use the scripts in the bin directory

      * for Linux/MacOS, run $NEO4J_HOME/bin/neo4j start
      * for Windows, double-click on %NEO4J_HOME%\bin\Neo4j.bat
 4. Refer to the packaged information in the doc directory for details

For information on High Availability, please refer to Chapter 23, High
Availability.

18.1.1. As a Windows service

With administrative rights, Neo4j can be installed as a Windows service.

 1. Click Start → All Programs → Accessories
 2. Right click Command Prompt → Run as Administrator
 3. Provide authorization and/or the Administrator password
 4. Navigate to %NEO4J_HOME%
 5. Run bin\Neo4j.bat install

To uninstall, run bin\Neo4j.bat remove as Administrator.

To query the status of the service, run bin\Neo4j.bat status

To start the service from the command prompt, run bin\Neo4j.bat start

To stop the service from the command prompt, run bin\Neo4j.bat stop

Note

Some users have reported problems on Windows when using the ZoneAlarm firewall.
If you are having problems getting large responses from the server, or if
Webadmin does not work, try disabling ZoneAlarm. Contact ZoneAlarm support to
get information on how to resolve this.

18.1.2. Linux Service

Neo4j can participate in the normal system startup and shutdown process. The
following procedure should work on most popular Linux distributions:

 1. cd $NEO4J_HOME
 2. sudo ./bin/neo4j install

    if asked, enter your password to gain super-user privileges

 3. service neo4j-service status

    should indicate that the server is not running

 4. service neo4j-service start

    will start the server

During installation you will be given the option to select the user Neo4j will
run as. You will be asked to supply a username (defaulting to neo4j) and if
that user is not present on the system it will be created as a system account
and the $NEO4J_HOME/data directory will be chown'ed to that user.

You are encouraged to create a dedicated user for running the service and for
that reason it is suggested that you unpack the distribution package under /opt
or your site specific optional packages directory.

After installation you may have to do some platform specific configuration and
performance tuning. For that, refer to Section 22.9, “Linux specific notes”.

Finally, note that if you chose to create a new user account, on uninstall you
will be prompted to remove it from the system.

18.1.3. Mac OSX

18.1.3.1. via Homebrew

Using Homebrew <http://mxcl.github.com/homebrew/>, to install the latest stable
version of Neo4j Server, issue the following command:

brew install neo4j && neo4j start

This will get a Neo4j instance running on http://localhost:7474 <http://
localhost:7474>. The installation files will reside in ls /usr/local/Cellar/
neo4j/community-{NEO4J_VERSION}/libexec/ — to tweak settings and symlink the
database directory if desired.

18.1.3.2. as a Service

Neo4j can be installed as a Mac launchd job:

 1. cd $NEO4J_HOME
 2. ./bin/neo4j install
 3. launchctl list | grep neo

    should reveal the launchd "org.neo4j.server.7474" job for running the Neo4j
    Server

 4. ./bin/neo4j status

    should indicate that the server is running

 5. launchctl stop org.neo4j.server.7474

    should stop the server.

 6. launchctl start org.neo4j.server.7474

    should start the server again.

18.1.4. Multiple Server instances on one machine

Neo4j can be set up to run as several instances on one machine, providing for
instance several databases for development. To configure, install two instances
of the Neo4j Server in two different directories following the steps outlined
below.

18.1.4.1. First instance

First, create a directory to hold both database instances, and unpack the
development instance:

 1. cd $INSTANCE_ROOT
 2. mkdir -p neo4j
 3. cd neo4j
 4. tar -xvzf /path/to/neo4j-community.tar.gz
 5. mv neo4j-community dev

Next, configure the instance by changing the following values in dev/conf/
neo4j-server.properties, see even Section 25.1, “Securing access to the Neo4j
Server”:

org.neo4j.server.webserver.port=7474

# Uncomment the following if the instance will be accessed from a host other than localhost.
org.neo4j.server.webserver.address=0.0.0.0

Before running the Windows install or startup, change in dev/conf/
neo4j-wrapper.properties

# Name of the service for the first instance
wrapper.name=neo4j_1

Start the instance:

dev/bin/neo4j start

Check that instance is available by browsing to http://localhost:7474/webadmin/
<http://localhost:7474/webadmin/>

18.1.4.2. Second instance (testing, development)

In many cases during application development, it is desirable to have one
development database set up, and another against which to run unit tests. For
the following example, we are assuming that both databases will run on the same
host.

Now create the unit testing second instance:

 1. cd $INSTANCE_ROOT/neo4j
 2. tar -xvzf /path/to/neo4j-community.tar.gz
 3. mv neo4j-community test

Next, configure the instance by changing the following values in test/conf/
neo4j-server.properties to

  * change the server port to 7475

# Note the different port number from the development instance
org.neo4j.server.webserver.port=7475

# Uncomment the following if the instance will be accessed from a host other than localhost
org.neo4j.server.webserver.address=0.0.0.0

Differentiate the instance from the development instance by modifying test/conf
/neo4j-wrapper.properties.

wrapper.name=neo4j-test

On Windows, you even need to change the name of the service in bin\neo4j.bat to
be able to run it together with the first instance.

set serviceName=Neo4j-Server-test
set serviceDisplayName=Neo4j-Server-test

Start the instance:

test/bin/neo4j start

Check that instance is available by browsing to http://localhost:7475/webadmin/
<http://localhost:7475/webadmin/>

18.2. Server Configuration

Quick info

  * The server’s primary configuration file is found under conf/
    neo4j-server.properties
  * The conf/log4j.properties file contains the default server logging
    configuration
  * Low-level performance tuning parameters are found in conf/neo4j.properties
  * Configuraion of the deamonizing wrapper are found in conf/
    neo4j-wrapper.properties
  * HTTP logging configuration is found in conf/neo4j-http-logging.xml

18.2.1. Important server configurations parameters

The main configuration file for the server can be found at conf/
neo4j-server.properties. This file contains several important settings, and
although the defaults are sensible administrators might choose to make changes
(especially to the port settings).

Set the location on disk of the database directory like this:

org.neo4j.server.database.location=data/graph.db

Note

On Windows systems, absolute locations including drive letters need to read "c:
/data/db".

Specify the HTTP server port supporting data, administrative, and UI access:

org.neo4j.server.webserver.port=7474

Specify the client accept pattern for the webserver (default is 127.0.0.1,
localhost only):

#allow any client to connect
org.neo4j.server.webserver.address=0.0.0.0

For securing the Neo4j Server, see also Section 25.1, “Securing access to the
Neo4j Server”

Set the location of the round-robin database directory which gathers metrics on
the running server instance:

org.neo4j.server.webadmin.rrdb.location=data/graph.db/../rrd

Set the URI path for the REST data API through which the database is accessed.
This should be a relative path.

org.neo4j.server.webadmin.data.uri=/db/data/

Setting the management URI for the administration API that the Webadmin tool
uses. This should be a relative path.

org.neo4j.server.webadmin.management.uri=/db/manage

Force the server to use IPv4 network addresses, in conf/neo4j-wrapper.conf
under the section Java Additional Parameters add a new paramter:

wrapper.java.additional.3=-Djava.net.preferIPv4Stack=true

Low-level performance tuning parameters can be explicitly set by referring to
the following property:

org.neo4j.server.db.tuning.properties=neo4j.properties

If this property isn’t set, the server will look for a file called 
neo4j.properties in the same directory as the neo4j-server.properties file.

If this property isn’t set, and there is no neo4j.properties file in the
default configuration directory, then the server will log a warning.
Subsequently at runtime the database engine will attempt tune itself based on
the prevailing conditions.

18.2.2. Neo4j Database performance configuration

The fine-tuning of the low-level Neo4j graph database engine is specified in a
separate properties file, conf/neo4j.properties.

The graph database engine has a range of performance tuning options which are
enumerated in Section 18.5, “Server Performance Tuning”. Note that other
factors than Neo4j tuning should be considered when performance tuning a
server, including general server load, memory and file contention, and even
garbage collection penalties on the JVM, though such considerations are beyond
the scope of this configuration document.

18.2.3. Server logging configuration

Application events within Neo4j server are processed with java.util.logging
<http://download.oracle.com/javase/6/docs/technotes/guides/logging/
overview.html> and configured in the file conf/logging.properties.

By default it is setup to print INFO level messages both on screen and in a
rolling file in data/log. Most deployments will choose to use their own
configuration here to meet local standards. During development, much useful
information can be found in the logs so some form of logging to disk is well
worth keeping. On the other hand, if you want to completely silence the console
output, set:

java.util.logging.ConsoleHandler.level=OFF

By default log files are rotated at approximately 10Mb and named consecutively
neo4j.<id>.<rotation sequence #>.log To change the naming scheme, rotation
frequency and backlog size modify

java.util.logging.FileHandler.pattern
java.util.logging.FileHandler.limit
java.util.logging.FileHandler.count

respectively to your needs. Details are available at the Javadoc for
java.util.logging.FileHandler <http://download.oracle.com/javase/6/docs/api/
java/util/logging/FileHandler.html>.

Apart from log statements originating from the Neo4j server, other libraries
report their messages through various frameworks.

Zookeeper is hardwired to use the log4j logging framework. The bundled conf/
log4j.properties applies for this use only and uses a rolling appender and
outputs logs by default to the data/log directory.

18.2.4. HTTP logging configuration

As well as logging events happening within the Neo4j server, it is possible to
log the HTTP requests and responses that the server consumes and produces.
Configuring HTTP logging requires operators to enable and configure the logger
and where it will log; and then to optionally configure the log format.

Warning

By default the HTTP logger uses Common Log Format <http://en.wikipedia.org/wiki
/Common_Log_Format> meaning that most Web server tooling can automtically
consume such logs. In general users should only enable HTTP logging, select an
output directory, and if necessary alter the rollover and retention policies.

To enable HTTP logging, edit the conf/neo4j-server.properties file resemble the
following:

[source]
----
org.neo4j.server.http.log.enabled=true
org.neo4j.server.http.log.config=conf/neo4j-http-logging.xml
----

org.neo4j.server.http.log.enabled=true tells the server that HTTP logging is
enabled. HTTP logging can be totally disabled by setting this property to false
. org.neo4j.server.http.log.config=conf/neo4j-http-logging.xml specifies the
logging format and rollover policy file that governs how HTTP log output is
presented and archived. The defaults provided with Neo4j server uses an hourly
log rotation and Common Log Format <http://en.wikipedia.org/wiki/
Common_Log_Format>.

If logging is set up to use log files then the server will check that the log
file directory exists and is writable. If this check fails, then the server
will not startup and wil report the failure another available channel like
standard out.

18.2.5. Other configuration options

18.2.5.1. Enabling logging from the garbage collector

To get garbage collection logging output you have to pass the corresponding
option to the server JVM executable by setting in conf/neo4j-wrapper.conf the
value

wrapper.java.additional.3=-Xloggc:data/log/neo4j-gc.log

This line is already present and needs uncommenting. Note also that logging is
not directed to console ; You will find the logging statements in data/log/
ne4j-gc.log or whatever directory you set at the option.

18.3. Setup for remote debugging

In order to configure the Neo4j server for remote debugging sessions, the Java
debugging parameters need to be passed to the Java process through the
configuration. They live in the conf/neo4j-wrapper.properties file.

In order to specify the parameters, add a line for the additional Java
arguments like this:

# Java Additional Parameters
wrapper.java.additional.1=-Dorg.neo4j.server.properties=conf/neo4j-server.properties
wrapper.java.additional.2=-Dlog4j.configuration=file:conf/log4j.properties
wrapper.java.additional.3=-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -Xdebug-Xnoagent-Djava.compiler=NONE-Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005

This configuration will start a Neo4j server ready for remote debugging
attachement at localhost and port 5005. Use these parameters to attach to the
process from Eclipse, IntelliJ or your remote debugger of choice after starting
the server.

18.4. Using the server (including web administration) with an embedded database

Even if you are using the Neo4j Java API directly, for instance via
EmbeddedGraphDatabase or HighlyAvailableGraphDatabase, you can still use the
features the server provides.

18.4.1. Getting the libraries

18.4.1.1. From the Neo4j Server installation

To run the server all the libraries you need are in the system/lib/ directory
of the download package <http://neo4j.org/download/>. For further instructions,
see Section 4.1, “Include Neo4j in your project”. The only difference to the
embedded setup is that system/lib/ should be added as well, not only the lib/
directory.

18.4.1.2. Via Maven

For users of dependency management, an example for Apache Maven <http://
maven.apache.org> follows. Note that the web resources are in a different
artifact.

Maven pom.xml snippet. 

<dependencies>
  <dependency>
    <groupId>org.neo4j.app</groupId>
    <artifactId>neo4j-server</artifactId>
    <version>${neo4j-version}</version>
  </dependency>
  <dependency>
    <groupId>org.neo4j.app</groupId>
    <artifactId>neo4j-server</artifactId>
    <classifier>static-web</classifier>
    <version>${neo4j-version}</version>
  </dependency>
</dependencies>
<repositories>
  <repository>
    <id>neo4j-release-repository</id>
    <name>Neo4j Maven 2 release repository</name>
    <url>http://m2.neo4j.org/releases</url>
    <releases>
      <enabled>true</enabled>
    </releases>
    <snapshots>
      <enabled>false</enabled>
    </snapshots>
  </repository>
</repositories>

Where ${neo4j-version} is the intended version.

18.4.1.3. Via Scala SBT / Ivy

In order to pull in the dependencys with SBT <https://github.com/harrah/xsbt/
wiki> and configure the underlying Ivy <http://ant.apache.org/ivy/> dependency
manager, you can use a setup like the following in your build.sbt:

organization := "your.org"

name := "your.name"

version := "your.version"

/** Deps for Embedding the Neo4j Admin server - works around: http://neo4j.org/forums/#nabble-td3477583 */
libraryDependencies ++= Seq(
   "org.neo4j.app" % "neo4j-server" % "{neo4j-version}",
   "org.neo4j.app" % "neo4j-server" % "{neo4j-version}" classifier "static-web"
      from "http://m2.neo4j.org/releases/org/neo4j/app/neo4j-server/1.5/neo4j-server-1.5-static-web.jar", "com.sun.jersey" % "jersey-core" % "1.9"
)

/** Repos for Neo4j Admin server dep */
resolvers ++= Seq(
  "tinkerprop" at "http://tinkerpop.com/maven2",
  "neo4j-public-repository" at "http://m2.neo4j.org/releases"
)

Where ${neo4j-version} is the intended version.

18.4.2. Starting the Server from Java

The Neo4j server exposes a class called WrappingNeoServerBootstrapper <http://
components.neo4j.org/neo4j-server/1.8.M04/apidocs/org/neo4j/server/
WrappingNeoServerBootstrapper.html>, which is capable of starting a Neo4j
server in the same process as your application. It uses an
AbstractGraphDatabase <http://components.neo4j.org/neo4j-kernel/1.8.M04/apidocs
/org/neo4j/kernel/AbstractGraphDatabase.html> instance that you provide.

This gives your application, among other things, the REST API, statistics
gathering and the web administration interface that comes with the server.

Usage example. 

AbstractGraphDatabase graphdb = getGraphDb();
WrappingNeoServerBootstrapper srv;
srv = new WrappingNeoServerBootstrapper( graphdb );
srv.start();
// The server is now running
// until we stop it:
srv.stop();

Once you have the server up and running, see Chapter 27, Web Administration and
Chapter 19, REST API for how to use it!

18.4.3. Providing custom configuration

You can modify the server settings programmatically and, within reason, the
same settings are available to you here as those outlined in Section 18.2,
“Server Configuration”.

The settings that are not available (or rather, that are ignored) are those
that concern the underlying database, such as database location and database
configuration path.

Custom configuration example. 

// let the database accept remote neo4j-shell connections
GraphDatabaseAPI graphdb = (GraphDatabaseAPI) new GraphDatabaseFactory().newEmbeddedDatabaseBuilder( "target/configDb" ).setConfig( ShellSettings.remote_shell_enabled, GraphDatabaseSetting.TRUE ).newGraphDatabase();
ServerConfigurator config;
config = new ServerConfigurator( graphdb );
// let the server endpoint be on a custom port
config.configuration().setProperty(
        Configurator.WEBSERVER_PORT_PROPERTY_KEY, 7575 );

WrappingNeoServerBootstrapper srv;
srv = new WrappingNeoServerBootstrapper( graphdb, config );
srv.start();

18.5. Server Performance Tuning

At the heart of the Neo4j server is a regular Neo4j storage engine instance.
That engine can be tuned in the same way as the other embedded configurations,
using the same file format. The only difference is that the server must be told
where to find the fine-tuning configuration.

Quick info

  * The neo4j.properties file is a standard configuration file that databases
    load in order to tune their memory use and caching strategies.
  * See Section 22.3, “Caches in Neo4j” for more information.

18.5.1. Specifying Neo4j tuning properties

The conf/neo4j-server.properties file in the server distribution, is the main
configuration file for the server. In this file we can specify a second
properties file that contains the database tuning settings (that is, the
neo4j.properties file). This is done by setting a single property to point to a
valid neo4j.properties file:

org.neo4j.server.db.tuning.properties={neo4j.properties file}

On restarting the server the tuning enhancements specified in the
neo4j.properties file will be loaded and configured into the underlying
database engine.

18.5.2. Specifying JVM tuning properties

Tuning the standalone server is achieved by editing the neo4j-wrapper.conf file
in the conf directory of NEO4J_HOME.

Edit the following properties:

Table 18.1. neo4j-wrapper.conf JVM tuning properties

+-----------------------------------------------------------------------------+
|Property Name            |Meaning                                            |
|-------------------------+---------------------------------------------------|
|wrapper.java.initmemory  |initial heap size (in MB)                          |
|-------------------------+---------------------------------------------------|
|wrapper.java.maxmemory   |maximum heap size (in MB)                          |
|-------------------------+---------------------------------------------------|
|wrapper.java.additional.N|additional literal JVM parameter, where N is a     |
|                         |number for each                                    |
+-----------------------------------------------------------------------------+


For more information on the tuning properties, see Section 22.4, “JVM Settings”
.

18.6. Server Installation in the Cloud

Neo4j on various cloud services either by a user, or as a managed instance on
the Neo Technology cloud fabric. Below are instructions for some of these.

18.6.1. Heroku

For the basic setup, please see the Heroku Quickstart tutorial <http://
devcenter.heroku.com/articles/quickstart>

To add Neo4j to your Heroku app, do:

heroku addons:add neo4j

Chapter 19. REST API

The Neo4j REST API is designed with discoverability in mind, so that you can
start with a GET on the Section 19.1, “Service root” and from there discover
URIs to perform other requests. The examples below uses URIs in the examples;
they are subject to change in the future, so for future-proofness discover URIs
where possible, instead of relying on the current layout. The default
representation is json <http://www.json.org/>, both for responses and for data
sent with POST/PUT requests.

Below follows a listing of ways to interact with the REST API. For language
bindings to the REST API, see Chapter 6, Neo4j Remote Client Libraries.

To interact with the JSON interface you must explicitly set the request header
Accept:application/json for those requests that responds with data. You should
also set the header Content-Type:application/json if your request sends data,
for example when you’re creating a relationship. The examples include the
relevant request and response headers.

19.1. Service root

19.1.1. Get service root

The service root is your starting point to discover the REST API. It contains
the basic starting points for the databse, and some version and extension
information. The reference_node entry will only be present if there is a
reference node set and exists in the database.

Figure 19.1. Final Graph

Final-Graph-Get-service-root.svg


Example request

  * GET http://localhost:7474/db/data/
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

{
  "cypher" : "http://localhost:7474/db/data/cypher",
  "relationship_index" : "http://localhost:7474/db/data/index/relationship",
  "node" : "http://localhost:7474/db/data/node",
  "relationship_types" : "http://localhost:7474/db/data/relationship/types",
  "neo4j_version" : "1.8.M04-1-g892e348",
  "batch" : "http://localhost:7474/db/data/batch",
  "extensions_info" : "http://localhost:7474/db/data/ext",
  "node_index" : "http://localhost:7474/db/data/index/node",
  "reference_node" : "http://localhost:7474/db/data/node/31",
  "extensions" : {
  }
}

19.2. Nodes

19.2.1. Create Node

Figure 19.2. Final Graph

Final-Graph-create-Node.svg


Example request

  * POST http://localhost:7474/db/data/node
  * Accept: application/json

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/node/166

{
  "outgoing_relationships" : "http://localhost:7474/db/data/node/166/relationships/out",
  "data" : {
  },
  "traverse" : "http://localhost:7474/db/data/node/166/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/166/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/166/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/166",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/166/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/166/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/166/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/166/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/166/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/166/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/166/relationships/in/{-list|&|types}"
}

19.2.2. Create Node with properties

Figure 19.3. Final Graph

Final-Graph-create-Node-with-properties.svg


Example request

  * POST http://localhost:7474/db/data/node
  * Accept: application/json
  * Content-Type: application/json

{"foo" : "bar"}

Example response

  * 201: Created
  * Content-Length: 1120
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/node/167

{
  "outgoing_relationships" : "http://localhost:7474/db/data/node/167/relationships/out",
  "data" : {
    "foo" : "bar"
  },
  "traverse" : "http://localhost:7474/db/data/node/167/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/167/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/167/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/167",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/167/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/167/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/167/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/167/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/167/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/167/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/167/relationships/in/{-list|&|types}"
}

19.2.3. Get node

<p/> Note that the response contains URI/templates for the available operations
for getting properties and relationships.

Figure 19.4. Final Graph

Final-Graph-Get-node.svg


Example request

  * GET http://localhost:7474/db/data/node/3
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

{
  "outgoing_relationships" : "http://localhost:7474/db/data/node/3/relationships/out",
  "data" : {
  },
  "traverse" : "http://localhost:7474/db/data/node/3/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/3/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/3/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/3",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/3/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/3/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/3/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/3/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/3/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/3/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/3/relationships/in/{-list|&|types}"
}

19.2.4. Get non-existent node

Figure 19.5. Final Graph

Final-Graph-Get-non-existent-node.svg


Example request

  * GET http://localhost:7474/db/data/node/800000
  * Accept: application/json

Example response

  * 404: Not Found
  * Content-Type: application/json

{
  "message" : "Cannot find node with id [800000] in database.",
  "exception" : "org.neo4j.server.rest.web.NodeNotFoundException: Cannot find node with id [800000] in database.",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.node(DatabaseActions.java:124)", "org.neo4j.server.rest.web.DatabaseActions.getNode(DatabaseActions.java:235)", "org.neo4j.server.rest.web.RestfulGraphDatabase.getNode(RestfulGraphDatabase.java:225)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.2.5. Delete node

Figure 19.6. Final Graph

Final-Graph-Delete-node.svg


Example request

  * DELETE http://localhost:7474/db/data/node/175
  * Accept: application/json

Example response

  * 204: No Content

19.2.6. Nodes with relationships can not be deleted

The relationships on a node has to be deleted before the node can be deleted.

Figure 19.7. Final Graph

Final-Graph-Nodes-with-relationships-can-not-be-deleted.svg


Example request

  * DELETE http://localhost:7474/db/data/node/176
  * Accept: application/json

Example response

  * 409: Conflict
  * Content-Type: application/json

{
  "message" : "The node with id 176 cannot be deleted. Check that the node is orphaned before deletion.",
  "exception" : "org.neo4j.server.rest.web.OperationFailureException: The node with id 176 cannot be deleted. Check that the node is orphaned before deletion.",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.deleteNode(DatabaseActions.java:256)", "org.neo4j.server.rest.web.RestfulGraphDatabase.deleteNode(RestfulGraphDatabase.java:239)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.3. Relationships

Relationships are a first class citizen in the Neo4j REST API. They can be
accessed either stand-alone or through the nodes they are attached to.

The general pattern to get relationships from a node is:

GET http://localhost:7474/db/data/node/123/relationships/{dir}/{-list|&|types}

Where dir is one of all, in, out and types is an ampersand-separated list of
types. See the examples below for more information.

19.3.1. Get Relationship by ID

Figure 19.8. Final Graph

Final-Graph-get-Relationship-by-ID.svg


Example request

  * GET http://localhost:7474/db/data/relationship/15
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

{
  "start" : "http://localhost:7474/db/data/node/42",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/15",
  "property" : "http://localhost:7474/db/data/relationship/15/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/15/properties",
  "type" : "know",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/41"
}

19.3.2. Create relationship

Upon successful creation of a relationship, the new relationship is returned.

Figure 19.9. Final Graph

Final-Graph-Create-relationship.svg


Example request

  * POST http://localhost:7474/db/data/node/87/relationships
  * Accept: application/json
  * Content-Type: application/json

{"to" : "http://localhost:7474/db/data/node/86", "type" : "LOVES"}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/relationship/95

{
  "start" : "http://localhost:7474/db/data/node/87",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/95",
  "property" : "http://localhost:7474/db/data/relationship/95/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/95/properties",
  "type" : "LOVES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/86"
}

19.3.3. Create a relationship with properties

Upon successful creation of a relationship, the new relationship is returned.

Figure 19.10. Starting Graph

Starting-Graph-Add-relationship-with-properties-before.svg


Figure 19.11. Final Graph

Final-Graph-Create-a-relationship-with-properties.svg


Example request

  * POST http://localhost:7474/db/data/node/85/relationships
  * Accept: application/json
  * Content-Type: application/json

{"to" : "http://localhost:7474/db/data/node/84", "type" : "LOVES", "data" : {"foo" : "bar"}}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/relationship/93

{
  "start" : "http://localhost:7474/db/data/node/85",
  "data" : {
    "foo" : "bar"
  },
  "self" : "http://localhost:7474/db/data/relationship/93",
  "property" : "http://localhost:7474/db/data/relationship/93/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/93/properties",
  "type" : "LOVES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/84"
}

19.3.4. Delete relationship

Figure 19.12. Starting Graph

Starting-Graph-Delete-relationship1.svg


Figure 19.13. Final Graph

Final-Graph-Delete-relationship.svg


Example request

  * DELETE http://localhost:7474/db/data/relationship/20
  * Accept: application/json

Example response

  * 204: No Content

19.3.5. Get all properties on a relationship

Figure 19.14. Final Graph

Final-Graph-get-all-properties-on-a-relationship.svg


Example request

  * GET http://localhost:7474/db/data/relationship/24/properties
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

{
  "since" : "1day",
  "cost" : "high"
}

19.3.6. Set all properties on a relationship

Figure 19.15. Starting Graph

Starting-Graph-Set-relationship-property1.svg


Figure 19.16. Final Graph

Final-Graph-set-all-properties-on-a-relationship.svg


Example request

  * PUT http://localhost:7474/db/data/relationship/23/properties
  * Accept: application/json
  * Content-Type: application/json

{
  "happy" : false
}

Example response

  * 204: No Content

19.3.7. Get single property on a relationship

Figure 19.17. Final Graph

Final-Graph-get-single-property-on-a-relationship.svg


Example request

  * GET http://localhost:7474/db/data/relationship/21/properties/cost
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

"high"

19.3.8. Set single property on a relationship

Figure 19.18. Starting Graph

Starting-Graph-Set-relationship-property1.svg


Figure 19.19. Final Graph

Final-Graph-set-single-property-on-a-relationship.svg


Example request

  * PUT http://localhost:7474/db/data/relationship/22/properties/cost
  * Accept: application/json
  * Content-Type: application/json

"deadly"

Example response

  * 204: No Content

19.3.9. Get all relationships

Figure 19.20. Final Graph

Final-Graph-Get-all-relationships.svg


Example request

  * GET http://localhost:7474/db/data/node/71/relationships/all
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/71",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/31",
  "property" : "http://localhost:7474/db/data/relationship/31/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/31/properties",
  "type" : "LIKES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/72"
}, {
  "start" : "http://localhost:7474/db/data/node/73",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/32",
  "property" : "http://localhost:7474/db/data/relationship/32/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/32/properties",
  "type" : "LIKES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/71"
}, {
  "start" : "http://localhost:7474/db/data/node/71",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/33",
  "property" : "http://localhost:7474/db/data/relationship/33/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/33/properties",
  "type" : "HATES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/74"
} ]

19.3.10. Get incoming relationships

Figure 19.21. Final Graph

Final-Graph-Get-incoming-relationships.svg


Example request

  * GET http://localhost:7474/db/data/node/76/relationships/in
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/78",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/35",
  "property" : "http://localhost:7474/db/data/relationship/35/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/35/properties",
  "type" : "LIKES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/76"
} ]

19.3.11. Get outgoing relationships

Figure 19.22. Final Graph

Final-Graph-Get-outgoing-relationships.svg


Example request

  * GET http://localhost:7474/db/data/node/81/relationships/out
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/81",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/37",
  "property" : "http://localhost:7474/db/data/relationship/37/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/37/properties",
  "type" : "LIKES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/82"
}, {
  "start" : "http://localhost:7474/db/data/node/81",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/39",
  "property" : "http://localhost:7474/db/data/relationship/39/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/39/properties",
  "type" : "HATES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/84"
} ]

19.3.12. Get typed relationships

<p/> Note that the "&" needs to be escaped for example when using cURL <http://
curl.haxx.se/> from the terminal.

Figure 19.23. Final Graph

Final-Graph-Get-typed-relationships.svg


Example request

  * GET http://localhost:7474/db/data/node/86/relationships/all/LIKES&HATES
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/86",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/40",
  "property" : "http://localhost:7474/db/data/relationship/40/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/40/properties",
  "type" : "LIKES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/87"
}, {
  "start" : "http://localhost:7474/db/data/node/88",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/41",
  "property" : "http://localhost:7474/db/data/relationship/41/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/41/properties",
  "type" : "LIKES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/86"
}, {
  "start" : "http://localhost:7474/db/data/node/86",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/42",
  "property" : "http://localhost:7474/db/data/relationship/42/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/42/properties",
  "type" : "HATES",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/89"
} ]

19.3.13. Get relationships on a node without relationships

Figure 19.24. Final Graph

Final-Graph-Get-relationships-on-a-node-without-relationships.svg


Example request

  * GET http://localhost:7474/db/data/node/105/relationships/all
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ ]

19.4. Relationship types

19.4.1. Get relationship types

Figure 19.25. Final Graph

Final-Graph-Get-relationship-types.svg


Example request

  * GET http://localhost:7474/db/data/relationship/types
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ "LOVES", "knows", "HATES", "likes", "KNOWS", "foo", "bar", "LIKES", "know", "has" ]

19.5. Node properties

19.5.1. Set property on node

Setting different properties will retain the existing ones for this node. Note
that a single value are submitted not as a map but just as a value (which is
valid JSON) like in the example below.

Figure 19.26. Final Graph

Final-Graph-Set-property-on-node.svg


Example request

  * PUT http://localhost:7474/db/data/node/17/properties/foo
  * Accept: application/json
  * Content-Type: application/json

"bar"

Example response

  * 204: No Content

19.5.2. Update node properties

This will replace all existing properties on the node with the new set of
attributes.

Figure 19.27. Final Graph

Final-Graph-Update-node-properties.svg


Example request

  * PUT http://localhost:7474/db/data/node/9/properties
  * Accept: application/json
  * Content-Type: application/json

{
  "age" : "18"
}

Example response

  * 204: No Content

19.5.3. Get properties for node

Figure 19.28. Final Graph

Final-Graph-Get-properties-for-node.svg


Example request

  * GET http://localhost:7474/db/data/node/2/properties
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

{
  "foo" : "bar"
}

19.5.4. Property values can not be null

This example shows the response you get when trying to set a property to null.

Figure 19.29. Final Graph

Final-Graph-Property-values-can-not-be-null.svg


Example request

  * POST http://localhost:7474/db/data/node
  * Accept: application/json
  * Content-Type: application/json

{"foo":null}

Example response

  * 400: Bad Request
  * Content-Type: application/json

{
  "message" : "Could not set property \"foo\", unsupported type: null",
  "exception" : "org.neo4j.server.rest.web.PropertyValueException: Could not set property \"foo\", unsupported type: null",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.set(DatabaseActions.java:156)", "org.neo4j.server.rest.web.DatabaseActions.createNode(DatabaseActions.java:214)", "org.neo4j.server.rest.web.RestfulGraphDatabase.createNode(RestfulGraphDatabase.java:195)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.5.5. Property values can not be nested

Nesting properties is not supported. You could for example store the nested
json as a string instead.

Figure 19.30. Final Graph

Final-Graph-Property-values-can-not-be-nested.svg


Example request

  * POST http://localhost:7474/db/data/node/
  * Accept: application/json
  * Content-Type: application/json

{"foo" : {"bar" : "baz"}}

Example response

  * 400: Bad Request
  * Content-Type: application/json

{
  "message" : "Could not set property \"foo\", unsupported type: {bar=baz}",
  "exception" : "org.neo4j.server.rest.web.PropertyValueException: Could not set property \"foo\", unsupported type: {bar=baz}",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.set(DatabaseActions.java:156)", "org.neo4j.server.rest.web.DatabaseActions.createNode(DatabaseActions.java:214)", "org.neo4j.server.rest.web.RestfulGraphDatabase.createNode(RestfulGraphDatabase.java:195)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.5.6. Delete all properties from node

Figure 19.31. Final Graph

Final-Graph-Delete-all-properties-from-node.svg


Example request

  * DELETE http://localhost:7474/db/data/node/27/properties
  * Accept: application/json

Example response

  * 204: No Content

19.5.7. Delete a named property from a node

To delete a single property from a node, see the example below.

Figure 19.32. Starting Graph

Starting-Graph-delete-named-property-start.svg


Figure 19.33. Final Graph

Final-Graph-delete-a-named-property-from-a-node.svg


Example request

  * DELETE http://localhost:7474/db/data/node/28/properties/name
  * Accept: application/json

Example response

  * 204: No Content

19.6. Relationship properties

19.6.1. Update relationship properties

Figure 19.34. Final Graph

Final-Graph-Update-relationship-properties.svg


Example request

  * PUT http://localhost:7474/db/data/relationship/102/properties
  * Accept: application/json
  * Content-Type: application/json

{
  "jim" : "tobias"
}

Example response

  * 204: No Content

inlcude::remove-properties-from-a-relationship.txt[]

19.6.2. Remove property from a relationship

See the example request below.

Figure 19.35. Starting Graph

Starting-Graph-Remove-property-from-a-relationship1.svg


Figure 19.36. Final Graph

Final-Graph-Remove-property-from-a-relationship.svg


Example request

  * DELETE http://localhost:7474/db/data/relationship/16/properties/cost
  * Accept: application/json

Example response

  * 204: No Content

19.6.3. Remove non-existent property from a relationship

Attempting to remove a property that doesn’t exist results in an error.

Figure 19.37. Final Graph

Final-Graph-Remove-non-existent-property-from-a-relationship.svg


Example request

  * DELETE http://localhost:7474/db/data/relationship/17/properties/
    non-existent
  * Accept: application/json

Example response

  * 404: Not Found
  * Content-Type: application/json

{
  "message" : "Relationship[17] does not have a property \"non-existent\"",
  "exception" : "org.neo4j.server.rest.web.NoSuchPropertyException: Relationship[17] does not have a property \"non-existent\"",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.removeRelationshipProperty(DatabaseActions.java:730)", "org.neo4j.server.rest.web.RestfulGraphDatabase.deleteRelationshipProperty(RestfulGraphDatabase.java:595)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.6.4. Remove properties from a non-existing relationship

Attempting to remove all properties from a relationship which doesn’t exist
results in an error.

Figure 19.38. Final Graph

Final-Graph-Remove-properties-from-a-non-existing-relationship.svg


Example request

  * DELETE http://localhost:7474/db/data/relationship/1234/properties
  * Accept: application/json

Example response

  * 404: Not Found
  * Content-Type: application/json

{
  "exception" : "org.neo4j.server.rest.web.RelationshipNotFoundException",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.relationship(DatabaseActions.java:138)", "org.neo4j.server.rest.web.DatabaseActions.removeAllRelationshipProperties(DatabaseActions.java:708)", "org.neo4j.server.rest.web.RestfulGraphDatabase.deleteAllRelationshipProperties(RestfulGraphDatabase.java:579)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.6.5. Remove property from a non-existing relationship

Attempting to remove a property from a relationship which doesn’t exist results
in an error.

Figure 19.39. Final Graph

Final-Graph-Remove-property-from-a-non-existing-relationship.svg


Example request

  * DELETE http://localhost:7474/db/data/relationship/1234/properties/cost
  * Accept: application/json

Example response

  * 404: Not Found
  * Content-Type: application/json

{
  "exception" : "org.neo4j.server.rest.web.RelationshipNotFoundException",
  "stacktrace" : [ "org.neo4j.server.rest.web.DatabaseActions.relationship(DatabaseActions.java:138)", "org.neo4j.server.rest.web.DatabaseActions.removeRelationshipProperty(DatabaseActions.java:724)", "org.neo4j.server.rest.web.RestfulGraphDatabase.deleteRelationshipProperty(RestfulGraphDatabase.java:595)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.7. Indexes

An index can contain either nodes or relationships.

Note

To create an index with default configuration, simply start using it by adding
nodes/relationships to it. It will then be automatically created for you.

What default configuration means depends on how you have configured your
database. If you haven’t changed any indexing configuration, it means the
indexes will be using a Lucene-based backend.

All the examples below show you how to do operations on node indexes, but all
of them are just as applicable to relationship indexes. Simple change the
"node" part of the URL to "relationship".

If you want to customize the index settings, see Section 19.7.2, “Create node
index with configuration”.

19.7.1. Create node index

Note

Instead of creating the index this way, you can simply start to use it, and it
will be created automatically with default configuration.

Figure 19.40. Final Graph

Final-Graph-Create-node-index.svg


Example request

  * POST http://localhost:7474/db/data/index/node/
  * Accept: application/json
  * Content-Type: application/json

{
  "name" : "favorites"
}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/node/favorites/

{
  "template" : "http://localhost:7474/db/data/index/node/favorites/{key}/{value}"
}

19.7.2. Create node index with configuration

This request is only necessary if you want to customize the index settings. If
you are happy with the defaults, you can just start indexing nodes/
relationships, as non-existent indexes will automatically be created as you do.
See Section 15.10, “Configuration and fulltext indexes” for more information on
index configuration.

Figure 19.41. Final Graph

Final-Graph-Create-node-index-with-configuration.svg


Example request

  * POST http://localhost:7474/db/data/index/node/
  * Accept: application/json
  * Content-Type: application/json

{"name":"fulltext", "config":{"type":"fulltext","provider":"lucene"}}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/node/fulltext/

{
  "template" : "http://localhost:7474/db/data/index/node/fulltext/{key}/{value}",
  "provider" : "lucene",
  "type" : "fulltext"
}

19.7.3. Delete node index

Figure 19.42. Final Graph

Final-Graph-Delete-node-index.svg


Example request

  * DELETE http://localhost:7474/db/data/index/node/kvnode
  * Accept: application/json

Example response

  * 204: No Content

19.7.4. List node indexes

Figure 19.43. Final Graph

Final-Graph-List-node-indexes.svg


Example request

  * GET http://localhost:7474/db/data/index/node/
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

{
  "node_auto_index" : {
    "template" : "http://localhost:7474/db/data/index/node/node_auto_index/{key}/{value}",
    "provider" : "lucene",
    "type" : "exact"
  },
  "favorites" : {
    "template" : "http://localhost:7474/db/data/index/node/favorites/{key}/{value}",
    "provider" : "lucene",
    "type" : "exact"
  }
}

19.7.5. Add node to index

Associates a node with the given key/value pair in the given index.

Note

Spaces in the URI have to be escaped.

Caution

This does not overwrite previous entries. If you index the same key/value/item
combination twice, two index entries are created. To do update-type operations,
you need to delete the old entry before adding a new one.

Figure 19.44. Final Graph

Final-Graph-Add-node-to-index.svg


Example request

  * POST http://localhost:7474/db/data/index/node/favorites
  * Accept: application/json
  * Content-Type: application/json

{
  "value" : "some value",
  "uri" : "http://localhost:7474/db/data/node/150",
  "key" : "some-key"
}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/node/favorites/some-key/
    some%20value/150

{
  "indexed" : "http://localhost:7474/db/data/index/node/favorites/some-key/some%20value/150",
  "outgoing_relationships" : "http://localhost:7474/db/data/node/150/relationships/out",
  "data" : {
  },
  "traverse" : "http://localhost:7474/db/data/node/150/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/150/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/150/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/150",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/150/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/150/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/150/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/150/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/150/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/150/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/150/relationships/in/{-list|&|types}"
}

19.7.6. Remove all entries with a given node from an index

Figure 19.45. Final Graph

Final-Graph-Remove-all-entries-with-a-given-node-from-an-index.svg


Example request

  * DELETE http://localhost:7474/db/data/index/node/kvnode/160
  * Accept: application/json

Example response

  * 204: No Content

19.7.7. Remove all entries with a given node and key from an index

Figure 19.46. Final Graph

Final-Graph-Remove-all-entries-with-a-given-node-and-key-from-an-index.svg


Example request

  * DELETE http://localhost:7474/db/data/index/node/kvnode/kvkey2/161
  * Accept: application/json

Example response

  * 204: No Content

19.7.8. Remove all entries with a given node, key and value from an index

Figure 19.47. Final Graph

Final-Graph-Remove-all-entries-with-a-given-node,-key-and-value-from-an-index.svg


Example request

  * DELETE http://localhost:7474/db/data/index/node/kvnode/kvkey1/value1/162
  * Accept: application/json

Example response

  * 204: No Content

19.7.9. Find node by exact match

Note

Spaces in the URI have to be escaped.

Figure 19.48. Final Graph

Final-Graph-Find-node-by-exact-match.svg


Example request

  * GET http://localhost:7474/db/data/index/node/favorites/key/the%2520value
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "indexed" : "http://localhost:7474/db/data/index/node/favorites/key/the%2520value/151",
  "outgoing_relationships" : "http://localhost:7474/db/data/node/151/relationships/out",
  "data" : {
  },
  "traverse" : "http://localhost:7474/db/data/node/151/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/151/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/151/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/151",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/151/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/151/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/151/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/151/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/151/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/151/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/151/relationships/in/{-list|&|types}"
} ]

19.7.10. Find node by query

The query language used here depends on what type of index you are querying.
The default index type is Lucene, in which case you should use the Lucene query
language here. Below an example of a fuzzy search over multiple keys.

See: http://lucene.apache.org/java/3_5_0/queryparsersyntax.html <http://
lucene.apache.org/java/3_5_0/queryparsersyntax.html>

Getting the results with a predefined ordering requires adding the parameter

order=ordering

where ordering is one of index, relevance or score. In this case an additional
field will be added to each result, named score, that holds the float value
that is the score reported by the query result.

Figure 19.49. Final Graph

Final-Graph-Find-node-by-query.svg


Example request

  * GET http://localhost:7474/db/data/index/node/bobTheIndex?query=
    Name:Build~0.1%20AND%20Gender:Male
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/152/relationships/out",
  "data" : {
    "Name" : "Builder"
  },
  "traverse" : "http://localhost:7474/db/data/node/152/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/152/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/152/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/152",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/152/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/152/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/152/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/152/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/152/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/152/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/152/relationships/in/{-list|&|types}"
} ]

19.8. Unique Indexes

For more information, see Section 13.6, “Creating unique nodes”.

19.8.1. Create a unique node in an index

Figure 19.50. Final Graph

Final-Graph-Create-a-unique-node-in-an-index.svg


Example request

  * POST http://localhost:7474/db/data/index/node/people?unique
  * Accept: application/json
  * Content-Type: application/json

{"key": "name", "value": "Tobias", "properties": {"name": "Tobias", "sequence": 1}}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/node/people/name/Tobias/163

{
  "indexed" : "http://localhost:7474/db/data/index/node/people/name/Tobias/163",
  "outgoing_relationships" : "http://localhost:7474/db/data/node/163/relationships/out",
  "data" : {
    "sequence" : 1,
    "name" : "Tobias"
  },
  "traverse" : "http://localhost:7474/db/data/node/163/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/163/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/163/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/163",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/163/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/163/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/163/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/163/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/163/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/163/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/163/relationships/in/{-list|&|types}"
}

19.8.2. Create a unique node in an index (the case where it exists)

Figure 19.51. Final Graph

Final-Graph-Create-a-unique-node-in-an-index-(the-case-where-it-exists).svg


Example request

  * POST http://localhost:7474/db/data/index/node/people?unique
  * Accept: application/json
  * Content-Type: application/json

{"key": "name", "value": "Peter", "properties": {"name": "Peter", "sequence": 2}}

Example response

  * 200: OK
  * Content-Type: application/json

{
  "indexed" : "http://localhost:7474/db/data/index/node/people/name/Peter/164",
  "outgoing_relationships" : "http://localhost:7474/db/data/node/164/relationships/out",
  "data" : {
    "sequence" : 1,
    "name" : "Peter"
  },
  "traverse" : "http://localhost:7474/db/data/node/164/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/164/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/164/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/164",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/164/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/164/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/164/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/164/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/164/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/164/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/164/relationships/in/{-list|&|types}"
}

19.8.3. Add a node to an index unless a node already exists for the given
mapping

Figure 19.52. Final Graph

Final-Graph-Add-a-node-to-an-index-unless-a-node-already-exists-for-the-given-mapping.svg


Example request

  * POST http://localhost:7474/db/data/index/node/people?unique
  * Accept: application/json
  * Content-Type: application/json

{"key": "name", "value": "Mattias", "uri":"http://localhost:7474/db/data/node/165"}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/node/people/name/Mattias/165

{
  "indexed" : "http://localhost:7474/db/data/index/node/people/name/Mattias/165",
  "outgoing_relationships" : "http://localhost:7474/db/data/node/165/relationships/out",
  "data" : {
  },
  "traverse" : "http://localhost:7474/db/data/node/165/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/165/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/165/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/165",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/165/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/165/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/165/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/165/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/165/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/165/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/165/relationships/in/{-list|&|types}"
}

19.8.4. Create a unique relationship in an index

Figure 19.53. Final Graph

Final-Graph-Create-a-unique-relationship-in-an-index.svg


Example request

  * POST http://localhost:7474/db/data/index/relationship/knowledge/?unique
  * Accept: application/json
  * Content-Type: application/json

{"key": "name", "value":"Tobias", "start": "http://localhost:7474/db/data/node/80", "end": "http://localhost:7474/db/data/node/81", "type": "knowledge"}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/relationship/knowledge/name/
    Tobias/90

{
  "indexed" : "http://localhost:7474/db/data/index/relationship/knowledge/name/Tobias/90",
  "start" : "http://localhost:7474/db/data/node/80",
  "data" : {
    "name" : "Tobias"
  },
  "self" : "http://localhost:7474/db/data/relationship/90",
  "property" : "http://localhost:7474/db/data/relationship/90/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/90/properties",
  "type" : "knowledge",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/81"
}

19.8.5. Add a relationship to an index unless a relationship already exists for
the given mapping

Figure 19.54. Final Graph

Final-Graph-Add-a-relationship-to-an-index-unless-a-relationship-already-exists-for-the-given-mapping.svg


Example request

  * POST http://localhost:7474/db/data/index/relationship/knowledge/?unique
  * Accept: application/json
  * Content-Type: application/json

{"key": "name", "value":"Mattias", "uri": "http://localhost:7474/db/data/relationship/91"}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/relationship/knowledge/name/
    Mattias/91

{
  "indexed" : "http://localhost:7474/db/data/index/relationship/knowledge/name/Mattias/91",
  "start" : "http://localhost:7474/db/data/node/82",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/91",
  "property" : "http://localhost:7474/db/data/relationship/91/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/91/properties",
  "type" : "knowledge",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/83"
}

19.9. Automatic Indexes

To enable automatic indexes in neo4j, set up the database for that, see
Section 15.12.1, “Configuration”. With this feature enabled, you can then index
and query nodes in these indexes.

19.9.1. Find node by exact match from an automatic index

Automatic index nodes can be found via exact lookups with normal Index REST
syntax.

Figure 19.55. Final Graph

Final-Graph-find-node-by-exact-match-from-an-automatic-index.svg


Example request

  * GET http://localhost:7474/db/data/index/auto/node/name/I
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/182/relationships/out",
  "data" : {
    "name" : "I"
  },
  "traverse" : "http://localhost:7474/db/data/node/182/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/182/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/182/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/182",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/182/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/182/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/182/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/182/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/182/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/182/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/182/relationships/in/{-list|&|types}"
} ]

19.9.2. Find node by query from an automatic index

See Find node by query for the actual query syntax.

Figure 19.56. Final Graph

Final-Graph-Find-node-by-query-from-an-automatic-index.svg


Example request

  * GET http://localhost:7474/db/data/index/auto/node/?query=name:I
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/181/relationships/out",
  "data" : {
    "name" : "I"
  },
  "traverse" : "http://localhost:7474/db/data/node/181/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/181/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/181/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/181",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/181/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/181/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/181/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/181/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/181/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/181/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/181/relationships/in/{-list|&|types}"
} ]

19.10. Configurable Automatic Indexing

Out of the box auto-indexing supports exact matches since they are created with
the default configuration (http://docs.neo4j.org/chunked/snapshot/
indexing-create.html <http://docs.neo4j.org/chunked/snapshot/
indexing-create.html>) the first time you access them. However it is possible
to intervene in the lifecycle of the server before any auto indexes are created
to change their configuration.

This approach cannot be used on databases that already have auto-indexes
established. To change the auto-index configuration existing indexes would have
to be deleted first, so be careful!

Caution

This technique works, but it is not particularly pleasant. Future versions of
Neo4j may remove this loophole in favour of a better structured feature for
managing auto-indexing configurations.

Auto-indexing must be enabled through configuration before we can create or
configure them. Firstly ensure that you’ve added some config like this into
your server’s neo4j.properties file:

node_auto_indexing=true
relationship_auto_indexing=true
node_keys_indexable=name,phone
relationship_keys_indexable=since

The node_auto_indexing and relationship_auto_indexing turn auto-indexing on for
nodes and relationships respectively. The node_keys_indexable key allows you to
specify a comma-separated list of node property keys to be indexed. The
relationship_keys_indexable does the same for relationship property keys.

Next start the server as usual by invoking the start script as described in
Section 18.1, “Server Installation”.

Next we have to pre-empt the creation of an auto-index, by telling the server
to create an apparently manual index which has the same name as the node (or
relationship) auto-index. For example, in this case we’ll create a node auto
index whose name is node_auto_index, like so:

19.10.1. Create an auto index for nodes with specific configuration

Example request

  * POST http://localhost:7474/db/data/index/node/
  * Accept: application/json
  * Content-Type: application/json

{"name":"node_auto_index", "config":{"type":"fulltext","provider":"lucene"}}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/node/node_auto_index/

{
  "template" : "http://localhost:7474/db/data/index/node/node_auto_index/{key}/{value}",
  "provider" : "lucene",
  "type" : "fulltext"
}

If you require configured auto-indexes for relationships, the approach is
similar:

19.10.2. Create an auto index for relationships with specific configuration

Example request

  * POST http://localhost:7474/db/data/index/relationship/
  * Accept: application/json
  * Content-Type: application/json

{"name":"relationship_auto_index", "config":{"type":"fulltext","provider":"lucene"}}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/index/relationship/
    relationship_auto_index/

{
  "template" : "http://localhost:7474/db/data/index/relationship/relationship_auto_index/{key}/{value}",
  "provider" : "lucene",
  "type" : "fulltext"
}

In case you’re curious how this works, on the server side it triggers the
creation of an index which happens to have the same name as the auto index that
the database would create for itself. Now when we interact with the database,
the index thinks the index is already is created so the state machine skips
over that step and just gets on with normal day-to-day auto-indexing.

Caution

You have to do this early in your server lifecycle, before any normal auto
indexes are created.

There are a few REST calls providing a REST interface to the AutoIndexer <http:
//components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/index/
AutoIndexer.html> component. The following REST calls work both, for node and
relationship by simply changing the respective part of the URL.

19.10.3. Get current status for autoindexing on nodes

Figure 19.57. Final Graph

Final-Graph-Get-current-status-for-autoindexing-on-nodes.svg


Example request

  * GET http://localhost:7474/db/data/index/auto/node/status
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

false

19.10.4. Enable node autoindexing

Figure 19.58. Final Graph

Final-Graph-Enable-node-autoindexing.svg


Example request

  * PUT http://localhost:7474/db/data/index/auto/node/status
  * Accept: application/json
  * Content-Type: application/json

true

Example response

  * 204: No Content

19.10.5. Lookup list of properties being autoindexed

Figure 19.59. Final Graph

Final-Graph-Lookup-list-of-properties-being-autoindexed.svg


Example request

  * GET http://localhost:7474/db/data/index/auto/node/properties
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ "some-property" ]

19.10.6. Add a property for autoindexing on nodes

Figure 19.60. Final Graph

Final-Graph-Add-a-property-for-autoindexing-on-nodes.svg


Example request

  * POST http://localhost:7474/db/data/index/auto/node/properties
  * Accept: application/json
  * Content-Type: application/json

myProperty1

Example response

  * 204: No Content

19.10.7. Remove a property for autoindexing on nodes

Figure 19.61. Final Graph

Final-Graph-Remove-a-property-for-autoindexing-on-nodes.svg


Example request

  * DELETE http://localhost:7474/db/data/index/auto/node/properties/myProperty1
  * Accept: application/json

Example response

  * 204: No Content

19.11. Traversals

Warning

The Traversal REST Endpoint executes arbitrary Groovy code under the hood as
part of the evaluators definitions. In hosted and open environments, this can
constitute a security risk. In these case, consider using declarative
approaches like Chapter 16, Cypher Query Language or write your own server side
plugin executing the interesting traversals with the Java API ( see
Section 7.1, “Server Plugins” ) or secure your server, see Section 25.1,
“Securing access to the Neo4j Server”.

Traversals are performed from a start node. The traversal is controlled by the
URI and the body sent with the request.

returnType

    The kind of objects in the response is determined by traverse/{returnType}
    in the URL. returnType can have one of these values:

      * node
      * relationship
      * path - contains full representations of start and end node, the rest
        are URIs
      * fullpath - contains full representations of all nodes and relationships

To decide how the graph should be traversed you can use these parameters in the
request body:

order

    Decides in which order to visit nodes. Possible values:

      * breadth_first - see Breadth-first search <http://en.wikipedia.org/wiki/
        Breadth-first_search>
      * depth_first - see Depth-first search <http://en.wikipedia.org/wiki/
        Depth-first_search>
relationships

    Decides which relationship types and directions should be followed. The
    direction can be one of:

      * all
      * in
      * out
uniqueness

    Decides how uniqueness should be calculated. For details on different
    uniqueness values see the Java API on Uniqueness <http://
    components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/kernel/
    Uniqueness.html>. Possible values:

      * node_global
      * none
      * relationship_global
      * node_path
      * relationship_path
prune_evaluator
    Decides whether the traverser should continue down that path or if it
    should be pruned so that the traverser won’t continue down that path. You
    can write your own prune evaluator as (see Section 19.11.1, “Traversal
    using a return filter” or use the built-in none prune evaluator.
return_filter

    Decides whether the current position should be included in the result. You
    can provide your own code for this (see Section 19.11.1, “Traversal using a
    return filter”), or use one of the built-in filters:

      * all
      * all_but_start_node
max_depth
    Is a short-hand way of specifying a prune evaluator which prunes after a
    certain depth. If not specified a max depth of 1 is used and if a
    prune_evaluator is specified instead of a max_depth, no max depth limit is
    set.

The position object in the body of the return_filter and prune_evaluator is a
Path <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/neo4j/graphdb/
Path.html> object representing the path from the start node to the current
traversal position.

Out of the box, the REST API supports JavaScript code in filters and
evaluators. The script body will be executed in a Java context which has access
to the full Neo4j Java API <http://components.neo4j.org/neo4j/1.8.M04/apidocs
/>. See the examples for the exact syntax of the request.

19.11.1. Traversal using a return filter

In this example, the none prune evaluator is used and a return filter is
supplied in order to return all names containing "t". The result is to be
returned as nodes and the max depth is set to 3.

Figure 19.62. Final Graph

Final-Graph-Traversal-using-a-return-filter.svg


Example request

  * POST http://localhost:7474/db/data/node/13/traverse/node
  * Accept: application/json
  * Content-Type: application/json

{
  "order" : "breadth_first",
  "return_filter" : {
    "body" : "position.endNode().getProperty('name').toLowerCase().contains('t')",
    "language" : "javascript"
  },
  "prune_evaluator" : {
    "body" : "position.length() > 10",
    "language" : "javascript"
  },
  "uniqueness" : "node_global",
  "relationships" : [ {
    "direction" : "all",
    "type" : "knows"
  }, {
    "direction" : "all",
    "type" : "loves"
  } ],
  "max_depth" : 3
}

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/13/relationships/out",
  "data" : {
    "name" : "Root"
  },
  "traverse" : "http://localhost:7474/db/data/node/13/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/13/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/13/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/13",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/13/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/13/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/13/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/13/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/13/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/13/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/13/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/16/relationships/out",
  "data" : {
    "name" : "Mattias"
  },
  "traverse" : "http://localhost:7474/db/data/node/16/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/16/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/16/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/16",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/16/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/16/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/16/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/16/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/16/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/16/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/16/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/15/relationships/out",
  "data" : {
    "name" : "Peter"
  },
  "traverse" : "http://localhost:7474/db/data/node/15/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/15/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/15/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/15",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/15/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/15/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/15/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/15/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/15/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/15/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/15/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/14/relationships/out",
  "data" : {
    "name" : "Tobias"
  },
  "traverse" : "http://localhost:7474/db/data/node/14/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/14/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/14/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/14",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/14/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/14/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/14/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/14/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/14/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/14/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/14/relationships/in/{-list|&|types}"
} ]

19.11.2. Return relationships from a traversal

Figure 19.63. Final Graph

Final-Graph-return-relationships-from-a-traversal.svg


Example request

  * POST http://localhost:7474/db/data/node/6/traverse/relationship
  * Accept: application/json
  * Content-Type: application/json

{"order":"breadth_first","uniqueness":"none","return_filter":{"language":"builtin","name":"all"}}

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/6",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/1",
  "property" : "http://localhost:7474/db/data/relationship/1/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/1/properties",
  "type" : "know",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/5"
}, {
  "start" : "http://localhost:7474/db/data/node/6",
  "data" : {
  },
  "self" : "http://localhost:7474/db/data/relationship/2",
  "property" : "http://localhost:7474/db/data/relationship/2/properties/{key}",
  "properties" : "http://localhost:7474/db/data/relationship/2/properties",
  "type" : "own",
  "extensions" : {
  },
  "end" : "http://localhost:7474/db/data/node/4"
} ]

19.11.3. Return paths from a traversal

Figure 19.64. Final Graph

Final-Graph-return-paths-from-a-traversal.svg


Example request

  * POST http://localhost:7474/db/data/node/9/traverse/path
  * Accept: application/json
  * Content-Type: application/json

{"order":"breadth_first","uniqueness":"none","return_filter":{"language":"builtin","name":"all"}}

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/9",
  "nodes" : [ "http://localhost:7474/db/data/node/9" ],
  "length" : 0,
  "relationships" : [ ],
  "end" : "http://localhost:7474/db/data/node/9"
}, {
  "start" : "http://localhost:7474/db/data/node/9",
  "nodes" : [ "http://localhost:7474/db/data/node/9", "http://localhost:7474/db/data/node/8" ],
  "length" : 1,
  "relationships" : [ "http://localhost:7474/db/data/relationship/3" ],
  "end" : "http://localhost:7474/db/data/node/8"
}, {
  "start" : "http://localhost:7474/db/data/node/9",
  "nodes" : [ "http://localhost:7474/db/data/node/9", "http://localhost:7474/db/data/node/7" ],
  "length" : 1,
  "relationships" : [ "http://localhost:7474/db/data/relationship/4" ],
  "end" : "http://localhost:7474/db/data/node/7"
} ]

19.11.4. Traversal returning nodes below a certain depth

Here, all nodes at a traversal depth below 3 are returned.

Figure 19.65. Final Graph

Final-Graph-Traversal-returning-nodes-below-a-certain-depth.svg


Example request

  * POST http://localhost:7474/db/data/node/20/traverse/node
  * Accept: application/json
  * Content-Type: application/json

{
  "return_filter" : {
    "body" : "position.length()<3;",
    "language" : "javascript"
  },
  "prune_evaluator" : {
    "name" : "none",
    "language" : "builtin"
  }
}

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/20/relationships/out",
  "data" : {
    "name" : "Root"
  },
  "traverse" : "http://localhost:7474/db/data/node/20/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/20/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/20",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/20/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/20/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/20/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/20/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/20/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/23/relationships/out",
  "data" : {
    "name" : "Mattias"
  },
  "traverse" : "http://localhost:7474/db/data/node/23/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/23/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/23/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/23",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/23/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/23/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/23/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/23/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/23/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/23/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/23/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/18/relationships/out",
  "data" : {
    "name" : "Johan"
  },
  "traverse" : "http://localhost:7474/db/data/node/18/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/18/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/18/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/18",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/18/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/18/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/18/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/18/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/18/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/18/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/18/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/19/relationships/out",
  "data" : {
    "name" : "Emil"
  },
  "traverse" : "http://localhost:7474/db/data/node/19/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/19/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/19/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/19",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/19/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/19/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/19/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/19/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/19/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/19/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/19/relationships/in/{-list|&|types}"
} ]

19.11.5. Creating a paged traverser

Paged traversers are created by POST-ing a traversal description to the link
identified by the paged_traverser key in a node representation. When creating a
paged traverser, the same options apply as for a regular traverser, meaning
that node, path, or fullpath, can be targeted.

Example request

  * POST http://localhost:7474/db/data/node/67/paged/traverse/node
  * Accept: application/json
  * Content-Type: application/json

{
  "prune_evaluator" : {
    "language" : "builtin",
    "name" : "none"
  },
  "return_filter" : {
    "language" : "javascript",
    "body" : "position.endNode().getProperty('name').contains('1');"
  },
  "order" : "depth_first",
  "relationships" : {
    "type" : "NEXT",
    "direction" : "out"
  }
}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/node/67/paged/traverse/node/
    bb23f7d8afb7436283ec494cc08eaee4

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/68/relationships/out",
  "data" : {
    "name" : "1"
  },
  "traverse" : "http://localhost:7474/db/data/node/68/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/68/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/68/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/68",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/68/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/68/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/68/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/68/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/68/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/68/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/68/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/77/relationships/out",
  "data" : {
    "name" : "10"
  },
  "traverse" : "http://localhost:7474/db/data/node/77/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/77/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/77/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/77",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/77/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/77/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/77/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/77/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/77/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/77/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/77/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/78/relationships/out",
  "data" : {
    "name" : "11"
  },
  "traverse" : "http://localhost:7474/db/data/node/78/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/78/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/78/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/78",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/78/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/78/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/78/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/78/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/78/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/78/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/78/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/79/relationships/out",
  "data" : {
    "name" : "12"
  },
  "traverse" : "http://localhost:7474/db/data/node/79/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/79/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/79/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/79",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/79/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/79/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/79/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/79/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/79/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/79/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/79/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/80/relationships/out",
  "data" : {
    "name" : "13"
  },
  "traverse" : "http://localhost:7474/db/data/node/80/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/80/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/80/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/80",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/80/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/80/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/80/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/80/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/80/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/80/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/80/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/81/relationships/out",
  "data" : {
    "name" : "14"
  },
  "traverse" : "http://localhost:7474/db/data/node/81/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/81/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/81/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/81",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/81/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/81/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/81/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/81/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/81/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/81/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/81/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/82/relationships/out",
  "data" : {
    "name" : "15"
  },
  "traverse" : "http://localhost:7474/db/data/node/82/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/82/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/82/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/82",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/82/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/82/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/82/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/82/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/82/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/82/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/82/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/83/relationships/out",
  "data" : {
    "name" : "16"
  },
  "traverse" : "http://localhost:7474/db/data/node/83/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/83/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/83/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/83",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/83/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/83/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/83/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/83/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/83/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/83/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/83/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/84/relationships/out",
  "data" : {
    "name" : "17"
  },
  "traverse" : "http://localhost:7474/db/data/node/84/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/84/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/84/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/84",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/84/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/84/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/84/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/84/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/84/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/84/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/84/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/85/relationships/out",
  "data" : {
    "name" : "18"
  },
  "traverse" : "http://localhost:7474/db/data/node/85/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/85/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/85/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/85",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/85/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/85/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/85/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/85/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/85/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/85/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/85/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/86/relationships/out",
  "data" : {
    "name" : "19"
  },
  "traverse" : "http://localhost:7474/db/data/node/86/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/86/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/86/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/86",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/86/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/86/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/86/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/86/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/86/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/86/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/86/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/88/relationships/out",
  "data" : {
    "name" : "21"
  },
  "traverse" : "http://localhost:7474/db/data/node/88/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/88/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/88/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/88",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/88/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/88/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/88/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/88/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/88/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/88/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/88/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/98/relationships/out",
  "data" : {
    "name" : "31"
  },
  "traverse" : "http://localhost:7474/db/data/node/98/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/98/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/98/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/98",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/98/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/98/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/98/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/98/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/98/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/98/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/98/relationships/in/{-list|&|types}"
} ]

19.11.6. Paging through the results of a paged traverser

Paged traversers hold state on the server, and allow clients to page through
the results of a traversal. To progress to the next page of traversal results,
the client issues a HTTP GET request on the paged traversal URI which causes
the traversal to fill the next page (or partially fill it if insufficient
results are available).

Note that if a traverser expires through inactivity it will cause a 404
response on the next GET request. Traversers' leases are renewed on every
successful access for the same amount of time as originally specified.

When the paged traverser reaches the end of its results, the client can expect
a 404 response as the traverser is disposed by the server.

Example request

  * GET http://localhost:7474/db/data/node/100/paged/traverse/node/
    5dc15ed9316a4fbeb20712ecf060bbc4
  * Accept: application/json

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/431/relationships/out",
  "data" : {
    "name" : "331"
  },
  "traverse" : "http://localhost:7474/db/data/node/431/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/431/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/431/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/431",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/431/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/431/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/431/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/431/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/431/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/431/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/431/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/441/relationships/out",
  "data" : {
    "name" : "341"
  },
  "traverse" : "http://localhost:7474/db/data/node/441/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/441/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/441/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/441",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/441/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/441/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/441/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/441/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/441/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/441/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/441/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/451/relationships/out",
  "data" : {
    "name" : "351"
  },
  "traverse" : "http://localhost:7474/db/data/node/451/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/451/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/451/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/451",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/451/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/451/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/451/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/451/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/451/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/451/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/451/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/461/relationships/out",
  "data" : {
    "name" : "361"
  },
  "traverse" : "http://localhost:7474/db/data/node/461/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/461/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/461/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/461",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/461/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/461/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/461/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/461/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/461/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/461/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/461/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/471/relationships/out",
  "data" : {
    "name" : "371"
  },
  "traverse" : "http://localhost:7474/db/data/node/471/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/471/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/471/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/471",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/471/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/471/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/471/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/471/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/471/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/471/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/471/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/481/relationships/out",
  "data" : {
    "name" : "381"
  },
  "traverse" : "http://localhost:7474/db/data/node/481/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/481/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/481/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/481",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/481/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/481/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/481/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/481/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/481/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/481/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/481/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/491/relationships/out",
  "data" : {
    "name" : "391"
  },
  "traverse" : "http://localhost:7474/db/data/node/491/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/491/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/491/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/491",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/491/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/491/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/491/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/491/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/491/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/491/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/491/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/501/relationships/out",
  "data" : {
    "name" : "401"
  },
  "traverse" : "http://localhost:7474/db/data/node/501/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/501/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/501/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/501",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/501/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/501/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/501/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/501/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/501/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/501/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/501/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/510/relationships/out",
  "data" : {
    "name" : "410"
  },
  "traverse" : "http://localhost:7474/db/data/node/510/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/510/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/510/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/510",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/510/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/510/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/510/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/510/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/510/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/510/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/510/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/511/relationships/out",
  "data" : {
    "name" : "411"
  },
  "traverse" : "http://localhost:7474/db/data/node/511/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/511/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/511/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/511",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/511/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/511/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/511/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/511/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/511/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/511/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/511/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/512/relationships/out",
  "data" : {
    "name" : "412"
  },
  "traverse" : "http://localhost:7474/db/data/node/512/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/512/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/512/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/512",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/512/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/512/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/512/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/512/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/512/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/512/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/512/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/513/relationships/out",
  "data" : {
    "name" : "413"
  },
  "traverse" : "http://localhost:7474/db/data/node/513/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/513/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/513/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/513",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/513/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/513/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/513/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/513/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/513/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/513/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/513/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/514/relationships/out",
  "data" : {
    "name" : "414"
  },
  "traverse" : "http://localhost:7474/db/data/node/514/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/514/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/514/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/514",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/514/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/514/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/514/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/514/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/514/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/514/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/514/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/515/relationships/out",
  "data" : {
    "name" : "415"
  },
  "traverse" : "http://localhost:7474/db/data/node/515/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/515/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/515/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/515",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/515/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/515/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/515/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/515/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/515/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/515/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/515/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/516/relationships/out",
  "data" : {
    "name" : "416"
  },
  "traverse" : "http://localhost:7474/db/data/node/516/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/516/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/516/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/516",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/516/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/516/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/516/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/516/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/516/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/516/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/516/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/517/relationships/out",
  "data" : {
    "name" : "417"
  },
  "traverse" : "http://localhost:7474/db/data/node/517/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/517/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/517/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/517",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/517/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/517/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/517/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/517/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/517/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/517/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/517/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/518/relationships/out",
  "data" : {
    "name" : "418"
  },
  "traverse" : "http://localhost:7474/db/data/node/518/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/518/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/518/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/518",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/518/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/518/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/518/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/518/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/518/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/518/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/518/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/519/relationships/out",
  "data" : {
    "name" : "419"
  },
  "traverse" : "http://localhost:7474/db/data/node/519/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/519/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/519/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/519",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/519/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/519/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/519/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/519/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/519/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/519/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/519/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/521/relationships/out",
  "data" : {
    "name" : "421"
  },
  "traverse" : "http://localhost:7474/db/data/node/521/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/521/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/521/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/521",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/521/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/521/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/521/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/521/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/521/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/521/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/521/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/531/relationships/out",
  "data" : {
    "name" : "431"
  },
  "traverse" : "http://localhost:7474/db/data/node/531/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/531/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/531/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/531",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/531/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/531/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/531/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/531/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/531/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/531/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/531/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/541/relationships/out",
  "data" : {
    "name" : "441"
  },
  "traverse" : "http://localhost:7474/db/data/node/541/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/541/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/541/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/541",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/541/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/541/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/541/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/541/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/541/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/541/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/541/relationships/in/{-list|&|types}"
} ]

19.11.7. Paged traverser page size

The default page size is 50 items, but depending on the application larger or
smaller pages sizes might be appropriate. This can be set by adding a pageSize
query parameter.

Example request

  * POST http://localhost:7474/db/data/node/577/paged/traverse/node?pageSize=1
  * Accept: application/json
  * Content-Type: application/json

{
  "prune_evaluator" : {
    "language" : "builtin",
    "name" : "none"
  },
  "return_filter" : {
    "language" : "javascript",
    "body" : "position.endNode().getProperty('name').contains('1');"
  },
  "order" : "depth_first",
  "relationships" : {
    "type" : "NEXT",
    "direction" : "out"
  }
}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/node/577/paged/traverse/node/
    557fb508377b43339f35d00548e6214e

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/578/relationships/out",
  "data" : {
    "name" : "1"
  },
  "traverse" : "http://localhost:7474/db/data/node/578/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/578/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/578/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/578",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/578/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/578/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/578/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/578/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/578/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/578/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/578/relationships/in/{-list|&|types}"
} ]

19.11.8. Paged traverser timeout

The default timeout for a paged traverser is 60 seconds, but depending on the
application larger or smaller timeouts might be appropriate. This can be set by
adding a leaseTime query parameter with the number of seconds the paged
traverser should last.

Example request

  * POST http://localhost:7474/db/data/node/610/paged/traverse/node?leaseTime=
    10
  * Accept: application/json
  * Content-Type: application/json

{
  "prune_evaluator" : {
    "language" : "builtin",
    "name" : "none"
  },
  "return_filter" : {
    "language" : "javascript",
    "body" : "position.endNode().getProperty('name').contains('1');"
  },
  "order" : "depth_first",
  "relationships" : {
    "type" : "NEXT",
    "direction" : "out"
  }
}

Example response

  * 201: Created
  * Content-Type: application/json
  * Location: http://localhost:7474/db/data/node/610/paged/traverse/node/
    9cfcff00e94d41058a49991f33fef61d

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/611/relationships/out",
  "data" : {
    "name" : "1"
  },
  "traverse" : "http://localhost:7474/db/data/node/611/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/611/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/611/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/611",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/611/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/611/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/611/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/611/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/611/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/611/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/611/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/620/relationships/out",
  "data" : {
    "name" : "10"
  },
  "traverse" : "http://localhost:7474/db/data/node/620/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/620/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/620/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/620",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/620/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/620/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/620/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/620/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/620/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/620/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/620/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/621/relationships/out",
  "data" : {
    "name" : "11"
  },
  "traverse" : "http://localhost:7474/db/data/node/621/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/621/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/621/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/621",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/621/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/621/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/621/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/621/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/621/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/621/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/621/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/622/relationships/out",
  "data" : {
    "name" : "12"
  },
  "traverse" : "http://localhost:7474/db/data/node/622/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/622/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/622/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/622",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/622/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/622/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/622/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/622/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/622/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/622/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/622/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/623/relationships/out",
  "data" : {
    "name" : "13"
  },
  "traverse" : "http://localhost:7474/db/data/node/623/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/623/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/623/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/623",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/623/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/623/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/623/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/623/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/623/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/623/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/623/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/624/relationships/out",
  "data" : {
    "name" : "14"
  },
  "traverse" : "http://localhost:7474/db/data/node/624/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/624/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/624/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/624",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/624/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/624/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/624/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/624/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/624/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/624/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/624/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/625/relationships/out",
  "data" : {
    "name" : "15"
  },
  "traverse" : "http://localhost:7474/db/data/node/625/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/625/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/625/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/625",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/625/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/625/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/625/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/625/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/625/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/625/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/625/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/626/relationships/out",
  "data" : {
    "name" : "16"
  },
  "traverse" : "http://localhost:7474/db/data/node/626/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/626/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/626/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/626",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/626/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/626/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/626/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/626/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/626/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/626/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/626/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/627/relationships/out",
  "data" : {
    "name" : "17"
  },
  "traverse" : "http://localhost:7474/db/data/node/627/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/627/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/627/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/627",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/627/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/627/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/627/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/627/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/627/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/627/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/627/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/628/relationships/out",
  "data" : {
    "name" : "18"
  },
  "traverse" : "http://localhost:7474/db/data/node/628/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/628/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/628/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/628",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/628/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/628/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/628/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/628/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/628/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/628/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/628/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/629/relationships/out",
  "data" : {
    "name" : "19"
  },
  "traverse" : "http://localhost:7474/db/data/node/629/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/629/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/629/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/629",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/629/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/629/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/629/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/629/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/629/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/629/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/629/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/631/relationships/out",
  "data" : {
    "name" : "21"
  },
  "traverse" : "http://localhost:7474/db/data/node/631/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/631/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/631/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/631",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/631/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/631/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/631/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/631/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/631/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/631/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/631/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/641/relationships/out",
  "data" : {
    "name" : "31"
  },
  "traverse" : "http://localhost:7474/db/data/node/641/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/641/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/641/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/641",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/641/relationships/out/{-list|&|types}",
  "properties" : "http://localhost:7474/db/data/node/641/properties",
  "incoming_relationships" : "http://localhost:7474/db/data/node/641/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/641/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/641/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/641/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/641/relationships/in/{-list|&|types}"
} ]

19.12. Cypher queries

The Neo4j REST API allows querying with the Chapter 16, Cypher Query Language.
The results are returned as a list of string headers (columns), and a data
part, consisting of a list of all rows, every row consisting of a list of REST
representations of the field value - Node, Relationship, Path or any simple
value like String.

19.12.1. Send a Query

A simple query returning all nodes connected to node 1, returning the node and
the name property, if it exists, otherwise null:

START x  = node(23)
MATCH x -[r]-> n
RETURN type(r), n.name?, n.age?

Figure 19.66. Final Graph

Final-Graph-Send-a-Query.svg


Example request

  * POST http://localhost:7474/db/data/cypher
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x  = node(23) match x -[r]-> n return type(r), n.name?, n.age?","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ "know", "him", 25 ], [ "know", "you", null ] ],
  "columns" : [ "type(r)", "n.name?", "n.age?" ]
}

19.12.2. Return paths

Paths can be returned together with other return types by just specifying
returns.

START x  = node(%I%)
MATCH path = (x--friend)
RETURN path, friend.name

Figure 19.67. Final Graph

Final-Graph-return-paths.svg


Example request

  * POST http://localhost:7474/db/data/cypher
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x  = node(27) match path = (x--friend) return path, friend.name","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ {
    "start" : "http://localhost:7474/db/data/node/26",
    "nodes" : [ "http://localhost:7474/db/data/node/26", "http://localhost:7474/db/data/node/27" ],
    "length" : 1,
    "relationships" : [ "http://localhost:7474/db/data/relationship/8" ],
    "end" : "http://localhost:7474/db/data/node/27"
  }, "you" ] ],
  "columns" : [ "path", "friend.name" ]
}

19.12.3. Send queries with parameters

Cypher supports queries with parameters which are submitted as a JSON map.

START x  = node:node_auto_index(name={startName})
MATCH path = (x-[r]-friend)
WHERE friend.name = {name}
RETURN TYPE(r)

Figure 19.68. Final Graph

Final-Graph-send-queries-with-parameters.svg


Example request

  * POST http://localhost:7474/db/data/cypher
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x  = node:node_auto_index(name={startName}) match path = (x-[r]-friend) where friend.name = {name} return TYPE(r)","params": {"startName":"I","name":"you"}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ "know" ] ],
  "columns" : [ "TYPE(r)" ]
}

19.12.4. Nested results

When sending queries that return nested results like list and maps, these will
get serialized into nested JSON representations according to their types.

START n = node(%I%,%you%)
RETURN collect(n.name)

Figure 19.69. Final Graph

Final-Graph-nested-results.svg


Example request

  * POST http://localhost:7474/db/data/cypher
  * Accept: application/json
  * Content-Type: application/json

{"query": "start n = node(36,35) return collect(n.name)","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ [ "I", "you" ] ] ],
  "columns" : [ "collect(n.name)" ]
}

19.12.5. Server errors

Errors on the server will be reported as a JSON-formatted stacktrace and
message.

START x = node(%I%)
RETURN x.dummy

Figure 19.70. Final Graph

Final-Graph-Server-errors.svg


Example request

  * POST http://localhost:7474/db/data/cypher
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x = node(25) return x.dummy","params": {}},

Example response

  * 400: Bad Request
  * Content-Type: application/json

{
  "message" : "The property 'dummy' does not exist on Node[25]",
  "exception" : "org.neo4j.server.rest.repr.BadInputException: The property 'dummy' does not exist on Node[25]",
  "stacktrace" : [ "org.neo4j.server.rest.repr.RepresentationExceptionHandlingIterable.exceptionOnHasNext(RepresentationExceptionHandlingIterable.java:51)", "org.neo4j.helpers.collection.ExceptionHandlingIterable$1.hasNext(ExceptionHandlingIterable.java:61)", "org.neo4j.helpers.collection.IteratorWrapper.hasNext(IteratorWrapper.java:42)", "org.neo4j.server.rest.repr.ListRepresentation.serialize(ListRepresentation.java:58)", "org.neo4j.server.rest.repr.Serializer.serialize(Serializer.java:75)", "org.neo4j.server.rest.repr.MappingSerializer.putList(MappingSerializer.java:61)", "org.neo4j.server.rest.repr.ListRepresentation.putTo(ListRepresentation.java:73)", "org.neo4j.server.rest.repr.ObjectRepresentation$PropertyGetter.putTo(ObjectRepresentation.java:133)", "org.neo4j.server.rest.repr.ObjectRepresentation.serialize(ObjectRepresentation.java:144)", "org.neo4j.server.rest.repr.MappingRepresentation.serialize(MappingRepresentation.java:42)", "org.neo4j.server.rest.repr.OutputFormat.format(OutputFormat.java:146)", "org.neo4j.server.rest.repr.OutputFormat.formatRepresentation(OutputFormat.java:114)", "org.neo4j.server.rest.repr.OutputFormat.response(OutputFormat.java:104)", "org.neo4j.server.rest.repr.OutputFormat.ok(OutputFormat.java:52)", "org.neo4j.server.rest.web.CypherService.cypher(CypherService.java:68)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.13. Built-in Graph Algorithms

Neo4j comes with a number of built-in graph algorithms. They are performed from
a start node. The traversal is controlled by the URI and the body sent with the
request.

algorithm

    The algorithm to choose. If not set, default is shortestPath. algorithm can
    have one of these values:

      * shortestPath
      * allSimplePaths
      * allPaths
      * dijkstra (optional with cost_property and default_cost parameters)
max_depth
    The maximum depth as an integer for the algorithms like ShortestPath, where
    applicable. Default is 1.

19.13.1. Find all shortest paths

The shortestPath algorithm can find multiple paths between the same nodes, like
in this example.

Figure 19.71. Final Graph

Final-Graph-Find-all-shortest-paths.svg


Example request

  * POST http://localhost:7474/db/data/node/16/paths
  * Accept: application/json
  * Content-Type: application/json

{
  "to" : "http://localhost:7474/db/data/node/11",
  "max_depth" : 3,
  "relationships" : {
    "type" : "to",
    "direction" : "out"
  },
  "algorithm" : "shortestPath"
}

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "start" : "http://localhost:7474/db/data/node/16",
  "nodes" : [ "http://localhost:7474/db/data/node/16", "http://localhost:7474/db/data/node/12", "http://localhost:7474/db/data/node/11" ],
  "length" : 2,
  "relationships" : [ "http://localhost:7474/db/data/relationship/1", "http://localhost:7474/db/data/relationship/7" ],
  "end" : "http://localhost:7474/db/data/node/11"
}, {
  "start" : "http://localhost:7474/db/data/node/16",
  "nodes" : [ "http://localhost:7474/db/data/node/16", "http://localhost:7474/db/data/node/15", "http://localhost:7474/db/data/node/11" ],
  "length" : 2,
  "relationships" : [ "http://localhost:7474/db/data/relationship/0", "http://localhost:7474/db/data/relationship/9" ],
  "end" : "http://localhost:7474/db/data/node/11"
} ]

19.13.2. Find one of the shortest paths between nodes

If no path algorithm is specified, a ShortestPath algorithm with a max depth of
1 will be chosen. In this example, the max_depth is set to 3 in order to find
the shortest path between 3 linked nodes.

Figure 19.72. Final Graph

Final-Graph-Find-one-of-the-shortest-paths-between-nodes.svg


Example request

  * POST http://localhost:7474/db/data/node/23/path
  * Accept: application/json
  * Content-Type: application/json

{
  "to" : "http://localhost:7474/db/data/node/18",
  "max_depth" : 3,
  "relationships" : {
    "type" : "to",
    "direction" : "out"
  },
  "algorithm" : "shortestPath"
}

Example response

  * 200: OK
  * Content-Type: application/json

{
  "start" : "http://localhost:7474/db/data/node/23",
  "nodes" : [ "http://localhost:7474/db/data/node/23", "http://localhost:7474/db/data/node/19", "http://localhost:7474/db/data/node/18" ],
  "length" : 2,
  "relationships" : [ "http://localhost:7474/db/data/relationship/11", "http://localhost:7474/db/data/relationship/17" ],
  "end" : "http://localhost:7474/db/data/node/18"
}

19.13.3. Execute a Dijkstra algorithm with similar weights on relationships

Figure 19.73. Final Graph

Final-Graph-Execute-a-Dijkstra-algorithm-with-similar-weights-on-relationships.svg


Example request

  * POST http://localhost:7474/db/data/node/38/path
  * Accept: application/json
  * Content-Type: application/json

{
  "to" : "http://localhost:7474/db/data/node/41",
  "cost_property" : "cost",
  "relationships" : {
    "type" : "to",
    "direction" : "out"
  },
  "algorithm" : "dijkstra"
}

Example response

  * 200: OK
  * Content-Type: application/json

{
  "weight" : 2.0,
  "start" : "http://localhost:7474/db/data/node/38",
  "nodes" : [ "http://localhost:7474/db/data/node/38", "http://localhost:7474/db/data/node/39", "http://localhost:7474/db/data/node/41" ],
  "length" : 2,
  "relationships" : [ "http://localhost:7474/db/data/relationship/33", "http://localhost:7474/db/data/relationship/34" ],
  "end" : "http://localhost:7474/db/data/node/41"
}

19.13.4. Execute a Dijkstra algorithm with weights on relationships

Figure 19.74. Final Graph

Final-Graph-Execute-a-Dijkstra-algorithm-with-weights-on-relationships.svg


Example request

  * POST http://localhost:7474/db/data/node/29/path
  * Accept: application/json
  * Content-Type: application/json

{
  "to" : "http://localhost:7474/db/data/node/32",
  "cost_property" : "cost",
  "relationships" : {
    "type" : "to",
    "direction" : "out"
  },
  "algorithm" : "dijkstra"
}

Example response

  * 200: OK
  * Content-Type: application/json

{
  "weight" : 6.0,
  "start" : "http://localhost:7474/db/data/node/29",
  "nodes" : [ "http://localhost:7474/db/data/node/29", "http://localhost:7474/db/data/node/30", "http://localhost:7474/db/data/node/27", "http://localhost:7474/db/data/node/28", "http://localhost:7474/db/data/node/25", "http://localhost:7474/db/data/node/26", "http://localhost:7474/db/data/node/32" ],
  "length" : 6,
  "relationships" : [ "http://localhost:7474/db/data/relationship/20", "http://localhost:7474/db/data/relationship/22", "http://localhost:7474/db/data/relationship/24", "http://localhost:7474/db/data/relationship/27", "http://localhost:7474/db/data/relationship/29", "http://localhost:7474/db/data/relationship/30" ],
  "end" : "http://localhost:7474/db/data/node/32"
}

19.14. Batch operations

Caution

Batch support is currently experimental. Expect this part of the API to change.

19.14.1. Execute multiple operations in batch

This lets you execute multiple API calls through a single HTTP call,
significantly improving performance for large insert and update operations.

The batch service expects an array of job descriptions as input, each job
description describing an action to be performed via the normal server API.

This service is transactional. If any of the operations performed fails
(returns a non-2xx HTTP status code), the transaction will be rolled back and
all changes will be undone.

Each job description should contain a to attribute, with a value relative to
the data API root (so http://localhost:7474/db/data/node <http://localhost:7474
/db/data/node> becomes just /node), and a method attribute containing HTTP verb
to use.

Optionally you may provide a body attribute, and an id attribute to help you
keep track of responses, although responses are guaranteed to be returned in
the same order the job descriptions are received.

The following figure outlines the different parts of the job descriptions:

batch-request-api.png

Figure 19.75. Final Graph

Final-Graph-Execute-multiple-operations-in-batch.svg


Example request

  * POST http://localhost:7474/db/data/batch
  * Accept: application/json
  * Content-Type: application/json

[ {
  "method" : "PUT",
  "to" : "/node/44/properties",
  "body" : {
    "age" : 1
  },
  "id" : 0
}, {
  "method" : "GET",
  "to" : "/node/44",
  "id" : 1
}, {
  "method" : "POST",
  "to" : "/node",
  "body" : {
    "age" : 1
  },
  "id" : 2
}, {
  "method" : "POST",
  "to" : "/node",
  "body" : {
    "age" : 1
  },
  "id" : 3
} ]

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "id" : 0,
  "from" : "/node/44/properties"
}, {
  "id" : 1,
  "body" : {
    "outgoing_relationships" : "http://localhost:7474/db/data/node/44/relationships/out",
    "data" : {
      "age" : 1
    },
    "traverse" : "http://localhost:7474/db/data/node/44/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/44/relationships/all/{-list|&|types}",
    "property" : "http://localhost:7474/db/data/node/44/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/44",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/44/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/44/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/44/relationships/in",
    "extensions" : {
    },
    "create_relationship" : "http://localhost:7474/db/data/node/44/relationships",
    "paged_traverse" : "http://localhost:7474/db/data/node/44/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "all_relationships" : "http://localhost:7474/db/data/node/44/relationships/all",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/44/relationships/in/{-list|&|types}"
  },
  "from" : "/node/44"
}, {
  "id" : 2,
  "location" : "http://localhost:7474/db/data/node/45",
  "body" : {
    "outgoing_relationships" : "http://localhost:7474/db/data/node/45/relationships/out",
    "data" : {
      "age" : 1
    },
    "traverse" : "http://localhost:7474/db/data/node/45/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/45/relationships/all/{-list|&|types}",
    "property" : "http://localhost:7474/db/data/node/45/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/45",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/45/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/45/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/45/relationships/in",
    "extensions" : {
    },
    "create_relationship" : "http://localhost:7474/db/data/node/45/relationships",
    "paged_traverse" : "http://localhost:7474/db/data/node/45/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "all_relationships" : "http://localhost:7474/db/data/node/45/relationships/all",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/45/relationships/in/{-list|&|types}"
  },
  "from" : "/node"
}, {
  "id" : 3,
  "location" : "http://localhost:7474/db/data/node/46",
  "body" : {
    "outgoing_relationships" : "http://localhost:7474/db/data/node/46/relationships/out",
    "data" : {
      "age" : 1
    },
    "traverse" : "http://localhost:7474/db/data/node/46/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/46/relationships/all/{-list|&|types}",
    "property" : "http://localhost:7474/db/data/node/46/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/46",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/46/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/46/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/46/relationships/in",
    "extensions" : {
    },
    "create_relationship" : "http://localhost:7474/db/data/node/46/relationships",
    "paged_traverse" : "http://localhost:7474/db/data/node/46/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "all_relationships" : "http://localhost:7474/db/data/node/46/relationships/all",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/46/relationships/in/{-list|&|types}"
  },
  "from" : "/node"
} ]

19.14.2. Refer to items created earlier in the same batch job

The batch operation API allows you to refer to the URI returned from a created
resource in subsequent job descriptions, within the same batch call.

Use the {[JOB ID]} special syntax to inject URIs from created resources into
JSON strings in subsequent job descriptions.

Figure 19.76. Final Graph

Final-Graph-Refer-to-items-created-earlier-in-the-same-batch-job.svg


Example request

  * POST http://localhost:7474/db/data/batch
  * Accept: application/json
  * Content-Type: application/json

[ {
  "method" : "POST",
  "to" : "/node",
  "id" : 0,
  "body" : {
    "name" : "bob"
  }
}, {
  "method" : "POST",
  "to" : "/node",
  "id" : 1,
  "body" : {
    "age" : 12
  }
}, {
  "method" : "POST",
  "to" : "{0}/relationships",
  "id" : 3,
  "body" : {
    "to" : "{1}",
    "data" : {
      "since" : "2010"
    },
    "type" : "KNOWS"
  }
}, {
  "method" : "POST",
  "to" : "/index/relationship/my_rels",
  "id" : 4,
  "body" : {
    "key" : "since",
    "value" : "2010",
    "uri" : "{3}"
  }
} ]

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "id" : 0,
  "location" : "http://localhost:7474/db/data/node/47",
  "body" : {
    "outgoing_relationships" : "http://localhost:7474/db/data/node/47/relationships/out",
    "data" : {
      "name" : "bob"
    },
    "traverse" : "http://localhost:7474/db/data/node/47/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/47/relationships/all/{-list|&|types}",
    "property" : "http://localhost:7474/db/data/node/47/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/47",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/47/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/47/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/47/relationships/in",
    "extensions" : {
    },
    "create_relationship" : "http://localhost:7474/db/data/node/47/relationships",
    "paged_traverse" : "http://localhost:7474/db/data/node/47/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "all_relationships" : "http://localhost:7474/db/data/node/47/relationships/all",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/47/relationships/in/{-list|&|types}"
  },
  "from" : "/node"
}, {
  "id" : 1,
  "location" : "http://localhost:7474/db/data/node/48",
  "body" : {
    "outgoing_relationships" : "http://localhost:7474/db/data/node/48/relationships/out",
    "data" : {
      "age" : 12
    },
    "traverse" : "http://localhost:7474/db/data/node/48/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/48/relationships/all/{-list|&|types}",
    "property" : "http://localhost:7474/db/data/node/48/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/48",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/48/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/48/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/48/relationships/in",
    "extensions" : {
    },
    "create_relationship" : "http://localhost:7474/db/data/node/48/relationships",
    "paged_traverse" : "http://localhost:7474/db/data/node/48/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "all_relationships" : "http://localhost:7474/db/data/node/48/relationships/all",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/48/relationships/in/{-list|&|types}"
  },
  "from" : "/node"
}, {
  "id" : 3,
  "location" : "http://localhost:7474/db/data/relationship/22",
  "body" : {
    "start" : "http://localhost:7474/db/data/node/47",
    "data" : {
      "since" : "2010"
    },
    "self" : "http://localhost:7474/db/data/relationship/22",
    "property" : "http://localhost:7474/db/data/relationship/22/properties/{key}",
    "properties" : "http://localhost:7474/db/data/relationship/22/properties",
    "type" : "KNOWS",
    "extensions" : {
    },
    "end" : "http://localhost:7474/db/data/node/48"
  },
  "from" : "http://localhost:7474/db/data/node/47/relationships"
}, {
  "id" : 4,
  "location" : "http://localhost:7474/db/data/index/relationship/my_rels/since/2010/22",
  "body" : {
    "indexed" : "http://localhost:7474/db/data/index/relationship/my_rels/since/2010/22",
    "start" : "http://localhost:7474/db/data/node/47",
    "data" : {
      "since" : "2010"
    },
    "self" : "http://localhost:7474/db/data/relationship/22",
    "property" : "http://localhost:7474/db/data/relationship/22/properties/{key}",
    "properties" : "http://localhost:7474/db/data/relationship/22/properties",
    "type" : "KNOWS",
    "extensions" : {
    },
    "end" : "http://localhost:7474/db/data/node/48"
  },
  "from" : "/index/relationship/my_rels"
} ]

19.14.3. Execute multiple operations in batch streaming

Figure 19.77. Final Graph

Final-Graph-execute-multiple-operations-in-batch-streaming.svg


Example request

  * POST http://localhost:7474/db/data/batch
  * Accept: application/json; stream=true
  * Content-Type: application/json

[ {
  "method" : "PUT",
  "to" : "/node/218/properties",
  "body" : {
    "age" : 1
  },
  "id" : 0
}, {
  "method" : "GET",
  "to" : "/node/218",
  "id" : 1
}, {
  "method" : "POST",
  "to" : "/node",
  "body" : {
    "age" : 1
  },
  "id" : 2
}, {
  "method" : "POST",
  "to" : "/node",
  "body" : {
    "age" : 1
  },
  "id" : 3
} ]

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "id" : 0,
  "from" : "/node/218/properties",
  "body" : null,
  "status" : 204
}, {
  "id" : 1,
  "from" : "/node/218",
  "body" : {
    "extensions" : {
    },
    "paged_traverse" : "http://localhost:7474/db/data/node/218/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "outgoing_relationships" : "http://localhost:7474/db/data/node/218/relationships/out",
    "traverse" : "http://localhost:7474/db/data/node/218/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/218/relationships/all/{-list|&|types}",
    "all_relationships" : "http://localhost:7474/db/data/node/218/relationships/all",
    "property" : "http://localhost:7474/db/data/node/218/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/218",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/218/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/218/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/218/relationships/in",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/218/relationships/in/{-list|&|types}",
    "create_relationship" : "http://localhost:7474/db/data/node/218/relationships",
    "data" : {
      "age" : 1
    }
  },
  "status" : 200
}, {
  "id" : 2,
  "from" : "/node",
  "body" : {
    "extensions" : {
    },
    "paged_traverse" : "http://localhost:7474/db/data/node/219/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "outgoing_relationships" : "http://localhost:7474/db/data/node/219/relationships/out",
    "traverse" : "http://localhost:7474/db/data/node/219/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/219/relationships/all/{-list|&|types}",
    "all_relationships" : "http://localhost:7474/db/data/node/219/relationships/all",
    "property" : "http://localhost:7474/db/data/node/219/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/219",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/219/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/219/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/219/relationships/in",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/219/relationships/in/{-list|&|types}",
    "create_relationship" : "http://localhost:7474/db/data/node/219/relationships",
    "data" : {
      "age" : 1
    }
  },
  "location" : "http://localhost:7474/db/data/node/219",
  "status" : 201
}, {
  "id" : 3,
  "from" : "/node",
  "body" : {
    "extensions" : {
    },
    "paged_traverse" : "http://localhost:7474/db/data/node/220/paged/traverse/{returnType}{?pageSize,leaseTime}",
    "outgoing_relationships" : "http://localhost:7474/db/data/node/220/relationships/out",
    "traverse" : "http://localhost:7474/db/data/node/220/traverse/{returnType}",
    "all_typed_relationships" : "http://localhost:7474/db/data/node/220/relationships/all/{-list|&|types}",
    "all_relationships" : "http://localhost:7474/db/data/node/220/relationships/all",
    "property" : "http://localhost:7474/db/data/node/220/properties/{key}",
    "self" : "http://localhost:7474/db/data/node/220",
    "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/220/relationships/out/{-list|&|types}",
    "properties" : "http://localhost:7474/db/data/node/220/properties",
    "incoming_relationships" : "http://localhost:7474/db/data/node/220/relationships/in",
    "incoming_typed_relationships" : "http://localhost:7474/db/data/node/220/relationships/in/{-list|&|types}",
    "create_relationship" : "http://localhost:7474/db/data/node/220/relationships",
    "data" : {
      "age" : 1
    }
  },
  "location" : "http://localhost:7474/db/data/node/220",
  "status" : 201
} ]

19.15. WADL Support

The Neo4j REST API is a truly RESTful interface relying on hypermedia controls
(links) to advertise permissible actions to users. Hypermedia is a dynamic
interface style where declarative constructs (semantic markup) are used to
inform clients of their next legal choices just in time.

Caution

RESTful APIs cannot be modelled by static interface description languages like
WSDL or WADL.

However for some use cases, developers may wish to expose WADL descriptions of
the Neo4j REST API, particularly when using tooling that expects such.

In those cases WADL generation may be enabled by adding to your server’s
neo4j.properties file:

unsupported_wadl_generation_enabled=true

Caution

WADL is not an officially supported part of the Neo4j server API because WADL
is insufficiently expressive to capture the set of potential interactions a
client can drive with Neo4j server. Expect the WADL description to be
incomplete, and in some cases contradictory to the real API. In any cases where
the WADL description disagrees with the REST API, the REST API should be
considered authoritative. WADL generation may be withdrawn at any point in the
Neo4j release cycle.

19.16. Cypher Plugin

Warning

This functionality is now provided by the core REST API. The plugin will
continue to work for some time, but is as of Neo4j 1.6 deprecated. See
Section 19.12, “Cypher queries” for documentation on the built-in Cypher
support.

The Neo4j Cypher Plugin enables querying with the Chapter 16, Cypher Query
Language. The results are returned as a list of string headers (columns), and a
data part, consisting of a list of all rows, every row consisting of a list of
REST representations of the field value - Node, Relationship or any simple
value like String.

19.16.1. Send a Query

A simple query returning all nodes connected to node 1, returning the node and
the name property, if it exists, otherwise null:

START x  = node(3)
MATCH x -[r]-> n
RETURN type(r), n.name?, n.age?

Figure 19.78. Final Graph

Final-Graph-Send-a-Query.svg


Example request

  * POST http://localhost:7474/db/data/ext/CypherPlugin/graphdb/execute_query
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x  = node(3) match x -[r]-> n return type(r), n.name?, n.age?","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ "know", "him", 25 ], [ "know", "you", null ] ],
  "columns" : [ "type(r)", "n.name?", "n.age?" ]
}

19.16.2. Return paths

Paths can be returned together with other return types by just specifying
returns.

START x  = node(%I%)
MATCH path = (x--friend)
RETURN path, friend.name

Figure 19.79. Final Graph

Final-Graph-return-paths.svg


Example request

  * POST http://localhost:7474/db/data/ext/CypherPlugin/graphdb/execute_query
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x  = node(7) match path = (x--friend) return path, friend.name","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ {
    "start" : "http://localhost:7474/db/data/node/6",
    "nodes" : [ "http://localhost:7474/db/data/node/6", "http://localhost:7474/db/data/node/7" ],
    "length" : 1,
    "relationships" : [ "http://localhost:7474/db/data/relationship/3" ],
    "end" : "http://localhost:7474/db/data/node/7"
  }, "you" ] ],
  "columns" : [ "path", "friend.name" ]
}

19.16.3. Send queries with parameters

Cypher supports queries with parameters which are submitted as a JSON map.

START x  = node:node_auto_index(name={startName})
MATCH path = (x-[r]-friend)
WHERE friend.name = {name}
RETURN TYPE(r)

Figure 19.80. Final Graph

Final-Graph-send-queries-with-parameters.svg


Example request

  * POST http://localhost:7474/db/data/ext/CypherPlugin/graphdb/execute_query
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x  = node:node_auto_index(name={startName}) match path = (x-[r]-friend) where friend.name = {name} return TYPE(r)","params": {"startName":"I","name":"you"}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ "know" ] ],
  "columns" : [ "TYPE(r)" ]
}

19.16.4. Server errors

Errors on the server will be reported as a JSON-formatted stacktrace and
message.

START x = node(%I%)
RETURN x.dummy

Figure 19.81. Final Graph

Final-Graph-Server-errors.svg


Example request

  * POST http://localhost:7474/db/data/ext/CypherPlugin/graphdb/execute_query
  * Accept: application/json
  * Content-Type: application/json

{"query": "start x = node(5) return x.dummy","params": {}},

Example response

  * 400: Bad Request
  * Content-Type: application/json

{
  "message" : "The property 'dummy' does not exist on Node[5]",
  "exception" : "org.neo4j.server.rest.repr.BadInputException: The property 'dummy' does not exist on Node[5]",
  "stacktrace" : [ "org.neo4j.server.rest.repr.RepresentationExceptionHandlingIterable.exceptionOnHasNext(RepresentationExceptionHandlingIterable.java:51)", "org.neo4j.helpers.collection.ExceptionHandlingIterable$1.hasNext(ExceptionHandlingIterable.java:61)", "org.neo4j.helpers.collection.IteratorWrapper.hasNext(IteratorWrapper.java:42)", "org.neo4j.server.rest.repr.ListRepresentation.serialize(ListRepresentation.java:58)", "org.neo4j.server.rest.repr.Serializer.serialize(Serializer.java:75)", "org.neo4j.server.rest.repr.MappingSerializer.putList(MappingSerializer.java:61)", "org.neo4j.server.rest.repr.ListRepresentation.putTo(ListRepresentation.java:73)", "org.neo4j.server.rest.repr.ObjectRepresentation$PropertyGetter.putTo(ObjectRepresentation.java:133)", "org.neo4j.server.rest.repr.ObjectRepresentation.serialize(ObjectRepresentation.java:144)", "org.neo4j.server.rest.repr.MappingRepresentation.serialize(MappingRepresentation.java:42)", "org.neo4j.server.rest.repr.OutputFormat.format(OutputFormat.java:146)", "org.neo4j.server.rest.repr.OutputFormat.formatRepresentation(OutputFormat.java:114)", "org.neo4j.server.rest.repr.OutputFormat.response(OutputFormat.java:104)", "org.neo4j.server.rest.repr.OutputFormat.ok(OutputFormat.java:52)", "org.neo4j.server.rest.web.ExtensionService.invokeGraphDatabaseExtension(ExtensionService.java:122)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

19.17. Gremlin Plugin

gremlin-logo.png

Gremlin <http://gremlin.tinkerpop.com> is a Groovy based Graph Traversal
Language. It provides a very expressive way of explicitly scripting traversals
through a Neo4j graph.

The Neo4j Gremlin Plugin provides an endpoint to send Gremlin scripts to the
Neo4j Server. The scripts are executed on the server database and the results
are returned as Neo4j Node and Relationship representations. This keeps the
types throughout the REST API consistent. The results are quite verbose when
returning Neo4j Node, Relationship or Graph representations. On the other hand,
just return properties like in the Section 19.17.4, “Send a Gremlin Script -
JSON encoded with table results” example for responses tailored to specific
needs.

Warning

The Gremlin plugin lets you execute arbitrary Groovy code under the hood. In
hosted and open environments, this can constitute a security risk. In these
case, consider using declarative approaches like Chapter 16, Cypher Query
Language or write your own server side plugin executing the interesting Gremlin
or Java routines, see Section 7.1, “Server Plugins” or secure your server, see
Section 25.1, “Securing access to the Neo4j Server”.

19.17.1. Send a Gremlin Script - URL encoded

Scripts can be sent as URL-encoded In this example, the graph has been
autoindexed by Neo4j, so we can look up the name property on nodes.

Raw script source

g.idx('node_auto_index')[[name:'I']].out

Figure 19.82. Final Graph

Final-Graph-Send-a-Gremlin-Script---URL-encoded.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/x-www-form-urlencoded

script=g.idx%28%27node_auto_index%27%29%5B%5Bname%3A%27I%27%5D%5D.out

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/1/relationships/out",
  "data" : {
    "name" : "you"
  },
  "traverse" : "http://localhost:7474/db/data/node/1/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/1/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/1/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/1",
  "properties" : "http://localhost:7474/db/data/node/1/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/1/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/1/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/1/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/1/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/1/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/1/relationships/in/{-list|&|types}"
} ]

19.17.2. Load a sample graph

Import a graph form a GraphML <http://graphml.graphdrawing.org/> file can be
achieved through the Gremlin GraphMLReader. The following script imports a
small GraphML file from an URL into Neo4j, resulting in the depicted graph. The
underlying database is auto-indexed, see Section 15.12, “Automatic Indexing” so
the script can return the imported node by index lookup.

Raw script source

g.clear()
g.loadGraphML('https://raw.github.com/neo4j/gremlin-plugin/master/src/data/graphml1.xml')
g.idx('node_auto_index')[[name:'you']]

Figure 19.83. Final Graph

Final-Graph-Load-a-sample-graph.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.clear();g.loadGraphML('https://raw.github.com/neo4j/gremlin-plugin/master/src/data/graphml1.xml');g.idx('node_auto_index')[[name:'you']];","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/10/relationships/out",
  "data" : {
    "name" : "you"
  },
  "traverse" : "http://localhost:7474/db/data/node/10/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/10/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/10/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/10",
  "properties" : "http://localhost:7474/db/data/node/10/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/10/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/10/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/10/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/10/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/10/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/10/relationships/in/{-list|&|types}"
} ]

19.17.3. Sort a result using raw Groovy operations

The following script returns a sorted list of all nodes connected via outgoing
relationships to node 1, sorted by their name-property.

Raw script source

g.idx('node_auto_index')[[name:'I']].out.sort{it.name}

Figure 19.84. Final Graph

Final-Graph-Sort-a-result-using-raw-Groovy-operations.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.idx('node_auto_index')[[name:'I']].out.sort{it.name}","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/16/relationships/out",
  "data" : {
    "name" : "him"
  },
  "traverse" : "http://localhost:7474/db/data/node/16/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/16/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/16/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/16",
  "properties" : "http://localhost:7474/db/data/node/16/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/16/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/16/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/16/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/16/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/16/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/16/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/15/relationships/out",
  "data" : {
    "name" : "you"
  },
  "traverse" : "http://localhost:7474/db/data/node/15/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/15/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/15/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/15",
  "properties" : "http://localhost:7474/db/data/node/15/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/15/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/15/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/15/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/15/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/15/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/15/relationships/in/{-list|&|types}"
} ]

19.17.4. Send a Gremlin Script - JSON encoded with table results

To send a Script JSON encoded, set the payload Content-Type Header. In this
example, find all the things that my friends like, and return a table listing
my friends by their name, and the names of the things they like in a table with
two columns, ignoring the third named step variable I. Remember that everything
in Gremlin is an iterator - in order to populate the result table t, iterate
through the pipes with iterate().

Raw script source

t= new Table()
g.v(23).as('I').out('know').as('friend').out('like').as('likes').table(t,['friend','likes']){it.name}{it.name}.iterate()
t

Figure 19.85. Final Graph

Final-Graph-Send-a-Gremlin-Script---JSON-encoded-with-table-results.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "t= new Table();g.v(23).as('I').out('know').as('friend').out('like').as('likes').table(t,['friend','likes']){it.name}{it.name}.iterate();t;","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "data" : [ [ "Joe", "cats" ], [ "Joe", "dogs" ] ],
  "columns" : [ "friend", "likes" ]
}

19.17.5. Returning nested pipes

Raw script source

g.v(27).as('I').out('know').as('friend').out('like').as('likes').table(new Table()){it.name}{it.name}.cap

Figure 19.86. Final Graph

Final-Graph-returning-nested-pipes.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.v(27).as('I').out('know').as('friend').out('like').as('likes').table(new Table()){it.name}{it.name}.cap;","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ [ {
  "data" : [ [ "I", "Joe", "cats" ], [ "I", "Joe", "dogs" ] ],
  "columns" : [ "I", "friend", "likes" ]
} ] ]

19.17.6. Set script variables

To set variables in the bindings for the Gremlin Script Engine on the server,
you can include a params parameter with a String representing a JSON map of
variables to set to initial values. These can then be accessed as normal
variables within the script.

Raw script source

meaning_of_life

Figure 19.87. Final Graph

Final-Graph-Set-script-variables.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{
  "script" : "meaning_of_life",
  "params" : {
    "meaning_of_life" : 42.0
  }
}

Example response

  * 200: OK
  * Content-Type: application/json

42.0

19.17.7. Send a Gremlin Script with variables in a JSON Map

Send a Gremlin Script, as JSON payload and additional parameters

Raw script source

g.v(me).out

Figure 19.88. Final Graph

Final-Graph-Send-a-Gremlin-Script-with-variables-in-a-JSON-Map.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.v(me).out","params": {"me":"6"}},

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/5/relationships/out",
  "data" : {
    "name" : "you"
  },
  "traverse" : "http://localhost:7474/db/data/node/5/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/5/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/5/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/5",
  "properties" : "http://localhost:7474/db/data/node/5/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/5/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/5/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/5/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/5/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/5/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/5/relationships/in/{-list|&|types}"
} ]

19.17.8. Return paths from a Gremlin script

The following script returns paths. Paths in Gremlin consist of the pipes that
make up the path from the starting pipes. The server is returning JSON
representations of their content as a nested list.

Raw script source

g.v(20).out.name.paths

Figure 19.89. Final Graph

Final-Graph-Return-paths-from-a-Gremlin-script.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.v(20).out.name.paths","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ [ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/20/relationships/out",
  "data" : {
    "name" : "I"
  },
  "traverse" : "http://localhost:7474/db/data/node/20/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/20/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/20",
  "properties" : "http://localhost:7474/db/data/node/20/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/20/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/20/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/20/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/20/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/18/relationships/out",
  "data" : {
    "name" : "you"
  },
  "traverse" : "http://localhost:7474/db/data/node/18/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/18/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/18/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/18",
  "properties" : "http://localhost:7474/db/data/node/18/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/18/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/18/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/18/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/18/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/18/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/18/relationships/in/{-list|&|types}"
}, "you" ], [ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/20/relationships/out",
  "data" : {
    "name" : "I"
  },
  "traverse" : "http://localhost:7474/db/data/node/20/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/20/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/20",
  "properties" : "http://localhost:7474/db/data/node/20/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/20/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/20/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/20/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/20/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/20/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/19/relationships/out",
  "data" : {
    "name" : "him"
  },
  "traverse" : "http://localhost:7474/db/data/node/19/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/19/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/19/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/19",
  "properties" : "http://localhost:7474/db/data/node/19/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/19/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/19/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/19/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/19/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/19/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/19/relationships/in/{-list|&|types}"
}, "him" ] ]

19.17.9. Send an arbitrary Groovy script - Lucene sorting

This example demonstrates that you via the Groovy runtime embedded with the
server have full access to all of the servers Java APIs. The below example
creates Nodes in the database both via the Blueprints and the Neo4j API indexes
the nodes via the native Neo4j Indexing API constructs a custom Lucene sorting
and searching returns a Neo4j IndexHits result iterator.

Raw script source

'******** Additional imports *********'
import org.neo4j.graphdb.index.*
import org.neo4j.graphdb.*
import org.neo4j.index.lucene.*
import org.apache.lucene.search.*

'**** Blueprints API methods on the injected Neo4jGraph at variable g ****'
meVertex = g.addVertex([name:'me'])
meNode = meVertex.getRawVertex()

'*** get the Neo4j raw instance ***'
neo4j = g.getRawGraph()


'******** Neo4j API methods: *********'
tx = neo4j.beginTx()
 youNode = neo4j.createNode()
 youNode.setProperty('name','you')
 youNode.createRelationshipTo(meNode,DynamicRelationshipType.withName('knows'))

'*** index using Neo4j APIs ***'
 idxManager = neo4j.index()
 personIndex = idxManager.forNodes('persons')
 personIndex.add(meNode,'name',meNode.getProperty('name'))
 personIndex.add(youNode,'name',youNode.getProperty('name'))
tx.success()
tx.finish()


'*** Prepare a custom Lucene query context with Neo4j API ***'
query = new QueryContext( 'name:*' ).sort( new Sort(new SortField( 'name',SortField.STRING, true ) ) )
results = personIndex.query( query )

Figure 19.90. Final Graph

Final-Graph-Send-an-arbitrary-Groovy-script---Lucene-sorting.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "'******** Additional imports *********';import org.neo4j.graphdb.index.*;import org.neo4j.graphdb.*;import org.neo4j.index.lucene.*;import org.apache.lucene.search.*;;'**** Blueprints API methods on the injected Neo4jGraph at variable g ****';meVertex = g.addVertex([name:'me']);meNode = meVertex.getRawVertex();;'*** get the Neo4j raw instance ***';neo4j = g.getRawGraph();;;'******** Neo4j API methods: *********';tx = neo4j.beginTx(); youNode = neo4j.createNode(); youNode.setProperty('name','you'); youNode.createRelationshipTo(meNode,DynamicRelationshipType.withName('knows'));;'*** index using Neo4j APIs ***'; idxManager = neo4j.index(); personIndex = idxManager.forNodes('persons'); personIndex.add(meNode,'name',meNode.getProperty('name')); personIndex.add(youNode,'name',youNode.getProperty('name'));tx.success();tx.finish();;;'*** Prepare a custom Lucene query context with Neo4j API ***';query = new QueryContext( 'name:*' ).sort( new Sort(new SortField( 'name',SortField.STRING, true ) ) );results = personIndex.query( query );","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/30/relationships/out",
  "data" : {
    "name" : "you"
  },
  "traverse" : "http://localhost:7474/db/data/node/30/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/30/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/30/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/30",
  "properties" : "http://localhost:7474/db/data/node/30/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/30/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/30/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/30/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/30/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/30/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/30/relationships/in/{-list|&|types}"
}, {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/29/relationships/out",
  "data" : {
    "name" : "me"
  },
  "traverse" : "http://localhost:7474/db/data/node/29/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/29/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/29/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/29",
  "properties" : "http://localhost:7474/db/data/node/29/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/29/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/29/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/29/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/29/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/29/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/29/relationships/in/{-list|&|types}"
} ]

19.17.10. Emit a sample graph

Exporting a graph can be done by simple emitting the appropriate String.

Raw script source

writer = new GraphMLWriter(g)
out = new java.io.ByteArrayOutputStream()
writer.outputGraph(out)
result = out.toString()

Figure 19.91. Final Graph

Final-Graph-Emit-a-sample-graph.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "writer = new GraphMLWriter(g);out = new java.io.ByteArrayOutputStream();writer.outputGraph(out);result = out.toString();","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

"<?xml version=\"1.0\" ?><graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\"><key id=\"name\" for=\"node\" attr.name=\"name\" attr.type=\"string\"></key><graph id=\"G\" edgedefault=\"directed\"><node id=\"12\"><data key=\"name\">you</data></node><node id=\"13\"><data key=\"name\">him</data></node><node id=\"14\"><data key=\"name\">I</data></node><edge id=\"6\" source=\"14\" target=\"12\" label=\"know\"></edge><edge id=\"7\" source=\"14\" target=\"13\" label=\"know\"></edge></graph></graphml>"

19.17.11. HyperEdges - find user roles in groups

Imagine a user being part of different groups. A group can have different
roles, and a user can be part of different groups. He also can have different
roles in different groups apart from the membership. The association of a User,
a Group and a Role can be referred to as a HyperEdge. However, it can be easily
modeled in a property graph as a node that captures this n-ary relationship, as
depicted below in the U1G2R1 node.

To find out in what roles a user is for a particular groups (here Group2), the
following script can traverse this HyperEdge node and provide answers.

Raw script source

g.v(37).out('hasRoleInGroup').as('hyperedge').out('hasGroup').filter{it.name=='Group2'}.back('hyperedge').out('hasRole').name

Figure 19.92. Final Graph

Final-Graph-HyperEdges---find-user-roles-in-groups.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.v(37).out('hasRoleInGroup').as('hyperedge').out('hasGroup').filter{it.name=='Group2'}.back('hyperedge').out('hasRole').name","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ "Role1" ]

19.17.12. Group count

This example is showing a group count in Germlin, for instance the counting of
the different relationship types connected to some the start node. The result
is collected into a variable that then is returned.

Raw script source

m = [:]
g.v(41).bothE().label.groupCount(m).iterate()
m

Figure 19.93. Final Graph

Final-Graph-group-count.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "m = [:];g.v(41).bothE().label.groupCount(m).iterate();m","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "knows" : 2,
  "likes" : 1
}

19.17.13. Collect multiple traversal results

Multiple traversals can be combined into a single result, using splitting and
merging pipes in a lazy fashion.

Raw script source

g.idx('node_auto_index')[[name:'Peter']].copySplit(_().out('knows'), _().in('likes')).fairMerge.name

Figure 19.94. Final Graph

Final-Graph-collect-multiple-traversal-results.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.idx('node_auto_index')[[name:'Peter']].copySplit(_().out('knows'), _().in('likes')).fairMerge.name","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ "Ian", "Marie" ]

19.17.14. Collaborative filtering

This example demonstrates basic collaborative filtering - ordering a traversal
after occurence counts and substracting objects that are not interesting in the
final result.

Here, we are finding Friends-of-Friends that are not Joes friends already. The
same can be applied to graphs of users that LIKE things and others.

Raw script source

x=[]
fof=[:]
g.v(63).out('knows').aggregate(x).out('knows').except(x).groupCount(fof).iterate()
fof.sort{a,b -> b.value <=> a.value}

Figure 19.95. Final Graph

Final-Graph-collaborative-filtering.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "x=[];fof=[:];g.v(63).out('knows').aggregate(x).out('knows').except(x).groupCount(fof).iterate();fof.sort{a,b -> b.value <=> a.value}","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

{
  "v[62]" : 1,
  "v[61]" : 2,
  "v[60]" : 1
}

19.17.15. Chunking and offsetting in Gremlin

Raw script source

g.v(51).out('knows').filter{it.name == 'Sara'}[0..100]

Figure 19.96. Final Graph

Final-Graph-chunking-and-offsetting-in-Gremlin.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.v(51).out('knows').filter{it.name == 'Sara'}[0..100]","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ {
  "outgoing_relationships" : "http://localhost:7474/db/data/node/49/relationships/out",
  "data" : {
    "name" : "Sara"
  },
  "traverse" : "http://localhost:7474/db/data/node/49/traverse/{returnType}",
  "all_typed_relationships" : "http://localhost:7474/db/data/node/49/relationships/all/{-list|&|types}",
  "property" : "http://localhost:7474/db/data/node/49/properties/{key}",
  "self" : "http://localhost:7474/db/data/node/49",
  "properties" : "http://localhost:7474/db/data/node/49/properties",
  "outgoing_typed_relationships" : "http://localhost:7474/db/data/node/49/relationships/out/{-list|&|types}",
  "incoming_relationships" : "http://localhost:7474/db/data/node/49/relationships/in",
  "extensions" : {
  },
  "create_relationship" : "http://localhost:7474/db/data/node/49/relationships",
  "paged_traverse" : "http://localhost:7474/db/data/node/49/paged/traverse/{returnType}{?pageSize,leaseTime}",
  "all_relationships" : "http://localhost:7474/db/data/node/49/relationships/all",
  "incoming_typed_relationships" : "http://localhost:7474/db/data/node/49/relationships/in/{-list|&|types}"
} ]

19.17.16. Modify the graph while traversing

This example is showing a group count in Germlin, for instance the counting of
the different relationship types connected to some the start node. The result
is collected into a variable that then is returned.

Figure 19.97. Starting Graph

Starting-Graph-starting_graphmodify-the-graph-while-traversing.svg


Raw script source

g.v(44).bothE.each{g.removeEdge(it)}

Figure 19.98. Final Graph

Final-Graph-modify-the-graph-while-traversing.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "g.v(44).bothE.each{g.removeEdge(it)}","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

[ ]

19.17.17. Flow algorithms with Gremlin

This is a basic stub example for implementing flow algorithms in for instance
Flow Networks <http://en.wikipedia.org/wiki/Flow_network> with a pipes-based
approach and scripting, here between source and sink using the capacity
property on relationships as the base for the flow function and modifying the
graph during calculation.

Figure 19.99. Starting Graph

Starting-Graph-starting_graphflow-algorithms-with-Gremlin.svg


Raw script source

source=g.v(72)
sink=g.v(73)
maxFlow = 0
source.outE.inV.loop(2){!it.object.equals(sink)}.paths.each{flow = it.capacity.min()
 maxFlow += flow
it.findAll{it.capacity}.each{it.capacity -= flow}}
maxFlow

Figure 19.100. Final Graph

Final-Graph-flow-algorithms-with-Gremlin.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script": "source=g.v(72);sink=g.v(73);maxFlow = 0;source.outE.inV.loop(2){!it.object.equals(sink)}.paths.each{flow = it.capacity.min(); maxFlow += flow;it.findAll{it.capacity}.each{it.capacity -= flow}};maxFlow","params": {}},

Example response

  * 200: OK
  * Content-Type: application/json

4

19.17.18. Script execution errors

Script errors will result in an HTTP error response code.

Figure 19.101. Final Graph

Final-Graph-script-execution-errors.svg


Example request

  * POST http://localhost:7474/db/data/ext/GremlinPlugin/graphdb/execute_script
  * Accept: application/json
  * Content-Type: application/json

{"script":"g.addVertex([name:{}])"}

Example response

  * 400: Bad Request
  * Content-Type: application/json

{
  "message" : "javax.script.ScriptException: java.lang.IllegalArgumentException: Unknown property type on: Script286$_run_closure1@7811cc36, class Script286$_run_closure1",
  "exception" : "org.neo4j.server.rest.repr.BadInputException: javax.script.ScriptException: java.lang.IllegalArgumentException: Unknown property type on: Script286$_run_closure1@7811cc36, class Script286$_run_closure1",
  "stacktrace" : [ "org.neo4j.server.plugin.gremlin.GremlinPlugin.executeScript(GremlinPlugin.java:88)", "java.lang.reflect.Method.invoke(Method.java:597)", "org.neo4j.server.plugins.PluginMethod.invoke(PluginMethod.java:57)", "org.neo4j.server.plugins.PluginManager.invoke(PluginManager.java:168)", "org.neo4j.server.rest.web.ExtensionService.invokeGraphDatabaseExtension(ExtensionService.java:300)", "org.neo4j.server.rest.web.ExtensionService.invokeGraphDatabaseExtension(ExtensionService.java:122)", "java.lang.reflect.Method.invoke(Method.java:597)" ]
}

Chapter 20. Python embedded bindings

This describes neo4j-embedded, a Python library that lets you use the embedded
Neo4j database in Python.

Apart from the reference documentation and installation instructions in this
section, you may also want to take a look at Chapter 11, Using Neo4j embedded
in Python applications.

The source code for this project lives on GitHub: https://github.com/neo4j/
python-embedded <https://github.com/neo4j/python-embedded>

20.1. Installation

Note

The Neo4j database itself (from the Community Edition) is included in the
neo4j-embedded distribution.

20.1.1. Installation on OSX/Linux

20.1.1.1. Prerequisites

Caution

Make sure that the entire stack used is either 64bit or 32bit (no mixing, that
is). That means the JVM, Python and JPype.

First, install JPype:

 1. Download the latest version of JPype from http://sourceforge.net/projects/
    jpype/files/JPype/ <http://sourceforge.net/projects/jpype/files/JPype/>.
 2. Unzip the file.
 3. Open a console and navigate into the unzipped folder.
 4. Run sudo python setup.py install

JPype is also available in the Debian repos:

sudo apt-get install python-jpype

Then, make sure the JAVA_HOME environment variable is set to your jre or jdk
folder, so that JPype can find the JVM.

Note

Installation can be problematic on OSX. See the following Stack Overflow
discussion for help: http://stackoverflow.com/questions/8525193/
cannot-install-jpype-on-os-x-lion-to-use-with-neo4j <http://stackoverflow.com/
questions/8525193/cannot-install-jpype-on-os-x-lion-to-use-with-neo4j>

20.1.1.2. Installing neo4j-embedded

You can install neo4j-embedded with your python package manager of choice:

sudo pip install neo4j-embedded

sudo easy_install neo4j-embedded

Or install manually:

 1. Download the latest appropriate version of JPype from http://
    sourceforge.net/projects/jpype/files/JPype/ <http://sourceforge.net/
    projects/jpype/files/JPype/> for 32bit or from http://www.lfd.uci.edu/
    ~gohlke/pythonlibs/ <http://www.lfd.uci.edu/~gohlke/pythonlibs/> for 64bit.
 2. Unzip the file.
 3. Open a console and navigate into the unzipped folder.
 4. Run sudo python setup.py install

20.1.2. Installation on Windows

20.1.2.1. Prerequisites

Warning

It is imperative that the entire stack used is either 64bit or 32bit (no
mixing, that is). That means the JVM, Python, JPype and all extra DLLs (see
below).

First, install JPype:

Note

Notice that JPype only works with Python 2.6 and 2.7. Also note that there are
different downloads depending on which version you use.

 1. Download the latest appropriate version of JPype from http://
    sourceforge.net/projects/jpype/files/JPype/ <http://sourceforge.net/
    projects/jpype/files/JPype/> for 32bit or from http://www.lfd.uci.edu/
    ~gohlke/pythonlibs/ <http://www.lfd.uci.edu/~gohlke/pythonlibs/> for 64bit.
 2. Run the installer.

Then, make sure the JAVA_HOME environment variable is set to your jre or jdk
folder. There is a description of how to set environment variables in
Section 20.1.2.3, “Solving problems with missing DLL files”.

Note

There may be DLL files missing from your system that are required by JPype. See
Section 20.1.2.3, “Solving problems with missing DLL files” for instructions
for how to fix this.

20.1.2.2. Installing neo4j-embedded

 1. Download the latest version from http://pypi.python.org/pypi/neo4j-embedded
    / <http://pypi.python.org/pypi/neo4j-embedded/>.
 2. Run the installer.

20.1.2.3. Solving problems with missing DLL files

Certain versions of Windows ship without DLL files needed to programmatically
launch a JVM. You will need to make IEShims.dll and certain debugging dlls
available on Windows.

IEShims.dll is normally included with Internet Explorer installs. To make
windows find this file globally, you need to add the IE install folder to your
PATH.

 1. Right click on "My Computer" or "Computer".
 2. Select "Properties".
 3. Click on "Advanced" or "Advanced system settings".
 4. Click the "Environment variables" button.
 5. Find the path varible, and add C:\Program Files\Internet Explorer to it (or
    the install location of IE, if you have installed it somewhere else).

Required debugging dlls are bundled with Microsoft Visual C++ Redistributable
libraries.

  * 32bit Windows: http://www.microsoft.com/download/en/details.aspx?
    displaylang=en&id=5555 <http://www.microsoft.com/download/en/details.aspx?
    displaylang=en&id=5555>
  * 64bit Windows: http://www.microsoft.com/download/en/details.aspx?
    displaylang=en&id=14632 <http://www.microsoft.com/download/en/details.aspx?
    displaylang=en&id=14632>

If you are still getting errors about missing DLL files, you can use http://
www.dependencywalker.com/ <http://www.dependencywalker.com/> to open your
jvm.dll (located in JAVA_HOME/bin/client/ or JAVA_HOME/bin/server/), and it
will tell you if there are other missing dlls.

20.2. Core API

This section describes how get get up and running, and how to do basic
operations.

20.2.1. Getting started

20.2.1.1. Creating a database

from neo4j import GraphDatabase

# Create db
db = GraphDatabase(folder_to_put_db_in)

# Always shut down your database
db.shutdown()

20.2.1.2. Creating a database, with configuration

Please see Chapter 22, Configuration & Performance for what options you can use
here.

from neo4j import GraphDatabase

# Example configuration parameters
db = GraphDatabase(folder_to_put_db_in, string_block_size=200, array_block_size=240)

db.shutdown()

20.2.1.3. JPype JVM configuration

You can set extra arguments to be passed to the JVM using the
NEO4J_PYTHON_JVMARGS environment variable. This can be used to, for instance,
increase the max memory for the database.

Note that you must set this before you import the neo4j package, either by
setting it before you start python, or by setting it programatically in your
app.

import os
os.environ['NEO4J_PYTHON_JVMARGS'] = '-Xms128M -Xmx512M'
import neo4j

You can also override the classpath used by neo4j-embedded, by setting the
NEO4J_PYTHON_CLASSPATH environment variable.

20.2.2. Transactions

All write operations to the database need to be performed from within
transactions. This ensures that your database never ends up in an inconsistent
state.

See Chapter 13, Transaction Management for details on how Neo4j handles
transactions.

We use the python with statement to define a transaction context. If you are
using an older version of Python, you may have to import the with statement:

from __future__ import with_statement

Either way, this is how you get into a transaction:

# Start a transaction
with db.transaction:
    # This is inside the transactional
    # context. All work done here
    # will either entirely succeed,
    # or no changes will be applied at all.

    # Create a node
    node = db.node()

    # Give it a name
    node['name'] = 'Cat Stevens'

# The transaction is automatically
# commited when you exit the with
# block.

20.2.3. Nodes

This describes operations that are specific to node objects. For documentation
on how to handle properties on both relationships and nodes, see
Section 20.2.5, “Properties”.

20.2.3.1. Creating a node

with db.transaction:
    # Create a node
    thomas = db.node(name='Thomas Anderson', age=42)

20.2.3.2. Fetching a node by id

# You don't have to be in a transaction
# to do read operations.
a_node = db.node[some_node_id]

# Ids on nodes and relationships are available via the "id"
# property, eg.:
node_id = a_node.id

20.2.3.3. Fetching the reference node

reference = db.reference_node

20.2.3.4. Removing a node

with db.transaction:
    node = db.node()
    node.delete()

Tip

See also Section 13.5, “Delete semantics”.

20.2.3.5. Removing a node by id

with db.transaction:
    del db.node[some_node_id]

20.2.3.6. Accessing relationships from a node

For details on what you can do with the relationship objects, see
Section 20.2.4, “Relationships”.

# All relationships on a node
for rel in a_node.relationships:
    pass

# Incoming relationships
for rel in a_node.relationships.incoming:
    pass

# Outgoing relationships
for rel in a_node.relationships.outgoing:
    pass

# Relationships of a specific type
for rel in a_node.mayor_of:
    pass

# Incoming relationships of a specific type
for rel in a_node.mayor_of.incoming:
    pass

# Outgoing relationships of a specific type
for rel in a_node.mayor_of.outgoing:
    pass

20.2.3.7. Getting and/or counting all nodes

Use this with care, it will become extremely slow in large datasets.

for node in db.nodes:
    pass

# Shorthand for iterating through
# and counting all nodes
number_of_nodes = len(db.nodes)

20.2.4. Relationships

This describes operations that are specific to relationship objects. For
documentation on how to handle properties on both relationships and nodes, see
Section 20.2.5, “Properties”.

20.2.4.1. Creating a relationship

with db.transaction:
    # Nodes to create a relationship between
    steven = self.graphdb.node(name='Steve Brook')
    poplar_bluff = self.graphdb.node(name='Poplar Bluff')

    # Create a relationship of type "mayor_of"
    relationship = steven.mayor_of(poplar_bluff, since="12th of July 2012")

    # Or, to create relationship types with names
    # that would not be possible with the above
    # method.
    steven.relationships.create('mayor_of', poplar_bluff, since="12th of July 2012")

20.2.4.2. Fetching a relationship by id

the_relationship = db.relationship[a_relationship_id]

20.2.4.3. Removing a relationship

with db.transaction:
    # Create a relationship
    source = db.node()
    target = db.node()
    rel = source.Knows(target)

    # Delete it
    rel.delete()

Tip

See also Section 13.5, “Delete semantics”.

20.2.4.4. Removing a relationship by id

with db.transaction:
    del db.relationship[some_relationship_id]

20.2.4.5. Relationship start node, end node and type

relationship_type = relationship.type

start_node = relationship.start
end_node = relationship.end

20.2.4.6. Getting and/or counting all relationships

Use this with care, it will become extremely slow in large datasets.

for rel in db.relationships:
    pass

# Shorthand for iterating through
# and counting all relationships
number_of_rels = len(db.relationships)

20.2.5. Properties

Both nodes and relationships can have properties, so this section applies
equally to both node and relationship objects. Allowed property values include
strings, numbers, booleans, as well as arrays of those primitives. Within each
array, all values must be of the same type.

20.2.5.1. Setting properties

with db.transaction:
    node_or_rel['name'] = 'Thomas Anderson'
    node_or_rel['age'] = 42
    node_or_rel['favourite_numbers'] = [1,2,3]
    node_or_rel['favourite_words'] = ['banana','blue']

20.2.5.2. Getting properties

numbers = node_or_rel['favourite_numbers']

20.2.5.3. Removing properties

with db.transaction:
    del node_or_rel['favourite_numbers']

20.2.5.4. Looping through properties

# Loop key and value at the same time
for key, value in node_or_rel.items():
    pass

# Loop property keys
for key in node_or_rel.keys():
    pass

# Loop property values
for value in node_or_rel.values():
    pass

20.2.6. Paths

A path object represents a path between two nodes in the graph. Paths thus
contain at least two nodes and one relationship, but can reach arbitrary
length. It is used in various parts of the API, most notably in traversals.

20.2.6.1. Accessing the start and end nodes

start_node = path.start
end_node = path.end

20.2.6.2. Accessing the last relationship

last_relationship = path.last_relationship

20.2.6.3. Looping through the entire path

You can loop through all elements of a path directly, or you can choose to only
loop through nodes or relationships. When you loop through all elements, the
first item will be the start node, the second will be the first relationship,
the third the node that the relationship led to and so on.

for item in path:
    # Item is either a Relationship,
    # or a Node
    pass

for nodes in path.nodes:
    # All nodes in a path
    pass

for nodes in path.relationships:
    # All relationships in a path
    pass

20.3. Indexes

In order to rapidly find nodes or relationship based on properties, Neo4j
supports indexing. This is commonly used to find start nodes for traversals.

By default, the underlying index is powered by Apache Lucene <http://
lucene.apache.org/java/docs/index.html>, but it is also possible to use Neo4j
with other index implementations.

You can create an arbitrary number of named indexes. Each index handles either
nodes or relationships, and each index works by indexing key/value/object
triplets, object being either a node or a relationship, depending on the index
type.

20.3.1. Index management

Just like the rest of the API, all write operations to the index must be
performed from within a transaction.

20.3.1.1. Creating an index

Create a new index, with optional configuration.

with db.transaction:
    # Create a relationship index
    rel_idx = db.relationship.indexes.create('my_rels')

    # Create a node index, passing optional
    # arguments to the index provider.
    # In this case, enable full-text indexing.
    node_idx = db.node.indexes.create('my_nodes', type='fulltext')

20.3.1.2. Retrieving a pre-existing index

with db.transaction:
    node_idx = db.node.indexes.get('my_nodes')

    rel_idx = db.relationship.indexes.get('my_rels')

20.3.1.3. Deleting indexes

with db.transaction:
    node_idx = db.node.indexes.get('my_nodes')
    node_idx.delete()

    rel_idx = db.relationship.indexes.get('my_rels')
    rel_idx.delete()

20.3.1.4. Checking if an index exists

exists = db.node.indexes.exists('my_nodes')

20.3.2. Indexing things

20.3.2.1. Adding nodes or relationships to an index

with db.transaction:
    # Indexing nodes
    a_node = db.node()
    node_idx = db.node.indexes.create('my_nodes')

    # Add the node to the index
    node_idx['akey']['avalue'] = a_node

    # Indexing relationships
    a_relationship = a_node.knows(db.node())
    rel_idx = db.relationship.indexes.create('my_rels')

    # Add the relationship to the index
    rel_idx['akey']['avalue'] = a_relationship

20.3.2.2. Removing indexed items

Removing items from an index can be done at several levels of granularity. See
the example below.

# Remove specific key/value/item triplet
del idx['akey']['avalue'][item]

# Remove all instances under a certain
# key
del idx['akey'][item]

# Remove all instances all together
del idx[item]

20.3.3. Searching the index

You can retrieve indexed items in two ways. Either you do a direct lookup, or
you perform a query. The direct lookup is the same across different index
providers while the query syntax depends on what index provider you use. As
mentioned previously, Lucene is the default and by far most common index
provider. For querying Lucene you will want to use the Lucene query language
<http://lucene.apache.org/java/3_5_0/queryparsersyntax.html>.

There is a python library for programatically generating Lucene queries,
available at GitHub <https://github.com/scholrly/lucene-querybuilder>.

Important

Unless you loop through the entire index result, you have to close the result
when you are done with it. If you do not, the database does not know when it
can release the resources the result is taking up.

20.3.3.1. Direct lookups

hits = idx['akey']['avalue']
for item in hits:
    pass

# Always close index results when you are
# done, to free up resources.
hits.close()

20.3.3.2. Querying

hits = idx.query('akey:avalue')
for item in hits:
    pass

# Always close index results when you are
# done, to free up resources.
hits.close()

20.4. Cypher Queries

You can use the Cypher query language from neo4j-embedded. Read more about
cypher syntax and cool stuff you can with it here: Chapter 16, Cypher Query
Language.

20.4.1. Querying and reading the result

20.4.1.1. Basic query

To execute a plain text cypher query, do this:

result = db.query("START n=node(0) RETURN n")

20.4.1.2. Retrieve query result

Cypher returns a tabular result. You can either loop through the table
row-by-row, or you can loop through the values in a given column. Here is how
to loop row-by-row:

root_node = "START n=node(0) RETURN n"

# Iterate through all result rows
for row in db.query(root_node):
    node = row['n']

# We know it's a single result,
# so we could have done this as well
node = db.query(root_node).single['n']

Here is how to loop through the values of a given column:

root_node = "START n=node(0) RETURN n"

# Fetch an iterator for the "n" column
column = db.query(root_node)['n']

for cell in column:
    node = cell

# Coumns support "single":
column = db.query(root_node)['n']
node = column.single

20.4.1.3. List the result columns

You can get a list of the column names in the result like this:

result = db.query("START n=node(0) RETURN n,count(n)")

# Get a list of the column names
columns = result.keys()

20.4.2. Parameterized and prepared queries

20.4.2.1. Parameterized queries

Cypher supports parameterized queries, see Section 16.3, “Parameters”. This is
how you use them in neo4j-embedded.

result = db.query("START n=node({id}) RETURN n",id=0)

node = result.single['n']

20.4.2.2. Prepared queries

Prepared queries, where you could retrieve a pre-parsed version of a cypher
query to be used later, is deprecated. Cypher will recognize if it has
previously parsed a given query, and won’t parse the same string twice.

So, in effect, all cypher queries are prepared queries, if you use them more
than once. Use parameterized queries to gain the full power of this - then a
generic query can be pre-parsed, and modified with parameters each time it is
executed.

20.5. Traversals

Warning

Traversal support in neo4j-embedded for python is deprecated as of Neo4j 1.7
GA. Please see Section 20.4, “Cypher Queries” or the core API instead. This is
done because the traversal framework requires a very tight coupling between the
JVM and python. To keep improving performance, we need to break that coupling.

The below documentation will be removed in neo4j-embedded 1.8, and support for
traversals will be dropped in neo4j-embedded 1.9.

The traversal API used here is essentially the same as the one used in the Java
API, with a few modifications.

Traversals start at a given node and uses a set of rules to move through the
graph and to decide what parts of the graph to return.

20.5.1. Basic traversals

20.5.1.1. Following a relationship

The most basic traversals simply follow certain relationship types, and return
everything they encounter. By default, each node is visited only once, so there
is no risk of infinite loops.

traverser = db.traversal()\
    .relationships('related_to')\
    .traverse(start_node)

# The graph is traversed as
# you loop through the result.
for node in traverser.nodes:
    pass

20.5.1.2. Following a relationship in a specific direction

You can tell the traverser to only follow relationships in some specific
direction.

from neo4j import OUTGOING, INCOMING, ANY

traverser = db.traversal()\
    .relationships('related_to', OUTGOING)\
    .traverse(start_node)

20.5.1.3. Following multiple relationship types

You can specify an arbitrary number of relationship types and directions to
follow.

from neo4j import OUTGOING, INCOMING, ANY

traverser = db.traversal()\
    .relationships('related_to', INCOMING)\
    .relationships('likes')\
    .traverse(start_node)

20.5.2. Traversal results

A traversal can give you one of three different result types: nodes,
relationships or paths.

Traversals are performed lazily, which means that the graph is traversed as you
loop through the result.

traverser = db.traversal()\
    .relationships('related_to')\
    .traverse(start_node)

# Get each possible path
for path in traverser:
    pass

# Get each node
for node in traverser.nodes:
    pass

# Get each relationship
for relationship in traverser.relationships:
    pass

20.5.3. Uniqueness

To avoid infinite loops, it’s important to define what parts of the graph can
be re-visited during a traversal. By default, uniqueness is set to NODE_GLOBAL,
which means that each node is only visited once.

Here are the other options that are available.

from neo4j import Uniqueness

# Available options are:

Uniqueness.NONE
# Any position in the graph may be revisited.

Uniqueness.NODE_GLOBAL
# Default option
# No node in the entire graph may be visited
# more than once. This could potentially
# consume a lot of memory since it requires
# keeping an in-memory data structure
# remembering all the visited nodes.

Uniqueness.RELATIONSHIP_GLOBAL
# No relationship in the entire graph may be
# visited more than once. For the same
# reasons as NODE_GLOBAL uniqueness, this
# could use up a lot of memory. But since
# graphs typically have a larger number of
# relationships than nodes, the memory
# overhead of this uniqueness level could
# grow even quicker.

Uniqueness.NODE_PATH
# A node may not occur previously in the
# path reaching up to it.

Uniqueness.RELATIONSHIP_PATH
# A relationship may not occur previously in
# the path reaching up to it.

Uniqueness.NODE_RECENT
# Similar to NODE_GLOBAL uniqueness in that
# there is a global collection of visited
# nodes each position is checked against.
# This uniqueness level does however have a
# cap on how much memory it may consume in
# the form of a collection that only
# contains the most recently visited nodes.
# The size of this collection can be
# specified by providing a number as the
# second argument to the
# uniqueness()-method along with the
# uniqueness level.

Uniqueness.RELATIONSHIP_RECENT
# works like NODE_RECENT uniqueness, but
# with relationships instead of nodes.


traverser = db.traversal()\
    .uniqueness(Uniqueness.NODE_PATH)\
    .traverse(start_node)

20.5.4. Ordering

You can traverse either depth first, or breadth first. Depth first is the
default, because it has lower memory overhead.

# Depth first traversal, this
# is the default.
traverser = db.traversal()\
    .depthFirst()\
    .traverse(self.source)

# Breadth first traversal
traverser = db.traversal()\
    .breadthFirst()\
    .traverse(start_node)

20.5.5. Evaluators - advanced filtering

In order to traverse based on other critera, such as node properties, or more
complex things like neighboring nodes or patterns, we use evaluators. An
evaluator is a normal Python method that takes a path as an argument, and
returns a description of what to do next.

The path argument is the current position the traverser is at, and the
description of what to do can be one of four things, as seen in the example
below.

from neo4j import Evaluation

# Evaluation contains the four
# options that an evaluator can
# return. They are:

Evaluation.INCLUDE_AND_CONTINUE
# Include this node in the result and
# continue the traversal

Evaluation.INCLUDE_AND_PRUNE
# Include this node in the result, but don't
# continue the traversal

Evaluation.EXCLUDE_AND_CONTINUE
# Exclude this node from the result, but
# continue the traversal

Evaluation.EXCLUDE_AND_PRUNE
# Exclude this node from the result and
# don't continue the traversal

# An evaluator
def my_evaluator(path):
    # Filter on end node property
    if path.end['message'] == 'world':
        return Evaluation.INCLUDE_AND_CONTINUE

    # Filter on last relationship type
    if path.last_relationship.type.name() == 'related_to':
        return Evaluation.INCLUDE_AND_PRUNE

    # You can do even more complex things here, like subtraversals.

    return Evaluation.EXCLUDE_AND_CONTINUE

# Use the evaluator
traverser = db.traversal()\
    .evaluator(my_evaluator)\
    .traverse(start_node)

Part IV. Operations

This part describes how to install and maintain a Neo4j installation. This
includes topics such as backing up the database and monitoring the health of
the database as well as diagnosing issues.

Table of Contents

21. Installation & Deployment

    21.1. Deployment Scenarios

        21.1.1. Server
        21.1.2. Embedded

    21.2. System Requirements

        21.2.1. CPU
        21.2.2. Memory
        21.2.3. Disk
        21.2.4. Filesystem
        21.2.5. Software
        21.2.6. JDK Version

    21.3. Installation

        21.3.1. Embedded Installation
        21.3.2. Server Installation

    21.4. Upgrading

        21.4.1. Automatic Upgrade
        21.4.2. Explicit Upgrade
        21.4.3. Upgrade 1.6 → 1.7
        21.4.4. Upgrade 1.5 → 1.6
        21.4.5. Upgrade 1.4 → 1.5

    21.5. Usage Data Collector

        21.5.1. Technical Information
        21.5.2. How to disable UDC

22. Configuration & Performance

    22.1. Introduction

        22.1.1. How to add configuration settings

    22.2. Performance Guide

        22.2.1. Try this first
        22.2.2. Neo4j primitives' lifecycle
        22.2.3. Configuring Neo4j

    22.3. Caches in Neo4j

        22.3.1. File buffer cache
        22.3.2. Object cache

    22.4. JVM Settings

        22.4.1. Configuring heap size and GC

    22.5. Compressed storage of short strings
    22.6. Compressed storage of short arrays
    22.7. Memory mapped IO settings

        22.7.1. Optimizing for traversal speed example
        22.7.2. Batch insert example

    22.8. Linux Performance Guide

        22.8.1. Setup
        22.8.2. Running the benchmark
        22.8.3. Fixing the problem

    22.9. Linux specific notes

        22.9.1. File system tuning for high IO
        22.9.2. Setting the number of open files

23. High Availability

    23.1. Architecture
    23.2. Setup and configuration

        23.2.1. Small
        23.2.2. Medium
        23.2.3. Large
        23.2.4. Installation Notes

    23.3. How Neo4j HA operates
    23.4. High Availability setup tutorial

        23.4.1. Background
        23.4.2. Setup and start the Coordinator cluster
        23.4.3. Start the Neo4j Servers in HA mode
        23.4.4. Start Neo4j Embedded in HA mode

    23.5. Setting up HAProxy as a load balancer

        23.5.1. Installing HAProxy
        23.5.2. Configuring HAProxy
        23.5.3. Configuring separate sets for master and slaves
        23.5.4. Cache-based sharding with HAProxy

24. Backup

    24.1. Embedded and Server
    24.2. Online Backup from Java
    24.3. High Availability
    24.4. Restoring Your Data

25. Security

    25.1. Securing access to the Neo4j Server

        25.1.1. Secure the port and remote client connection accepts
        25.1.2. Arbitrary code execution
        25.1.3. HTTPS support
        25.1.4. Server Authorization Rules
        25.1.5. Hosted Scripting
        25.1.6. Security in Depth
        25.1.7. Rewriting URLs with a Proxy installation

26. Monitoring

    26.1. JMX

        26.1.1. Adjusting remote JMX access to the Neo4j Server
        26.1.2. How to connect to a Neo4j instance using JMX and JConsole
        26.1.3. How to connect to the JMX monitoring programmatically
        26.1.4. Reference of supported JMX MBeans

Chapter 21. Installation & Deployment

21.1. Deployment Scenarios

Neo4j can be embedded into your application, run as a standalone server or
deployed on several machines to provide high availability.

Table 21.1. Neo4j deployment options

+--------------------------------------------------------------------+
|          |Single Instance      |Multiple Instances                 |
|----------+---------------------+-----------------------------------|
|Embedded  |EmbeddedGraphDatabase|HighlyAvailableGraphDatabase       |
|----------+---------------------+-----------------------------------|
|Standalone|Neo4j Server         |Neo4j Server high availability mode|
+--------------------------------------------------------------------+


21.1.1. Server

Neo4j is normally accessed as a standalone server, either directly through a
REST interface or through a language-specific driver. More information about
Neo4j server is found in Chapter 18, Neo4j Server. For running the server and
embedded installations in high availability mode, see Chapter 23, High
Availability.

21.1.2. Embedded

Neo4j can be embedded directly in a server application by including the
appropriate Java libraries. When programming, you can refer to the
GraphDatabaseService <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/
neo4j/graphdb/GraphDatabaseService.html> API. To switch from a single instance
to multiple highly available instances, simply switch from the concrete
EmbeddedGraphDatabase <http://components.neo4j.org/neo4j/1.8.M04/apidocs/org/
neo4j/kernel/EmbeddedGraphDatabase.html> to the HighlyAvailableGraphDatabase
<http://components.neo4j.org/neo4j-enterprise/1.8.M04/apidocs/org/neo4j/kernel/
HighlyAvailableGraphDatabase.html>.

21.2. System Requirements

Memory constrains graph size, disk I/O constrains read/write performance, as
always.

21.2.1. CPU

Performance is generally memory or I/O bound for large graphs, and compute
bound for graphs which fit in memory.

Minimum
    Intel 486
Recommended
    Intel Core i7

21.2.2. Memory

More memory allows even larger graphs, but runs the risk of inducing larger
Garbage Collection operations.

Minimum
    1GB
Recommended
    4-8GB

21.2.3. Disk

Aside from capacity, the performance characteristics of the disk are the most
important when selecting storage.

Minimum
    SCSI, EIDE
Recommended
    SSD w/ SATA

21.2.4. Filesystem

For proper ACID behavior, the filesystem must support flush (fsync, fdatasync).

Minimum
    ext3 (or similar)
Recommended
    ext4, ZFS

21.2.5. Software

Neo4j is Java-based.

Java
    1.6+
Operating Systems
    Linux, Windows XP, Mac OS X

21.2.6. JDK Version

The Neo4j runtime is continuously tested with

  * Oracle Java Runtime Environment JRE 1.6 <http://www.oracle.com/technetwork/
    java/javase/downloads/index.html>

21.3. Installation

Neo4j can be installed as a server, running either as a headless application or
system service. For Java developers, it is also possible to use Neo4j as a
library, embedded in your application.

For information on installing Neo4j as a server, see Section 18.1, “Server
Installation”.

The following table outlines the available editions and their names for use
with dependency management tools.

Tip

Follow the links in the table for details on dependency configuration with
Apache Maven, Apache Buildr, Apache Ivy and Groovy Grape!

Table 21.2. Neo4j editions

+----------------------------------------------------------------------------------------+
|Edition   |Dependency                                             |Description  |License|
|----------+-------------------------------------------------------+-------------+-------|
|Community |org.neo4j:neo4j <http://search.maven.org/#search|gav|1||a high       |GPLv3  |
|          |g%3A%22org.neo4j%22%20AND%20a%3A%22neo4j%22>           |performance, |       |
|          |                                                       |fully ACID   |       |
|          |                                                       |transactional|       |
|          |                                                       |graph        |       |
|          |                                                       |database     |       |
|----------+-------------------------------------------------------+-------------+-------|
|Advanced  |org.neo4j:neo4j-advanced <http://search.maven.org/#    |adding       |AGPLv3 |
|          |search|gav|1|                                          |advanced     |       |
|          |g%3A%22org.neo4j%22%20AND%20a%3A%22neo4j-advanced%22>  |monitoring   |       |
|----------+-------------------------------------------------------+-------------+-------|
|Enterprise|org.neo4j:neo4j-enterprise <http://search.maven.org/#  |adding online|AGPLv3 |
|          |search|gav|1|                                          |backup and   |       |
|          |g%3A%22org.neo4j%22%20AND%20a%3A%22neo4j-enterprise%22>|High         |       |
|          |                                                       |Availability |       |
|          |                                                       |clustering   |       |
+----------------------------------------------------------------------------------------+


Note

The listed dependencies do not contain the implementation, but pulls it in
transitively.

For more information regarding licensing, see the Licensing Guide <http://
neo4j.org/licensing-guide/>.

21.3.1. Embedded Installation

The latest release is always available from http://neo4j.org/download <http://
neo4j.org/download>, included as part of the Neo4j download packages. After
selecting the appropriate version for your platform, embed Neo4j in your Java
application by including the Neo4j library jars in your build. Either take the
jar files from the lib/ directory of the download, or directly use the
artifacts available from Maven Central Repository ^[1]. Stable and milestone
releases are available there.

For information on how to use Neo4j as a dependency with Maven and other
dependency management tools, see the following table:

Note

The listed dependencies do not contain the implementation, but pulls it in
transitively.

Maven dependency. 

<project>
...
 <dependencies>
  <dependency>
   <groupId>org.neo4j</groupId>
   <artifactId>neo4j</artifactId>
   <version>${neo4j-version}</version>
  </dependency>
  ...
 </dependencies>
...
</project>

Where ${neo4j-version} is the intended version and the artifactId is one of
neo4j, neo4j-advanced, neo4j-enterprise.

21.3.2. Server Installation

please refer to Chapter 18, Neo4j Server and Section 18.1, “Server
Installation”.

21.4. Upgrading

A database can be upgraded from a minor version to the next, e.g. 1.1 → 1.2,
and 1.2 → 1.3, but you can not jump directly from 1.1 → 1.3. The upgrade
process is a one way step; databases cannot be downgraded.

For most upgrades, only small changes are required to the database store, and
these changes proceed automatically when you start up the database using the
newer version of Neo4J.

However, some upgrades require more significant changes to the database store.
In these cases, Neo4j will refuse to start without explicit configuration to
allow the upgrade.

The table below lists recent Neo4J versions, and the type of upgrade required.

Table 21.3. Upgrade process for Neo4J version

+--------------------------------------+
|From Version |To Version|Upgrade Type |
|-------------+----------+-------------|
|1.3          |1.4       |Automatic    |
|-------------+----------+-------------|
|1.4          |1.5       |Explicit     |
|-------------+----------+-------------|
|1.5          |1.6       |Explicit     |
|-------------+----------+-------------|
|1.6          |1.7       |Automatic    |
+--------------------------------------+


21.4.1. Automatic Upgrade

To perform a normal upgrade (for minor changes to the database store):

 1. download the newer version of Neo4j
 2. cleanly shutdown the database to upgrade, if it is running
 3. startup the database with the newer version of Neo4j

21.4.2. Explicit Upgrade

To perform a special upgrade (for significant changes to the database store):

 1. make sure the database you are upgrading has been cleanly shut down
 2. set the Neo4j configuration parameter "allow_store_upgrade=true" in your
    neo4j.properties or embedded configuration
 3. start the database
 4. the upgrade will happen during startup and the process is done when the
    database has been successfully started
 5. "allow_store_upgrade=true" configuration parameter should be removed, set
    to "false" or commented out

21.4.3. Upgrade 1.6 → 1.7

There are no store format changes between these versions, which means there is
no particular procedure you need to upgrade a single instance.

In an HA environment these steps need to be performed:

 1. shut down all the databases in the cluster
 2. shut down the ZooKeeper cluster and clear the version-2 directories on all
    the ZooKeeper instances
 3. start the ZooKeeper cluster again
 4. remove the databases except the master and start the master database with
    1.7
 5. start up the other databases so that they get a copy from the master

21.4.4. Upgrade 1.5 → 1.6

This upgrade changes lucene version from 3.1 to 3.5. The upgrade itself is done
by Lucene by loading an index.

In an HA environment these steps need to be performed:

 1. shut down all the databases in the cluster
 2. shut down the ZooKeeper cluster and clear the version-2 directories on all
    the ZooKeeper instances
 3. start the ZooKeeper cluster again
 4. start up the other databases so that they get a copy from the master

21.4.5. Upgrade 1.4 → 1.5

This upgrade includes a significant change to the layout of property store
files, which reduces their size on disk, and improves IO performance. To
achieve this layout change, the upgrade process takes some time to process the
whole of the existing database. You should budget for several minutes per
gigabyte of data as part of your upgrade planning.

Warning

The upgrade process for this upgrade temporarily requires additional disk
space, for the period while the upgrade is in progress. Before starting the
upgrade to Neo4J 1.5, you should ensure that the machine performing the upgrade
has free space equal to the current size of of the database on disk. You can
find the current space occupied by the database by inspecting the store file
directory (data/graph.db is the default location in Neo4J server). Once the
upgrade is complete, this additional space is no longer required.

21.5. Usage Data Collector

The Neo4j Usage Data Collector is a sub-system that gathers usage data,
reporting it to the UDC-server at udc.neo4j.org. It is easy to disable, and
does not collect any data that is confidential. For more information about what
is being sent, see below.

The Neo4j team uses this information as a form of automatic, effortless
feedback from the Neo4j community. We want to verify that we are doing the
right thing by matching download statistics with usage statistics. After each
release, we can see if there is a larger retention span of the server software.

The data collected is clearly stated here. If any future versions of this
system collect additional data, we will clearly announce those changes.

The Neo4j team is very concerned about your privacy. We do not disclose any
personally identifiable information.

21.5.1. Technical Information

To gather good statistics about Neo4j usage, UDC collects this information:

  * Kernel version - the build number, and if there are any modifications to
    the kernel.
  * Store id - it is a randomized globally unique id created at the same time a
    database is created.
  * Ping count - UDC holds an internal counter which is incremented for every
    ping, and reset for every restart of the kernel.
  * Source - this is either "neo4j" or "maven". If you downloaded Neo4j from
    the Neo4j website, it’s "neo4j", if you are using Maven to get Neo4j, it
    will be "maven".
  * Java version - the referrer string shows which version of Java is being
    used.
  * MAC address to uniquely identify instances behind firewalls
  * Registration id - for registered server instances
  * Tags about the execution context (e.g. test, language, web-container,
    app-container, spring, ejb)

After startup, UDC waits for ten minutes before sending the first ping. It does
this for two reasons; first, we don’t want the startup to be slower because of
UDC, and secondly, we want to keep pings from automatic tests to a minimum. The
ping to the UDC servers is done with a HTTP GET.

21.5.2. How to disable UDC

We’ve tried to make it extremely easy to disable UDC. In fact, the code for UDC
is not even included in the kernel jar but as a completely separate component.

There are three ways you can disable UDC:

 1. The easiest way is to just remove the neo4j-udc-*.jar file. By doing this,
    the kernel will not load UDC, and no pings will be sent.
 2. If you are using Maven, and want to make sure that UDC is never installed
    in your system, a dependency element like this will do that:

     <dependency>
       <groupId>org.neo4j</groupId>
       <artifactId>neo4j</artifactId>
       <version>${neo4j-version}</version>
       <exclusions>
         <exclusion>
           <groupId>org.neo4j</groupId>
           <artifactId>neo4j-udc</artifactId>
         </exclusion>
       </exclusions>
     </dependency>

    Where ${neo4j-version} is the Neo4j version in use.

 3. Lastly, if you are using a packaged version of Neo4j, and do not want to
    make any change to the jars, a system property setting like this will also
    make sure that UDC is never activated: -Dneo4j.ext.udc.disable=true.


--------------

^[1] http://repo1.maven.org/maven2/org/neo4j/ <http://repo1.maven.org/maven2/
org/neo4j/>

Chapter 22. Configuration & Performance

In order to get optimum performance out of Neo4j for your application there are
a few parameters that can be tweaked. The two main components that can be
configured are the Neo4j caches and the JVM that Neo4j runs in. The following
sections describe how to tune these.

22.1. Introduction

To gain good performance, these are the things to look into first:

  * Make sure the JVM is not spending too much time performing garbage
    collection. Monitoring heap usage on an application that uses Neo4j can be
    a bit confusing since Neo4j will increase the size of caches if there is
    available memory and decrease if the heap is getting full. The goal is to
    have a large enough heap to make sure that heavy/peak load will not result
    in so called GC trashing (performance can drop as much as two orders of
    magnitude when GC trashing happens).
  * Start the JVM with the -server flag and a good sized heap (see
    Section 22.4, “JVM Settings”). Having too large heap may also hurt
    performance so you may have to try some different heap sizes.
  * Use the parallel/concurrent garbage collector (we found that
    -XX:+UseConcMarkSweepGC works well in most use-cases)

22.1.1. How to add configuration settings

When creating the embedded Neo4j instance it is possible to pass in parameters
contained in a map where keys and values are strings.

Map<String, String> config = new HashMap<String, String>();
config.put( "neostore.nodestore.db.mapped_memory", "10M" );
config.put( "string_block_size", "60" );
config.put( "array_block_size", "300" );
GraphDatabaseService db = new ImpermanentGraphDatabase( config );

If no configuration is provided, the Database Kernel will try to determine
suitable settings from the information available via the JVM settings and the
underlying operating system.

The JVM is configured by passing command line flags when starting the JVM. The
most important configuration parameters for Neo4j are the ones that control the
memory and garbage collector, but some of the parameters for configuring the
Just In Time compiler are also of interest.

This is an example of starting up your applications main class using 64-bit
server VM mode and a heap space of 1GB:

java -d64 -server -Xmx1024m -cp /path/to/neo4j-kernel.jar:/path/to/jta.jar:/path/to/your-application.jar com.example.yourapp.MainClass

Looking at the example above you will also notice one of the most basic command
line parameters: the one for specifying the classpath. The classpath is the
path in which the JVM searches for your classes. It is usually a list of
jar-files. Specifying the classpath is done by specifying the flag -cp (or
-classpath) and then the value of the classpath. For Neo4j applications this
should at least include the path to the Neo4j neo4j-kernel.jar and the Java
Transaction API (jta.jar) as well as the path where the classes for your
application are located.

Tip

On Linux, Unix and Mac OS X each element in the path list are separated by a
colon symbol (:), on Windows the path elements are separated by a semicolon
(;).

When using the Neo4j REST server, see Section 18.2, “Server Configuration” for
how to add configuration settings for the database to the server.

22.2. Performance Guide

This is the Neo4j performance guide. It will attempt to guide you in how to use
Neo4j to achieve maximum performance.

22.2.1. Try this first

The first thing is to make sure the JVM is running well and not spending to
much time in garbage collection. Monitoring heap usage on an application that
uses Neo4j can be a bit confusing since Neo4j will increase the size of caches
if there is available memory and decrease if the heap is getting full. The goal
is to have a large enough heap so heavy/peak load will not result in so called
GC trashing (performance can drop as much as two orders of magnitude when this
happens).

Start the JVM with -server flag and -Xmx<good sized heap> (f.ex. -Xmx512M for
512Mb memory or -Xmx3G for 3Gb memory). Having too large heap may also hurt
performance so you may have to try some different heap sizes. Make sure
parallel/concurrent garbage collector is running (-XX:+UseConcMarkSweepGC works
well in most use-cases).

Finally make sure the OS has some memory to manage proper file system caches
meaning if your server has 8GB of RAM don’t use all of that RAM for heap
(unless you turned off memory mapped buffers) but leave a good size of it to
the OS. For more information on this see Chapter 22, Configuration &
Performance.

For Linux specific tweaks, see Section 22.8, “Linux Performance Guide”.

22.2.2. Neo4j primitives' lifecycle

Neo4j manages its primitives (nodes, relationships and properties) different
depending on how you use Neo4j. For example if you never get a property from a
certain node or relationship that node or relationship will not have its
properties loaded into memory. The first time, after loading a node or
relationship, any property is accessed all the properties are loaded for that
entity. If any of those properties contain an array larger than a few elements
or a long string such values are loaded on demand when requesting them
individually. Similarly, relationships of a node will only be loaded the first
time they are requested for that node.

Nodes and relationships are cached using LRU caches. If you (for some strange
reason) only work with nodes the relationship cache will become smaller and
smaller while the node cache is allowed to grow (if needed). Working with many
relationships and few nodes results in bigger relationship cache and smaller
node cache.

The Neo4j API specification does not say anything about order regarding
relationships so invoking

Node.getRelationships()

may return the relationships in a different order than the previous invocation.
This allows us to make even heavier optimizations returning the relationships
that are most commonly traversed.

All in all Neo4j has been designed to be very adaptive depending on how it is
used. The (unachievable) overall goal is to be able to handle any incoming
operation without having to go down and work with the file/disk I/O layer.

22.2.3. Configuring Neo4j

In Chapter 22, Configuration & Performance page there’s information on how to
configure Neo4j and the JVM. These settings have a lot impact on performance.

22.2.3.1. Disks, RAM and other tips

As always, as with any persistence solution, performance is very much depending
on the persistence media used. Better disks equals better performance.

If you have multiple disks or persistence media available it may be a good idea
to split the store files and transaction logs across those disks. Having the
store files running on disks with low seek time can do wonders for non cached
read operations. Today a typical mechanical drive has an average seek time of
about 5ms, this can cause a query or traversal to be very slow when available
RAM is too low or caches and memory mapped settings are badly configured. A new
good SATA enabled SSD has an average seek time of <100 microseconds meaning
those scenarios will execute at least 50 times faster.

To avoid hitting disk you need more RAM. On a standard mechanical drive you can
handle graphs with a few tens of millions of primitives with 1-2GB of RAM.
4-8GB of RAM can handle graphs with hundreds of millions of primitives while
you need a good server with 16-32GB to handle billions of primitives. However,
if you invest in a good SSD you will be able to handle much larger graphs on
less RAM.

Neo4j likes Java 1.6 JVMs and running in server mode so consider upgrading to
that if you haven’t yet (or at least give the -server flag). Use tools like
vmstat or equivalent to gather info when your application is running. If you
have high I/O waits and not that many blocks going out/in to disks when running
write/read transactions its a sign that you need to tweak your Java heap, Neo4j
cache and memory mapped settings (maybe even get more RAM or better disks).

22.2.3.2. Write performance

If you are experiencing poor write performance after writing some data
(initially fast, then massive slowdown) it may be the operating system writing
out dirty pages from the memory mapped regions of the store files. These
regions do not need to be written out to maintain consistency so to achieve
highest possible write speed that type of behavior should be avoided.

Another source of writes slow down can be the transaction size. Many small
transactions result in a lot of I/O writes to disc and should be avoided. Too
big transactions can result in OutOfMemory errors, since the uncommitted
transaction data is held on the Java Heap in memory. On details about
transaction management in Neo4j, please read the Chapter 13, Transaction
Management guidelines.

The Neo4j kernel makes use of several store files and a logical log file to
store the graph on disk. The store files contain the actual graph and the log
contains mutating operations. All writes to the logical log are append-only and
when a transaction is committed changes to the logical log will be forced
(fdatasync) down to disk. The store files are however not flushed to disk and
writes to them are not append-only either. They will be written to in a more or
less random pattern (depending on graph layout) and writes will not be forced
to disk until the log is rotated or the Neo4j kernel is shut down. It may be a
good idea to increase the logical log target size for rotation or turn off log
rotation if you experience problems with writes that can be linked to the
actual rotation of the log. Here is some example code demonstrating how to
change log rotation settings at runtime:

    GraphDatabaseService graphDb; // ...

    // get the XaDataSource for the native store
    TxModule txModule = ((EmbeddedGraphDatabase) graphDb).getConfig().getTxModule();
    XaDataSourceManager xaDsMgr = txModule.getXaDataSourceManager();
    XaDataSource xaDs = xaDsMgr.getXaDataSource( "nioneodb" );

    // turn off log rotation
    xaDs.setAutoRotate( false );

    // or to increase log target size to 100MB (default 10MB)
    xaDs.setLogicalLogTargetSize( 100 * 1024 * 1024L );

Since random writes to memory mapped regions for the store files may happen it
is very important that the data does not get written out to disk unless needed.
Some operating systems have very aggressive settings regarding when to write
out these dirty pages to disk. If the OS decides to start writing out dirty
pages of these memory mapped regions, write access to disk will stop being
sequential and become random. That hurts performance a lot, so to get maximum
write performance when using Neo4j make sure the OS is configured not to write
out any of the dirty pages caused by writes to the memory mapped regions of the
store files. As an example, if the machine has 8GB of RAM and the total size of
the store files is 4GB (fully memory mapped) the OS has to be configured to
accept at least 50% dirty pages in virtual memory to make sure we do not get
random disk writes.

Note: make sure to read the Section 22.8, “Linux Performance Guide” as well for
more specific information.

22.2.3.3. Second level caching

While normally building applications and "always assume the graph is in
memory", sometimes it is necessary to optimize certain performance critical
sections. Neo4j adds a small overhead even if the node, relationship or
property in question is cached when you compare to in memory data structures.
If this becomes an issue use a profiler to find these hot spots and then add
your own second-level caching. We believe second-level caching should be
avoided to greatest extend possible since it will force you to take care of
invalidation which sometimes can be hard. But when everything else fails you
have to use it so here is an example of how it can be done.

We have some POJO that wrapps a node holding its state. In this particular POJO
we’ve overridden the equals implementation.

   public boolean equals( Object obj )
   {
       return underlyingNode.getProperty( "some_property" ).equals( obj );
   }

   public int hashCode()
   {
       return underlyingNode.getProperty( "some_property" ).hashCode();
   }

This works fine in most scenarios but in this particular scenario many
instances of that POJO is being worked with in nested loops adding/removing/
getting/finding to collection classes. Profiling the applications will show
that the equals implementation is being called many times and can be viewed as
a hot spot. Adding second-level caching for the equals override will in this
particular scenario increase performance.

    private Object cachedProperty = null;

    public boolean equals( Object obj )
    {
       if ( cachedProperty == null )
       {
           cachedProperty = underlyingNode.getProperty( "some_property" );
       }
       return cachedProperty.equals( obj );
    }

    public int hashCode()
    {
       if ( cachedPropety == null )
       {
           cachedProperty = underlyingNode.getProperty( "some_property" );
       }
       return cachedProperty.hashCode();
    }

The problem now is that we need to invalidate the cached property whenever the
some_property is changed (may not be a problem in this scenario since the state
picked for equals and hash code computation often won’t change).

Tip

To sum up, avoid second-level caching if possible and only add it when you
really need it.

22.3. Caches in Neo4j

For how to provide custom configuration to Neo4j, see Section 22.1,
“Introduction”.

Neo4j utilizes two different types of caches: A file buffer cache and an object
cache. The file buffer cache caches the storage file data in the same format as
it is stored on the durable storage media. The object cache caches the nodes,
relationships and properties in a format that is optimized for high traversal
speeds and transactional mutation.

22.3.1. File buffer cache

Quick info

  * The file buffer cache is sometimes called low level cache or file system
    cache.
  * It caches the Neo4j data as stored on the durable media.
  * It uses the operating system memory mapping features when possible.
  * Neo4j will configure the cache automatically as long as the heap size of
    the JVM is configured properly.

The file buffer cache caches the Neo4j data in the same format as it is
represented on the durable storage media. The purpose of this cache layer is to
improve both read and write performance. The file buffer cache improves write
performance by writing to the cache and deferring durable write until the
logical log is rotated. This behavior is safe since all transactions are always
durably written to the logical log, which can be used to recover the store
files in the event of a crash.

Since the operation of the cache is tightly related to the data it stores, a
short description of the Neo4j durable representation format is necessary
background. Neo4j stores data in multiple files and relies on the underlying
file system to handle this efficiently. Each Neo4j storage file contains
uniform fixed size records of a particular type:

Store file  Record Contents
              size
nodestore      9 B Nodes

relstore      33 B Relationships

propstore     41 B Properties for nodes
                   and relationships

stringstore  128 B Values of string
                   properties

arraystore   128 B Values of array
                   properties

For strings and arrays, where data can be of variable length, data is stored in
one or more 120B chunks, with 8B record overhead. The sizes of these blocks can
actually be configured when the store is created using the string_block_size
and array_block_size parameters. The size of each record type can also be used
to calculate the storage requirements of a Neo4j graph or the appropriate cache
size for each file buffer cache. Note that some strings and arrays can be
stored without using the string store or the array store respectively, see
Section 22.5, “Compressed storage of short strings” and Section 22.6,
“Compressed storage of short arrays”.

Neo4j uses multiple file buffer caches, one for each different storage file.
Each file buffer cache divides its storage file into a number of equally sized
windows. Each cache window contains an even number of storage records. The
cache holds the most active cache windows in memory and tracks hit vs. miss
ratio for the windows. When the hit ratio of an uncached window gets higher
than the miss ratio of a cached window, the cached window gets evicted and the
previously uncached window is cached instead.

Important

Note that the block sizes can only be configured at store creation time.

22.3.1.1. Configuration

Parameter                                          Possible  Effect
                                                   values
use_memory_mapped_buffers                          true or   If set to true
                                                   false     Neo4j will use the
                                                             operating systems
                                                             memory mapping
                                                             functionality for
                                                             the file buffer
                                                             cache windows. If
                                                             set to false Neo4j
                                                             will use its own
                                                             buffer
                                                             implementation. In
                                                             this case the
                                                             buffers will reside
                                                             in the JVM heap
                                                             which needs to be
                                                             increased
                                                             accordingly. The
                                                             default value for
                                                             this parameter is
                                                             true, except on
                                                             Windows.

neostore.nodestore.db.mapped_memory                          The maximum amount
                                                             of memory to use
                                                             for the file buffer
                                                             cache of the node
                                                             storage file.

neostore.relationshipstore.db.mapped_memory                  The maximum amount
                                                             of memory to use
                                                             for the file buffer
                                                             cache of the
                                                             relationship store
                                                      The    file.
                                                    maximum
neostore.propertystore.db.index.keys.mapped_memory amount of The maximum amount
                                                   memory to of memory to use
                                                    use for  for the file buffer
                                                    memory   cache of the
                                                    mapped   something-something
                                                    buffers  file.
                                                   for this
neostore.propertystore.db.index.mapped_memory        file    The maximum amount
                                                    buffer   of memory to use
                                                    cache.   for the file buffer
                                                      The    cache of the
                                                    default  something-something
                                                    unit is  file.
                                                   MiB, for
neostore.propertystore.db.mapped_memory              other   The maximum amount
                                                   units use of memory to use
                                                    any of   for the file buffer
                                                      the    cache of the
                                                   following property storage
                                                   suffixes: file.
                                                    B, k, M
neostore.propertystore.db.strings.mapped_memory      or G.   The maximum amount
                                                             of memory to use
                                                             for the file buffer
                                                             cache of the string
                                                             property storage
                                                             file.

neostore.propertystore.db.arrays.mapped_memory               The maximum amount
                                                             of memory to use
                                                             for the file buffer
                                                             cache of the array
                                                             property storage
                                                             file.

string_block_size                                            Specifies the block
                                                             size for storing
                                                             strings. This
                                                             parameter is only
                                                             honored when the
                                                             store is created,
                                                             otherwise it is
                                                             ignored. Note that
                                                             each character in a
                                                             string occupies two
                                                             bytes, meaning that
                                                             a block size of 120
                                                             (the default size)
                                                             will hold a 60
                                                             character long
                                                             string before
                                                             overflowing into a
                                                             second block. Also
                                                             note that each
                                                      The    block carries an
                                                   number of overhead of 8
                                                   bytes per bytes. This means
                                                    block.   that if the block
                                                             size is 120, the
                                                             size of the stored
                                                             records will be 128
                                                             bytes.

array_block_size                                             Specifies the block
                                                             size for storing
                                                             arrays. This
                                                             parameter is only
                                                             honored when the
                                                             store is created,
                                                             otherwise it is
                                                             ignored. The
                                                             default block size
                                                             is 120 bytes, and
                                                             the overhead of
                                                             each block is the
                                                             same as for string
                                                             blocks, i.e., 8
                                                             bytes.

dump_configuration                                 true or   If set to true the
                                                   false     current
                                                             configuration
                                                             settings will be
                                                             written to the
                                                             default system
                                                             output, mostly the
                                                             console or the
                                                             logfiles.

When memory mapped buffers are used (use_memory_mapped_buffers = true) the heap
size of the JVM must be smaller than the total available memory of the
computer, minus the total amount of memory used for the buffers. When heap
buffers are used (use_memory_mapped_buffers = false) the heap size of the JVM
must be large enough to contain all the buffers, plus the runtime heap memory
requirements of the application and the object cache.

When reading the configuration parameters on startup Neo4j will automatically
configure the parameters that are not specified. The cache sizes will be
configured based on the available memory on the computer, how much is used by
the JVM heap, and how large the storage files are.

22.3.2. Object cache

Quick info

  * The object cache is sometimes called high level cache.
  * It caches the Neo4j data in a form optimized for fast traversal.

The object cache caches individual nodes and relationships and their properties
in a form that is optimized for fast traversal of the graph. There are two
different categories of object caches in Neo4j.

There is the reference caches. Here Neo4j will utilize as much as it can out of
the allocated heap memory for the JVM for object caching and relies on garbage
collection for eviction from the cache in an LRU manner. Note however that
Neo4j is "competing" for the heap space with other objects in the same JVM,
such as a your application, if deployed in embedded mode, and Neo4j will let
the application "win" by using less memory if the application needs more.

Note

The GC resistant cache described below is only available in the Neo4j
Enterprise Edition.

The other is the GC resistant cache which gets assigned a certain amount of
space in the JVM heap and will purge objects whenever it grows bigger than
that. It is assigned a maximum amount of memory which the sum of all cached
objects in it will not exceed. Objects will be evicted from cache when the
maximum size is about to be reached, instead of relying on garbage collection
(GC) to make that decision. Here the competition with other objects in the heap
as well as GC-pauses can be better controlled since the cache gets assigned a
maximum heap space usage. The overhead of the GC resistant cache is also much
smaller as well as insert/lookup times faster than for reference caches.

Warning

The GC resistant cache is experimental. Production use is only advisable after
extensive user testing.

Tip

The use of heap memory is subject to the java garbage collector - depending on
the cache type some tuning might be needed to play well with the GC at large
heap sizes. Therefore, assigning a large heap for Neo4j’s sake isn’t always the
best strategy as it may lead to long GC-pauses. Instead leave some space for
Neo4j’s filesystem caches. These are outside of the heap and under under the
kernel’s direct control, thus more efficiently managed.

The content of this cache are objects with a representation geared towards
supporting the Neo4j object API and graph traversals. Reading from this cache
is 5 to 10 times faster than reading from the file buffer cache. This cache is
contained in the heap of the JVM and the size is adapted to the current amount
of available heap memory.

Nodes and relationships are added to the object cache as soon as they are
accessed. The cached objects are however populated lazily. The properties for a
node or relationship are not loaded until properties are accessed for that node
or relationship. String (and array) properties are not loaded until that
particular property is accessed. The relationships for a particular node is
also not loaded until the relationships are accessed for that node.

22.3.2.1. Configuration

The main configuration parameter for the object cache is the cache_type
parameter. This specifies which cache implementation to use for the object
cache. Note that there will exist two cache instances, one for nodes and one
for relationships. The available cache types are:

cache_type Description
none       Do not use a high level cache. No objects will be cached.

soft       Provides optimal utilization of the available memory. Suitable for
           high performance traversal. May run into GC issues under high load
           if the frequently accessed parts of the graph does not fit in the
           cache.

           This is the default cache implementation.

weak       Provides short life span for cached objects. Suitable for high
           throughput applications where a larger portion of the graph than
           what can fit into memory is frequently accessed.

strong     This cache will hold on to all data that gets loaded to never
           release it again. Provides good performance if your graph is small
           enough to fit in memory.

gcr        Provides means of assigning a specific amount of memory to dedicate
           to caching loaded nodes and relationships. Small footprint and fast
           insert/lookup. Should be the best option for most scenarios. See
           below on how to configure it. Note that this option is only
           available in the Neo4j Enterprise Edition.

22.3.2.2. GC resistant cache configuration

Since the GC resistant cache operates with a maximum size in the JVM it may be
configured per use case for optimal performance. There are two aspects of the
cache size.

One is the size of the array referencing the objects that are put in the cache.
It is specified as a fraction of the heap, for example specifying 5 will let
that array itself take up 5% out of the entire heap. Increasing this figure (up
to a maximum of 10) will reduce the chance of hash collisions at the expense of
more heap used for it. More collisions means more redundant loading of objects
from the low level cache.

configuration option                  Description (what it controls)
Example value                         node_cache_array_fraction

Fraction of the heap to dedicate to   7
the array holding the nodes in the
cache (max 10).

relationship_cache_array_fraction     Fraction of the heap to dedicate to the
                                      array holding the relationships in the
                                      cache (max 10).

The other aspect is the maximum size of all the objects in the cache. It is
specified as size in bytes, for example 500M for 500 megabytes or 2G for two
gigabytes. Right before the maximum size is reached a purge is performed where
(currently) random objects are evicted from the cache until the cache size gets
below 90% of the maximum size. Optimal settings for the maximum size depends on
the size of your graph. The configured maximum size should leave enough room
for other objects to coexist in the same JVM, but at the same time large enough
to keep loading from the low level cache at a minimum. Predicted load on the
JVM as well as layout of domain level objects should also be take into
consideration.

configuration option                  Description (what it controls)
Example value                         node_cache_size

Maximum size of the heap memory to    2G
dedicate to the cached nodes.

relationship_cache_size               Maximum size of the heap memory to
                                      dedicate to the cached relationships.

You can read about references and relevant JVM settings for Sun HotSpot here:

  * Understanding soft/weak references <http://weblogs.java.net/blog/enicholas/
    archive/2006/05/understanding_w.html>
  * How Hotspot Decides to Clear SoftReferences <http://
    jeremymanson.blogspot.com/2009/07/how-hotspot-decides-to-clear_07.html>
  * HotSpot FAQ <http://java.sun.com/docs/hotspot/HotSpotFAQ.html#gc_softrefs>

22.3.2.3. Heap memory usage

This table can be used to calculate how much memory the data in the object
cache will occupy on a 64bit JVM:

Object        Size Comment
Node           344 Size for each node (not counting its relationships or
                 B properties).

              48 B Object overhead.

               136 Property storage (ArrayMap 48B, HashMap 88B).
                 B

               136 Relationship storage (ArrayMap 48B, HashMap 88B).
                 B

              24 B Location of first / next set of relationships.

Relationship   208 Size for each relationship (not counting its properties).
                 B

              48 B Object overhead.

               136 Property storage (ArrayMap 48B, HashMap 88B).
                 B

Property       116 Size for each property of a node or relationship.
                 B

              32 B Data element - allows for transactional modification and
                   keeps track of on disk location.

              48 B Entry in the hash table where it is stored.

              12 B Space used in hash table, accounts for normal fill ratio.

              24 B Property key index.

Relationships  108 Size for each relationship type for a node that has a
                 B relationship of that type.

              48 B Collection of the relationships of this type.

              48 B Entry in the hash table where it is stored.

              12 B Space used in hash table, accounts for normal fill ratio.

Relationships  8 B Space used by each relationship related to a particular node
                   (both incoming and outgoing).

Primitive     24 B Size of a primitive property value.

String        64+B Size of a string property value. 64 + 2*len(string) B (64
                   bytes, plus two bytes for each character in the string).

22.4. JVM Settings

There are two main memory parameters for the JVM, one controls the heap space
and the other controls the stack space. The heap space parameter is the most
important one for Neo4j, since this governs how many objects you can allocate.
The stack space parameter governs the how deep the call stack of your
application is allowed to get.

When it comes to heap space the general rule is: the larger heap space you have
the better, but make sure the heap fits in the RAM memory of the computer. If
the heap is paged out to disk performance will degrade rapidly. Having a heap
that is much larger than what your application needs is not good either, since
this means that the JVM will accumulate a lot of dead objects before the
garbage collector is executed, this leads to long garbage collection pauses and
undesired performance behavior.

Having a larger heap space will mean that Neo4j can handle larger transactions
and more concurrent transactions. A large heap space will also make Neo4j run
faster since it means Neo4j can fit a larger portion of the graph in its
caches, meaning that the nodes and relationships your application uses
frequently are always available quickly. The default heap size for a 32bit JVM
is 64MB (and 30% larger for 64bit), which is too small for most real
applications.

Neo4j works fine with the default stack space configuration, but if your
application implements some recursive behavior it is a good idea to increment
the stack size. Note that the stack size is shared for all threads, so if you
application is running a lot of concurrent threads it is a good idea to
increase the stack size.

  * The heap size is set by specifying the -Xmx???m parameter to hotspot, where
    ??? is the heap size in megabytes. Default heap size is 64MB for 32bit
    JVMs, 30% larger (appr. 83MB) for 64bit JVMs.
  * The stack size is set by specifying the -Xss???m parameter to hotspot,
    where ??? is the stack size in megabytes. Default stack size is 512kB for
    32bit JVMs on Solaris, 320kB for 32bit JVMs on Linux (and Windows), and
    1024kB for 64bit JVMs.

Most modern CPUs implement a Non-Uniform Memory Access (NUMA) architecture
<http://en.wikipedia.org/wiki/Non-Uniform_Memory_Access>, where different parts
of the memory have different access speeds. Suns Hotspot JVM is able to
allocate objects with awareness of the NUMA structure as of version 1.6.0
update 18. When enabled this can give up to 40% performance improvements. To
enabled the NUMA awareness, specify the -XX:+UseNUMA parameter (works only when
using the Parallel Scavenger garbage collector (default or -XX:+UseParallelGC
not the concurrent mark and sweep one).

Properly configuring memory utilization of the JVM is crucial for optimal
performance. As an example, a poorly configured JVM could spend all CPU time
performing garbage collection (blocking all threads from performing any work).
Requirements such as latency, total throughput and available hardware have to
be considered to find the right setup. In production, Neo4j should run on a
multi core/CPU platform with the JVM in server mode.

22.4.1. Configuring heap size and GC

A large heap allows for larger node and relationship caches — which is a good
thing — but large heaps can also lead to latency problems caused by full
garbage collection. The different high level cache implementations available in
Neo4j together with a suitable JVM configuration of heap size and garbage
collection (GC) should be able to handle most workloads.

The default cache (soft reference based LRU cache) works best with a heap that
never gets full: a graph where the most used nodes and relationships can be
cached. If the heap gets too full there is a risk that a full GC will be
triggered; the larger the heap, the longer it can take to determine what soft
references should be cleared.

Using the strong reference cache means that all the nodes and relationships
being used must fit in the available heap. Otherwise there is a risk of getting
out-of-memory exceptions. The soft reference and strong reference caches are
well suited for applications were the overal throughput is important.

The weak reference cache basically needs enough heap to handle the peak load of
the application — peak load multiplied by the average memory required per
request. It is well suited for low latency requirements were GC interuptions
are not acceptable.

Important

When running Neo4j on Windows, keep in mind that the memory mapped buffers are
allocated on heap by default, so they need to be taken into account when
determining heap size.

Table 22.1. Guidelines for heap size

+---------------------------------------------------------+
|Number of     |RAM size  |Heap         |Reserved RAM for |
|primitives    |          |configuration|the OS           |
|--------------+----------+-------------+-----------------|
|10M           |2GB       |512MB        |the rest         |
|--------------+----------+-------------+-----------------|
|100M          |8GB+      |1-4GB        |1-2GB            |
|--------------+----------+-------------+-----------------|
|1B+           |16GB-32GB+|4GB+         |1-2GB            |
+---------------------------------------------------------+


Tip

The recommended garbage collector to use when running Neo4j in production is
the Concurrent Mark and Sweep Compactor turned on by supplying
-XX:+UseConcMarkSweepGC as a JVM parameter.

When having made sure that the heap size is well configured the second thing to
tune in order to tune the garbage collector for your application is to specify
the sizes of the different generations of the heap. The default settings are
well tuned for "normal" applications, and work quite well for most
applications, but if you have an application with either really high allocation
rate, or a lot of long lived objects you might want to consider tuning the
sizes of the heap generation. The ratio between the young and tenured
generation of the heap is specified by using the -XX:NewRatio=# command line
option (where # is replaced by a number). The default ratio is 1:12 for client
mode JVM, and 1:8 for server mode JVM. You can also specify the size of the
young generation explicitly using the -Xmn command line option, which works
just like the -Xmx option that specifies the total heap space.

+-----------------------------------------------------------------------------+
|GC shortname       |Generation|Command line parameter |Comment               |
|-------------------+----------+-----------------------+----------------------|
|Copy               |Young     |-XX:+UseSerialGC       |The Copying collector |
|-------------------+----------+-----------------------+----------------------|
|MarkSweepCompact   |Tenured   |-XX:+UseSerialGC       |The Mark and Sweep    |
|                   |          |                       |Compactor             |
|-------------------+----------+-----------------------+----------------------|
|ConcurrentMarkSweep|Tenured   |-XX:+UseConcMarkSweepGC|The Concurrent Mark   |
|                   |          |                       |and Sweep Compactor   |
|-------------------+----------+-----------------------+----------------------|
|ParNew             |Young     |-XX:+UseParNewGC       |The parallel Young    |
|                   |          |                       |Generation            |
|                   |          |                       |Collector — can only  |
|                   |          |                       |be used with the      |
|                   |          |                       |Concurrent mark and   |
|                   |          |                       |sweep compactor.      |
|-------------------+----------+-----------------------+----------------------|
|PS Scavenge        |Young     |-XX:+UseParallelGC     |The parallel object   |
|                   |          |                       |scavenger             |
|-------------------+----------+-----------------------+----------------------|
|PS MarkSweep       |Tenured   |-XX:+UseParallelGC     |The parallel mark and |
|                   |          |                       |sweep collector       |
+-----------------------------------------------------------------------------+

These are the default configurations on some platforms according to our
non-exhaustive research:

+-----------------------------------------------------------------------------+
|JVM       |-d32 -client       |-d32 -server    |-d64 -client       |-d64     |
|          |                   |                |                   |-server  |
|----------+-------------------+----------------+-------------------+---------|
|Mac OS X  |ParNew and         |PS Scavenge and |ParNew and         |PS       |
|Snow      |ConcurrentMarkSweep|PS MarkSweep    |ConcurrentMarkSweep|Scavenge |
|Leopard,  |                   |                |                   |and PS   |
|64-bit,   |                   |                |                   |MarkSweep|
|Hotspot   |                   |                |                   |         |
|1.6.0_17  |                   |                |                   |         |
|----------+-------------------+----------------+-------------------+---------|
|Ubuntu,   |Copy and           |Copy and        |N/A                |N/A      |
|32-bit,   |MarkSweepCompact   |MarkSweepCompact|                   |         |
|Hotspot   |                   |                |                   |         |
|1.6.0_16  |                   |                |                   |         |
+-----------------------------------------------------------------------------+

22.5. Compressed storage of short strings

Neo4j will try to classify your strings in a short string class and if it
manages that it will treat it accordingly. In that case, it will be stored
without indirection in the property store, inlining it instead in the property
record, meaning that the dynamic string store will not be involved in storing
that value, leading to reduced disk footprint. Additionally, when no string
record is needed to store the property, it can be read and written in a single
lookup, leading to performance improvements.

The various classes for short strings are:

  * Numerical, consisting of digits 0..9 and the punctuation space, period,
    dash, plus, comma and apostrophe.
  * Date, consisting of digits 0..9 and the punctuation space dash, colon,
    slash, plus and comma.
  * Uppercase, consisting of uppercase letters A..Z, and the punctuation space,
    underscore, period, dash, colon and slash.
  * Lowercase, like upper but with lowercase letters a..z instead of uppercase
  * E-mail, consisting of lowercase letters a..z and the punctuation comma,
    underscore, period, dash, plus and the at sign (@)
  * URI, consisting of lowercase letters a..z, digits 0..9 and most punctuation
    available.
  * Alphanumerical, consisting of both upper and lowercase letters a..zA..z,
    digits 0..9 and punctuation space and underscore.
  * Alphasymbolical, consisting of both upper and lowercase letters a..zA..Z
    and the punctuation space, underscore, period, dash, colon, slash, plus,
    comma, apostrophe, at sign, pipe and semicolon.
  * European, consisting of most accented european characters and digits plus
    punctuation space, dash, underscore and period - like latin1 but with less
    punctuation
  * Latin 1
  * UTF-8

In addition to the string’s contents, the number of characters also determines
if the string can be inlined or not. Each class has its own character count
limits, which are

  * For Numerical and Date, 54
  * For Uppercase, Lowercase and E-mail, 43
  * For URI, Alphanumerical and Alphasymbolical, 36
  * For European, 31
  * For Latin1, 27
  * For UTF-8, 14

That means that the largest inline-able string is 54 characters long and must
be of the Numerical class and also that all Strings of size 14 or less will
always be inlined.

Also note that the above limits are for the default 41 byte PropertyRecord
layout - if that parameter is changed via editing the source and recompiling,
the above have to be recalculated.

22.6. Compressed storage of short arrays

Neo4j will try to store your primitive arrays in a compressed way, so as to
save disk space and possibly an I/O operation. To do that, it employs a
"bit-shaving" algorithm that tries to reduce the number of bits required for
storing the members of the array. In particular:

 1. For each member of the array, it determines the position of leftmost set
    bit.
 2. Determines the largest such position among all members of the array
 3. It reduces all members to that number of bits
 4. Stores those values, prefixed by a small header.

That means that when even a single negative value is included in the array then
the natural size of the primitives will be used.

There is a possibility that the result can be inlined in the property record
if:

  * It is less than 24 bytes after compression
  * It has less than 64 members

For example, an array long[] {0L, 1L, 2L, 4L} will be inlined, as the largest
entry (4) will require 3 bits to store so the whole array will be stored in 4*3
=12 bits. The array long[] {-1L, 1L, 2L, 4L} however will require the whole 64
bits for the -1 entry so it needs 64*4 = 32 bytes and it will end up in the
dynamic store.

22.7. Memory mapped IO settings

Each file in the Neo4j store can use memory mapped I/O for reading/writing.
Best performance is achieved if the full file can be memory mapped but if there
isn’t enough memory for that Neo4j will try and make the best use of the memory
it gets (regions of the file that get accessed often will more likely be memory
mapped).

Important

Neo4j makes heavy use of the java.nio package. Native I/O will result in memory
being allocated outside the normal Java heap so that memory usage needs to be
taken into consideration. Other processes running on the OS will impact the
availability of such memory. Neo4j will require all of the heap memory of the
JVM plus the memory to be used for memory mapping to be available as physical
memory. Other processes may thus not use more than what is available after the
configured memory allocation is made for Neo4j.

A well configured OS with large disk caches will help a lot once we get cache
misses in the node and relationship caches. Therefore it is not a good idea to
use all available memory as Java heap.

If you look into the directory of your Neo4j database, you will find its store
files, all prefixed by neostore:

  * nodestore stores information about nodes
  * relationshipstore holds all the relationships
  * propertystore stores information of properties and all simple properties
    such as primitive types (both for relationships and nodes)
  * propertystore strings stores all string properties
  * propertystore arrays stores all array properties

There are other files there as well, but they are normally not interesting in
this context.

This is how the default memory mapping configuration looks:

neostore.nodestore.db.mapped_memory=25M
neostore.relationshipstore.db.mapped_memory=50M
neostore.propertystore.db.mapped_memory=90M
neostore.propertystore.db.strings.mapped_memory=130M
neostore.propertystore.db.arrays.mapped_memory=130M

22.7.1. Optimizing for traversal speed example

To tune the memory mapping settings start by investigating the size of the
different store files found in the directory of your Neo4j database. Here is an
example of some of the files and sizes in a Neo4j database:

14M neostore.nodestore.db
510M neostore.propertystore.db
1.2G neostore.propertystore.db.strings
304M neostore.relationshipstore.db

In this example the application is running on a machine with 4GB of RAM. We’ve
reserved about 2GB for the OS and other programs. The Java heap is set to
1.5GB, that leaves about 500MB of RAM that can be used for memory mapping.

Tip

If traversal speed is the highest priority it is good to memory map as much as
possible of the node- and relationship stores.

An example configuration on the example machine focusing on traversal speed
would then look something like:

neostore.nodestore.db.mapped_memory=15M
neostore.relationshipstore.db.mapped_memory=285M
neostore.propertystore.db.mapped_memory=100M
neostore.propertystore.db.strings.mapped_memory=100M
neostore.propertystore.db.arrays.mapped_memory=0M

22.7.2. Batch insert example

Read general information on batch insertion in Section 14.1, “Batch Insertion”.

The configuration should suit the data set you are about to inject using
BatchInsert. Lets say we have a random-like graph with 10M nodes and 100M
relationships. Each node (and maybe some relationships) have different
properties of string and Java primitive types (but no arrays). The important
thing with a random graph will be to give lots of memory to the relationship
and node store:

neostore.nodestore.db.mapped_memory=90M
neostore.relationshipstore.db.mapped_memory=3G
neostore.propertystore.db.mapped_memory=50M
neostore.propertystore.db.strings.mapped_memory=100M
neostore.propertystore.db.arrays.mapped_memory=0M

The configuration above will fit the entire graph (with exception to
properties) in memory.

A rough formula to calculate the memory needed for the nodes:

number_of_nodes * 9 bytes

and for relationships:

number_of_relationships * 33 bytes

Properties will typically only be injected once and never read so a few
megabytes for the property store and string store is usually enough. If you
have very large strings or arrays you may want to increase the amount of memory
assigned to the string and array store files.

An important thing to remember is that the above configuration will need a Java
heap of 3.3G+ since in batch inserter mode normal Java buffers that gets
allocated on the heap will be used instead of memory mapped ones.

22.8. Linux Performance Guide

The key to achieve good performance on reads and writes is to have lots of RAM
since disks are so slow. This guide will focus on achieving good write
performance on a Linux kernel based operating system.

If you have not already read the information available in Chapter 22, 
Configuration & Performance do that now to get some basic knowledge on memory
mapping and store files with Neo4j.

This section will guide you through how to set up a file system benchmark and
use it to configure your system in a better way.

22.8.1. Setup

Create a large file with random data. The file should fit in RAM so if your
machine has 4GB of RAM a 1-2GB file with random data will be enough. After the
file has been created we will read the file sequentially a few times to make
sure it is cached.

$ dd if=/dev/urandom of=store bs=1M count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 263.53 s, 4.0 MB/s
$
$ dd if=store of=/dev/null bs=100M
10+0 records in
10+0 records out
1048576000 bytes (1.0 GB) copied, 38.6809 s, 27.1 MB/s
$
$ dd if=store of=/dev/null bs=100M
10+0 records in
10+0 records out
1048576000 bytes (1.0 GB) copied, 1.52365 s, 688 MB/s
$ dd if=store of=/dev/null bs=100M
10+0 records in
10+0 records out
1048576000 bytes (1.0 GB) copied, 0.776044 s, 1.4 GB/s

If you have a standard hard drive in the machine you may know that it is not
capable of transfer speeds as high as 1.4GB/s. What is measured is how fast we
can read a file that is cached for us by the operating system.

Next we will use a small utility that simulates the Neo4j kernel behavior to
benchmark write speed of the system.

$ git clone git@github.com:neo4j/tooling.git
...
$ cd tooling/write-test/
$ mvn compile
[INFO] Scanning for projects...
...
$ ./run
Usage: <large file> <log file> <[record size] [min tx size] [max tx size] [tx count] <[--nosync | --nowritelog | --nowritestore | --noread | --nomemorymap]>>

The utility will be given a store file (large file we just created) and a name
of a log file. Then a record size in bytes, min tx size, max tx size and
transaction count must be set. When started the utility will map the large
store file entirely in memory and read (transaction size) records from it
randomly and then write them sequentially to the log file. The log file will
then force changes to disk and finally the records will be written back to the
store file.

22.8.2. Running the benchmark

Lets try to benchmark 100 transactions of size 100-500 with a record size of 33
bytes (same record size used by the relationship store).

$ ./run store logfile 33 100 500 100
tx_count[100] records[30759] fdatasyncs[100] read[0.96802425 MB] wrote[1.9360485 MB]
Time was: 4.973
20.108585 tx/s, 6185.2 records/s, 20.108585 fdatasyncs/s, 199.32773 kB/s on reads, 398.65546 kB/s on writes

We see that we get about 6185 record updates/s and 20 transactions/s with the
current transaction size. We can change the transaction size to be bigger, for
example writing 10 transactions of size 1000-5000 records:

$ ./run store logfile 33 1000 5000 10
tx_count[10] records[24511] fdatasyncs[10] read[0.77139187 MB] wrote[1.5427837 MB]
Time was: 0.792
12.626263 tx/s, 30948.232 records/s, 12.626263 fdatasyncs/s, 997.35516 kB/s on reads, 1994.7103 kB/s on writes

With larger transaction we will do fewer of them per second but record
throughput will increase. Lets see if it scales, 10 transactions in under 1s
then 100 of them should execute in about 10s:

$ ./run store logfile 33 1000 5000 100
tx_count[100] records[308814] fdatasyncs[100] read[9.718763 MB] wrote[19.437527 MB]
Time was: 65.115
1.5357445 tx/s, 4742.594 records/s, 1.5357445 fdatasyncs/s, 152.83751 kB/s on reads, 305.67502 kB/s on writes

This is not very linear scaling. We modified a bit more than 10x records in
total but the time jumped up almost 100x. Running the benchmark watching vmstat
output will reveal that something is not as it should be:

$ vmstat 3
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 0  1  47660 298884 136036 2650324    0    0     0 10239 1167 2268  5  7 46 42
 0  1  47660 302728 136044 2646060    0    0     0  7389 1267 2627  6  7 47 40
 0  1  47660 302408 136044 2646024    0    0     0 11707 1861 2016  8  5 48 39
 0  2  47660 302472 136060 2646432    0    0     0 10011 1704 1878  4  7 49 40
 0  1  47660 303420 136068 2645788    0    0     0 13807 1406 1601  4  5 44 47

There are a lot of blocks going out to IO, way more than expected for the write
speed we are seeing in the benchmark. Another observation that can be made is
that the Linux kernel has spawned a process called "flush-x:x" (run top) that
seems to be consuming a lot of resources.

The problem here is that the Linux kernel is trying to be smart and write out
dirty pages from the virtual memory. As the benchmark will memory map a 1GB
file and do random writes it is likely that this will result in 1/4 of the
memory pages available on the system to be marked as dirty. The Neo4j kernel is
not sending any system calls to the Linux kernel to write out these pages to
disk however the Linux kernel decided to start doing so and it is a very bad
decision. The result is that instead of doing sequential like writes down to
disk (the logical log file) we are now doing random writes writing regions of
the memory mapped file to disk.

It is possible to observe this behavior in more detail by looking at /proc/
vmstat "nr_dirty" and "nr_writeback" values. By default the Linux kernel will
start writing out pages at a very low ratio of dirty pages (10%).

$ sync
$ watch grep -A 1 dirty /proc/vmstat
...
nr_dirty 22
nr_writeback 0

The "sync" command will write out all data (that needs writing) from memory to
disk. The second command will watch the "nr_dirty" and "nr_writeback" count
from vmstat. Now start the benchmark again and observe the numbers:

nr_dirty 124947
nr_writeback 232

The "nr_dirty" pages will quickly start to rise and after a while the
"nr_writeback" will also increase meaning the Linux kernel is scheduling a lot
of pages to write out to disk.

22.8.3. Fixing the problem

As we have 4GB RAM on the machine and memory map a 1GB file that does not need
its content written to disk (until we tell it to do so because of logical log
rotation or Neo4j kernel shutdown) it should be possible to do endless random
writes to that memory with high throughput. All we have to do is to tell the
Linux kernel to stop trying to be smart. Edit the /etc/sysctl.conf (need root
access) and add the following lines:

vm.dirty_background_ratio = 50
vm.dirty_ratio = 80

Then (as root) execute:

# sysctl -p

The "vm.dirty_background_ratio" tells at what ratio should the linux kernel
start the background task of writing out dirty pages. We increased this from
the default 10% to 50% and that should cover the 1GB memory mapped file. The
"vm.dirty_ratio" tells at what ratio all IO writes become synchronous, meaning
that we can not do IO calls without waiting for the underlying device to
complete them (which is something you never want to happen).

Rerun the benchmark:

$ ./run store logfile 33 1000 5000 100
tx_count[100] records[265624] fdatasyncs[100] read[8.35952 MB] wrote[16.71904 MB]
Time was: 6.781
14.7470875 tx/s, 39171.805 records/s, 14.7470875 fdatasyncs/s, 1262.3726 kB/s on reads, 2524.745 kB/s on writes

Results are now more in line with what can be expected, 10x more records
modified results in 10x longer execution time. The vmstat utility will not
report any absurd amount of IO blocks going out (it reports the ones caused by
the fdatasync to the logical log) and Linux kernel will not spawn a "flush-x:x"
background process writing out dirty pages caused by writes to the memory
mapped store file.

22.9. Linux specific notes

22.9.1. File system tuning for high IO

In order to support the high IO load of small transactions from a database, the
underlying file system should be tuned. Symptoms for this are low CPU load with
high iowait. In this case, there are a couple of tweaks possible on Linux
systems:

  * Disable access-time updates: noatime,nodiratime flags for disk mount
    command or in the /etc/fstab for the database disk volume mount.
  * Tune the IO scheduler for high disk IO on the database disk.

22.9.2. Setting the number of open files

Linux platforms impose an upper limit on the number of concurrent files a user
may have open. This number is reported for the current user and session with
the command

user@localhost:~$ ulimit -n
1024

The usual default of 1024 is often not enough, especially when many indexes are
used or a server installation sees too many connections (network sockets count
against that limit as well). Users are therefore encouraged to increase that
limit to a healthy value of 40000 or more, depending on usage patterns. Setting
this value via the ulimit command is possible only for the root user and that
for that session only. To set the value system wide you have to follow the
instructions for your platform.

What follows is the procedure to set the open file descriptor limit to 40k for
user neo4j under Ubuntu 10.04 and later. If you opted to run the neo4j service
as a different user, change the first field in step 2 accordingly.

 1. Become root since all operations that follow require editing protected
    system files.

    user@localhost:~$ sudo su -
    Password:
    root@localhost:~$

 2. Edit /etc/security/limits.conf and add these two lines:

    neo4j   soft    nofile  40000
    neo4j   hard    nofile  40000

 3. Edit /etc/pam.d/su and uncomment or add the following line:

    session    required   pam_limits.so

 4. A restart is required for the settings to take effect.

    After the above procedure, the neo4j user will have a limit of 40000
    simultaneous open files. If you continue experiencing exceptions on Too
    many open files or Could not stat() directory then you may have to raise
    that limit further.

Chapter 23. High Availability

Note

The High Availability features are only available in the Neo4j Enterprise
Edition.

Neo4j High Availability or “Neo4j HA” provides the following two main features:

 1. It enables a fault-tolerant database architecture, where several Neo4j
    slave databases can be configured to be exact replicas of a single Neo4j
    master database. This allows the end-user system to be fully functional and
    both read and write to the database in the event of hardware failure.
 2. It enables a horizontally scaling read-mostly architecture that enables the
    system to handle more read load than a single Neo4j database instance can
    handle.

23.1. Architecture

Neo4j HA has been designed to make the transition from single machine to multi
machine operation simple, by not having to change the already existing
application.

Consider an existing application with Neo4j embedded and running on a single
machine. To deploy such an application in a multi machine setup the only
required change is to switch the creation of the GraphDatabaseService from
EmbeddedGraphDatabase to HighlyAvailableGraphDatabase. Since both implement the
same interface, no additional changes are required.

Figure 23.1. Typical setup when running multiple Neo4j instances in HA mode

Neo4j Highly Available Cluster


When running Neo4j in HA mode there is always a single master and zero or more
slaves. Compared to other master-slave replication setups Neo4j HA can handle
writes on a slave so there is no need to redirect writes to the master.

A slave will handle writes by synchronizing with the master to preserve
consistency. Updates will however propagate from the master to other slaves
eventually so a write from one slave is not immediately visible on all other
slaves. This is the only difference between multiple machines running in HA
mode compared to single machine operation. All other ACID characteristics are
the same.

23.2. Setup and configuration

Neo4j HA can be set up to accommodate differing requirements for load, fault
tolerance and available hardware.

Within a cluster, Neo4j HA uses Apache ZooKeeper ^[2] for master election and
propagation of general cluster and machine status information. ZooKeeper can be
seen as a distributed coordination service. Neo4j HA requires a coordinator
service for initial master election, new master election (current master
failing) and to publish general status information about the current Neo4j HA
cluster (for example when a server joined or left the cluster). Read operations
through the GraphDatabaseService API will always work and even writes can
survive coordinator failures if a master is present.

ZooKeeper requires a majority of the ZooKeeper instances to be available to
operate properly. This means that the number of ZooKeeper instances should
always be an odd number since that will make best use of available hardware.

To further clarify the fault tolerance characteristics of Neo4j HA here are a
few example setups:

23.2.1. Small

  * 3 physical (or virtual) machines
  * 1 Coordinator running on each machine
  * 1 Neo4j HA instance running on each machine

This setup is conservative in the use of hardware while being able to handle
moderate read load. It can fully operate when at least 2 of the coordinator
instances are running. Since the coordinator and Neo4j HA are running together
on each machine this will in most scenarios mean that only one server is
allowed to go down.

23.2.2. Medium

  * 5-7+ machines
  * Coordinator running on 3, 5 or 7 machines
  * Neo4j HA can run on 5+ machines

This setup may mean that two different machine setups have to be managed (some
machines run both coordinator and Neo4j HA). The fault tolerance will depend on
how many machines there are that are running coordinators. With 3 coordinators
the cluster can survive one coordinator going down, with 5 it can survive 2 and
with 7 it can handle 3 coordinators failing. The number of Neo4j HA instances
that can fail for normal operations is theoretically all but 1 (but for each
required master election the coordinator must be available).

23.2.3. Large

  * 8+ total machines
  * 3+ Neo4j HA machines
  * 5+ Coordinators, on separate dedicated machines

In this setup all coordinators are running on separate machines as a dedicated
service. The dedicated coordinator cluster can handle half of the instances,
minus 1, going down. The Neo4j HA cluster will be able to operate with at least
a single live machine. Adding more Neo4j HA instances is very easy in this
setup since the coordinator cluster is operating as a separate service.

23.2.4. Installation Notes

For installation instructions of a High Availability cluster see Section 23.4,
“High Availability setup tutorial”.

Note that while the HighlyAvailableGraphDatabase supports the same API as the
EmbeddedGraphDatabase, it does have additional configuration parameters.

Table 23.1. HighlyAvailableGraphDatabase configuration parameters

+-----------------------------------------------------------------------------------------------------------------------------------------------+
|Parameter Name                      |Value                                  |Example value                               |Required?            |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.server_id                        |integer >= 0                           |1                                           |yes                  |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.server                           |(auto-discovered) host & port to bind  |my-domain.com:6001                          |no                   |
|                                    |when acting as master                  |                                            |                     |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.coordinators                     |comma delimited coordinator connections|localhost:2181,localhost:2182,localhost:2183|yes                  |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.cluster_name                     |name of the cluster to participate in  |neo4j.ha                                    |no                   |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.pull_interval                    |interval for polling master from a     |30                                          |no                   |
|                                    |slave, in seconds                      |                                            |                     |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.slave_coordinator_update_mode    |creates a slave-only instance that will|none                                        |no                   |
|                                    |never become a master                  |                                            |                     |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.read_timeout                     |how long a slave will wait for response|20                                          |no                   |
|                                    |from master before giving up (default  |                                            |                     |
|                                    |20)                                    |                                            |                     |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.lock_read_timeout                |how long a slave lock acquisition      |40                                          |no                   |
|                                    |request will wait for response from    |                                            |                     |
|                                    |master before giving up (defaults to   |                                            |                     |
|                                    |what ha.read_timeout is, or its default|                                            |                     |
|                                    |if absent)                             |                                            |                     |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.max_concurrent_channels_per_slave|max number of concurrent communication |100                                         |no                   |
|                                    |channels each slave has to its master. |                                            |                     |
|                                    |Increase if there’s high contention on |                                            |                     |
|                                    |few nodes                              |                                            |                     |
|------------------------------------+---------------------------------------+--------------------------------------------+---------------------|
|ha.branched_data_policy             |what to do with the db that is         |no                                          |ha.zk_session_timeout|
|                                    |considered branched and will be        |                                            |                     |
|                                    |replaced with a fresh copy from the    |                                            |                     |
|                                    |master {keep_all                       |                                            |                     |
|                                    |(default),keep_none,keep_none,shutdown}|                                            |                     |
+-----------------------------------------------------------------------------------------------------------------------------------------------+


Caution

Neo4j’s HA setup depends on ZooKeeper a.k.a. Coordinator which makes certain
assumptions about the state of the underlying operating system. In particular
ZooKeeper expects that the system time on each machine is set correctly,
synchronized with respect to each other. If this is not true, then Neo4j HA
will appear to misbehave, caused by seemingly random ZooKeeper hiccups.

Caution

Neo4j uses the Coordinator cluster to store information representative of the
deployment’s state, including key fields of the database itself. Since that
information is permanently stored in the cluster, you cannot reuse it for
multiple deployments of different databases. In particular, removing the Neo4j
servers, replacing the database and restarting them using the same coordinator
instances will result in errors mentioning the existing HA deployment. To reset
the Coordinator cluster to a clean state, you have to shutdown all instances,
remove the data/coordinator/version-2/* data files and restart the
Coordinators.

23.3. How Neo4j HA operates

A Neo4j HA cluster operates cooperatively, coordinating activity through
Zookeeper.

On startup a Neo4j HA instance will connect to the coordinator service
(ZooKeeper) to register itself and ask, "who is master?" If some other machine
is master, the new instance will start as slave and connect to that master. If
the machine starting up was the first to register — or should become master
according to the master election algorithm — it will start as master.

When performing a write transaction on a slave each write operation will be
synchronized with the master (locks will be acquired on both master and slave).
When the transaction commits it will first occur on the master. If the master
commit is successful the transaction will be committed on the slave as well. To
ensure consistency, a slave has to be up to date with the master before
performing a write operation. This is built into the communication protocol
between the slave and master, so that updates will happen automatically if
needed.

You can make a database instance permanently slave-only by including the
ha.slave_coordinator_update_mode=none configuration parameter in its
configuration. Such instances will never become a master during fail-over
elections though otherwise they behave identically to any other slaves,
including the ability to write-through permanent slaves to the master.

When performing a write on the master it will execute in the same way as
running in normal embedded mode. Currently the master will not push updates to
the slave. Instead, slaves can be configured to have a pull interval. Without
polling, updates will only happen on slaves whenever they synchronize a write
with the master.

Having all writes go through slaves has the benefit that the data will be
replicated on two machines. This is recommended to avoid rollbacks in case of a
master failure that could potentially happen when the new master is elected.

Whenever a server running a neo4j database becomes unavailable the coordinator
service will detect that and remove it from the cluster. If the master goes
down a new master will automatically be elected. Normally a new master is
elected and started within just a few seconds and during this time no writes
can take place (the write will throw an exception). A machine that becomes
available after being unavailable will automatically reconnect to the cluster.
The only time this is not true is when an old master had changes that did not
get replicated to any other machine. If the new master is elected and performs
changes before the old master recovers, there will be two different versions of
the data. The old master will move away the branched database and download a
full copy from the new master.

All this can be summarized as:

  * Slaves can handle write transactions.
  * Updates to slaves are eventual consistent.
  * Neo4j HA is fault tolerant and (depending on ZooKeeper setup) can continue
    to operate from X machines down to a single machine.
  * Slaves will be automatically synchronized with the master on a write
    operation.
  * If the master fails a new master will be elected automatically.
  * Machines will be reconnected automatically to the cluster whenever the
    issue that caused the outage (network, maintenance) is resolved.
  * Transactions are atomic, consistent and durable but eventually propagated
    out to other slaves.
  * If the master goes down any running write transaction will be rolled back
    and during master election no write can take place.
  * Reads are highly available.

23.4. High Availability setup tutorial

This is a guide to set up a Neo4j HA cluster and run embedded Neo4j or Neo4j
Server instances participating as cluster nodes.

23.4.1. Background

The members of the HA cluster (see Chapter 23, High Availability) use a
Coordinator cluster to manage themselves and coordinate lifecycle activity like
electing a master. When running an Neo4j HA cluster, a Coordinator cluster is
used for cluster collaboration and must be installed and configured before
working with the Neo4j database HA instances.

Tip

Neo4j Server (see Chapter 18, Neo4j Server) and Neo4j Embedded (see
Section 22.1, “Introduction”) can both be used as nodes in the same HA cluster.
This opens for scenarios where one application can insert and update data via a
Java or JVM language based application, and other instances can run Neo4j
Server and expose the data via the REST API (Chapter 19, REST API).

Below, there will be 3 coordinator instances set up on one local machine.

23.4.1.1. Download and unpack Neoj4 Enterprise

Download and unpack three installations of Neo4j Enterprise (called
$NEO4J_HOME1, $NEO4J_HOME2, $NEO4J_HOME3) from the Neo4j download site <http://
neo4j.org/download>.

23.4.2. Setup and start the Coordinator cluster

Now, in the NEO4J_HOME1/conf/coord.cfg file, adjust the coordinator clientPort
and let the coordinator search for other coordinator cluster members at the
localhost port ranges:

#$NEO4J_HOME1/conf/coord.cfg

server.1=localhost:2888:3888
server.2=localhost:2889:3889
server.3=localhost:2890:3890

clientPort=2181

The other two config files in $NEO4J_HOME2 and $NEO4J_HOME3 will have a
different clienttPort set but the other parameters identical to the first one:

#$NEO4J_HOME2/conf/coord.cfg
...
server.1=localhost:2888:3888
server.2=localhost:2889:3889
server.3=localhost:2890:3890
...
clientPort=2182

#$NEO4J_HOME2/conf/coord.cfg
...
server.1=localhost:2888:3888
server.2=localhost:2889:3889
server.3=localhost:2890:3890
...
clientPort=2183

Next we need to create a file in each data directory called "myid" that
contains an id for each server equal to the number in server.1, server.2 and
server.3 from the configuration files.

neo4j_home1$ echo '1' > data/coordinator/myid
neo4j_home2$ echo '2' > data/coordinator/myid
neo4j_home3$ echo '3' > data/coordinator/myid

We are now ready to start the Coordinator instances:

neo4j_home1$ ./bin/neo4j-coordinator start
neo4j_home2$ ./bin/neo4j-coordinator start
neo4j_home3$ ./bin/neo4j-coordinator start

23.4.3. Start the Neo4j Servers in HA mode

In your conf/neo4j.properties file, enable HA by setting the necessary
parameters for all 3 installations, adjusting the ha.server_id for all
instances:

#$NEO4J_HOME1/conf/neo4j.properties
#unique server id for this graph database
#can not be negative id and must be unique
ha.server_id = 1

#ip and port for this instance to bind to
ha.server = localhost:6001

#connection information to the coordinator cluster client ports
ha.coordinators = localhost:2181,localhost:2182,localhost:2183

#$NEO4J_HOME2/conf/neo4j.properties
#unique server id for this graph database
#can not be negative id and must be unique
ha.server_id = 2

#ip and port for this instance to bind to
ha.server = localhost:6002

#connection information to the coordinator cluster client ports
ha.coordinators = localhost:2181,localhost:2182,localhost:2183

#$NEO4J_HOME3/conf/neo4j.properties
#unique server id for this graph database
#can not be negative id and must be unique
ha.server_id = 3

#ip and port for this instance to bind to
ha.server = localhost:6003

#connection information to the coordinator cluster client ports
ha.coordinators = localhost:2181,localhost:2182,localhost:2183

To avoid port clashes when starting the servers, adjust the ports for the REST
endpoints in all instances under conf/neo4j-server.properties and enable HA
mode:

#$NEO4J_HOME1/conf/neo4j-server.properties
...
# http port (for all data, administrative, and UI access)
org.neo4j.server.webserver.port=7474
...
# Allowed values:
# HA - High Availability
# SINGLE - Single mode, default.
# To run in High Availability mode, configure the coord.cfg file, and the
# neo4j.properties config file, then uncomment this line:
org.neo4j.server.database.mode=HA

#$NEO4J_HOME2/conf/neo4j-server.properties
...
# http port (for all data, administrative, and UI access)
org.neo4j.server.webserver.port=7475
...
# Allowed values:
# HA - High Availability
# SINGLE - Single mode, default.
# To run in High Availability mode, configure the coord.cfg file, and the
# neo4j.properties config file, then uncomment this line:
org.neo4j.server.database.mode=HA

#$NEO4J_HOME3/conf/neo4j-server.properties
...
# http port (for all data, administrative, and UI access)
org.neo4j.server.webserver.port=7476
...
# Allowed values:
# HA - High Availability
# SINGLE - Single mode, default.
# To run in High Availability mode, configure the coord.cfg file, and the
# neo4j.properties config file, then uncomment this line:
org.neo4j.server.database.mode=HA

To avoid JMX port clashes adjust the assigned ports for all instances under 
conf/neo4j-wrapper.properties:

#$NEO4J_HOME1/conf/neo4j-wrapper.properties
...
# Remote JMX monitoring, adjust the following lines if needed.
# Also make sure to update the jmx.access and jmx.password files with appropriate permission roles and passwords,
# the shipped configuration contains only a read only role called 'monitor' with password 'Neo4j'.
# For more details, see: http://download.oracle.com/javase/6/docs/technotes/guides/management/agent.html
wrapper.java.additional.4=-Dcom.sun.management.jmxremote.port=3637
...

#$NEO4J_HOME2/conf/neo4j-wrapper.properties
...
# Remote JMX monitoring, adjust the following lines if needed.
# Also make sure to update the jmx.access and jmx.password files with appropriate permission roles and passwords,
# the shipped configuration contains only a read only role called 'monitor' with password 'Neo4j'.
# For more details, see: http://download.oracle.com/javase/6/docs/technotes/guides/management/agent.html
wrapper.java.additional.4=-Dcom.sun.management.jmxremote.port=3638
...

#$NEO4J_HOME3/conf/neo4j-server.properties
...
# Remote JMX monitoring, adjust the following lines if needed.
# Also make sure to update the jmx.access and jmx.password files with appropriate permission roles and passwords,
# the shipped configuration contains only a read only role called 'monitor' with password 'Neo4j'.
# For more details, see: http://download.oracle.com/javase/6/docs/technotes/guides/management/agent.html
wrapper.java.additional.4=-Dcom.sun.management.jmxremote.port=3639
...

Now, start all three server instances.

neo4j_home1$ ./bin/neo4j start
neo4j_home2$ ./bin/neo4j start
neo4j_home3$ ./bin/neo4j start

Now, you should be able to access the 3 servers (the first one being elected as
master since it was started first) at http://localhost:7474/webadmin/#/info/
org.neo4j/High%20Availability/ <http://localhost:7474/webadmin/#/info/org.neo4j
/High%20Availability/>, http://localhost:7475/webadmin/#/info/org.neo4j/
High%20Availability/ <http://localhost:7475/webadmin/#/info/org.neo4j/
High%20Availability/> and http://localhost:7476/webadmin/#/info/org.neo4j/
High%20Availability/ <http://localhost:7476/webadmin/#/info/org.neo4j/
High%20Availability/> and check the status of the HA configuration.
Alternatively, the REST API is exposing JMX, so you can check the HA JMX bean
with e.g.

curl -H "Content-Type:application/json" -d '["org.neo4j:*"]' http://localhost:7474/db/manage/server/jmx/query

And find in the response

"description" : "Information about all instances in this cluster",
    "name" : "InstancesInCluster",
    "value" : [ {
      "description" : "org.neo4j.management.InstanceInfo",
      "value" : [ {
        "description" : "address",
        "name" : "address"
      }, {
        "description" : "instanceId",
        "name" : "instanceId"
      }, {
        "description" : "lastCommittedTransactionId",
        "name" : "lastCommittedTransactionId",
        "value" : 1
      }, {
        "description" : "machineId",
        "name" : "machineId",
        "value" : 1
      }, {
        "description" : "master",
        "name" : "master",
        "value" : true
      } ],
      "type" : "org.neo4j.management.InstanceInfo"
    }

23.4.4. Start Neo4j Embedded in HA mode

If you are using Maven and Neo4j Embedded, simply add the following dependency
to your project:

<dependency>
   <groupId>org.neo4j</groupId>
   <artifactId>neo4j-ha</artifactId>
   <version>${neo4j-version}</version>
</dependency>

Where ${neo4j-version} is the Neo4j version used.

If you prefer to download the jar files manually, they are included in the
Neo4j distribution <http://neo4j.org/download/>.

The difference in code when using Neo4j-HA is the creation of the graph
database service.

GraphDatabaseService db = new HighlyAvailableGraphDatabase( path, config );

The configuration can contain the standard configuration parameters (provided
as part of the config above or in neo4j.properties but will also have to
contain:

#HA instance1
#unique machine id for this graph database
#can not be negative id and must be unique
ha.server_id = 1

#ip and port for this instance to bind to
ha.server = localhost:6001

#connection information to the coordinator cluster client ports
ha.coordinators = localhost:2181,localhost:2182,localhost:2183

enable_remote_shell = port=1331

First we need to create a database that can be used for replication. This is
easiest done by just starting a normal embedded graph database, pointing out a
path and shutdown.

Map<String,String> config = HighlyAvailableGraphDatabase.loadConfigurations( configFile );
GraphDatabaseService db = new HighlyAvailableGraphDatabase( path, config );

We created a config file with machine id=1 and enabled remote shell. The main
method will expect the path to the db as first parameter and the configuration
file as the second parameter.

It should now be possible to connect to the instance using Chapter 28, Neo4j
Shell:

neo4j_home1$ ./bin/neo4j-shell -port 1331
NOTE: Remote Neo4j graph database service 'shell' at port 1331
Welcome to the Neo4j Shell! Enter 'help' for a list of commands

neo4j-sh (0)$ hainfo
I'm currently master
Connected slaves:

Since it is the first instance to join the cluster it is elected master.
Starting another instance would require a second configuration and another path
to the db.

#HA instance2
#unique machine id for this graph database
#can not be negative id and must be unique
ha.server_id = 2

#ip and port for this instance to bind to
ha.server = localhost:6001

#connection information to the coordinator cluster client ports
ha.coordinators = localhost:2181,localhost:2182,localhost:2183

enable_remote_shell = port=1332

Now start the shell connecting to port 1332:

neo4j_home1$ ./bin/neo4j-shell -port 1332
NOTE: Remote Neo4j graph database service 'shell' at port 1332
Welcome to the Neo4j Shell! Enter 'help' for a list of commands

neo4j-sh (0)$ hainfo
I'm currently slave

23.5. Setting up HAProxy as a load balancer

In the Neo4j HA architecture, the cluster is typically fronted by a load
balancer. In this section we will explore how to set up HAProxy to perform load
balancing across the HA cluster.

23.5.1. Installing HAProxy

For this tutorial we will assume a Linux environment. We will also be
installing HAProxy from source, and we’ll be using version 1.4.18. You need to
ensure that your Linux server has a development environment set up. On Ubuntu/
apt systems, simply do:

aptitude install build-essential

And on CentOS/yum systems do:

yum -y groupinstall 'Development Tools'

Then download the tarball from the HAProxy website <http://haproxy.1wt.eu/>.
Once you’ve downloaded it, simply build and install HAProxy:

tar -zvxf haproxy-1.4.18.tar.gz
cd haproxy-1.4.18
make
cp haproxy /usr/sbin/haproxy

Or specify a target for make (TARGET=linux26 for linux kernel 2.6 or above or
linux24 for 2.4 kernel)

tar -zvxf haproxy-1.4.18.tar.gz
cd haproxy-1.4.18
make TARGET=linux26
cp haproxy /usr/sbin/haproxy

23.5.2. Configuring HAProxy

HAProxy can be configured in many ways. The full documentation is available at
their website.

For this example, we will configure HAProxy to load balance requests to three
HA servers. Simply write the follow configuration to /etc/haproxy.cfg:

global
    daemon
    maxconn 256

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

frontend http-in
    bind *:80
    default_backend neo4j

backend neo4j
    server s1 10.0.1.10:7474 maxconn 32
    server s2 10.0.1.11:7474 maxconn 32
    server s3 10.0.1.12:7474 maxconn 32

listen admin
    bind *:8080
    stats enable

HAProxy can now be started by running:

/usr/sbin/haproxy -f /etc/haproxy.cfg

You can connect to http://<ha-proxy-ip>:8080/haproxy?stats <http://
<ha-proxy-ip>:8080/haproxy?stats> to view the status dashboard. This dashboard
can be moved to run on port 80, and authentication can also be added. See the
HAProxy documentation for details on this.

23.5.3. Configuring separate sets for master and slaves

It is possible to set HAProxy backends up to only include slaves or the master.
For example, it may be desired to only write to slaves. To accomplish this, you
need to have a small extension on the server than can report whether or not the
machine is master via HTTP response codes. In this example, the extension
exposes two URLs:

  * /hastatus/master, which returns 200 if the machine is the master, and 404
    if the machine is a slave
  * /hastatus/slave, which returns 200 if the machine is a slave, and 404 if
    the machine is the master

The following example excludes the master from the set of machines. Request
will only be sent to the slaves.

global
    daemon
    maxconn 256

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

frontend http-in
    bind *:80
    default_backend neo4j-slaves

backend neo4j-slaves
    option httpchk GET /hastatus/slave
    server s1 10.0.1.10:7474 maxconn 32 check
    server s2 10.0.1.11:7474 maxconn 32 check
    server s3 10.0.1.12:7474 maxconn 32 check

listen admin
    bind *:8080
    stats enable

23.5.4. Cache-based sharding with HAProxy

Neo4j HA enables what is called cache-based sharding. If the dataset is too big
to fit into the cache of any single machine, then by applying a consistent
routing algorithm to requests, the caches on each machine will actually cache
different parts of the graph. A typical routing key could be user ID.

In this example, the user ID is a query parameter in the URL being requested.
This will route the same user to the same machine for each request.

global
    daemon
    maxconn 256

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

frontend http-in
    bind *:80
    default_backend neo4j-slaves

backend neo4j-slaves
    balance url_param user_id
    server s1 10.0.1.10:7474 maxconn 32
    server s2 10.0.1.11:7474 maxconn 32
    server s3 10.0.1.12:7474 maxconn 32

listen admin
    bind *:8080
    stats enable

Naturally the health check and query parameter-based routing can be combined to
only route requests to slaves by user ID. Other load balancing algorithms are
also available, such as routing by source IP (source), the URI (uri) or HTTP
headers(hdr()).


--------------

^[2] http://hadoop.apache.org/zookeeper/ <http://hadoop.apache.org/zookeeper/>

Chapter 24. Backup

Note

The Backup features are only available in the Neo4j Enterprise Edition.

Backups are performed over the network live from a running graph database onto
a local copy. There are two types of backup: full and incremental.

A full backup copies the database files without acquiring any locks, allowing
for continued operations on the target instance. This of course means that
while copying, transactions will continue and the store will change. For this
reason, the transaction that was running when the backup operation started is
noted and, when the copy operation completes, all transactions from the latter
down to the one happening at the end of the copy are replayed on the backup
files. This ensures that the backed up data represent a consistent and
up-to-date snapshot of the database storage.

In contrast, an incremental backup does not copy store files — instead it
copies the logs of the transactions that have taken place since the last full
or incremental backup which are then replayed over an existing backup store.
This makes incremental backups far more efficient than doing full backups every
time but they also require that a full backup has taken place before they are
executed.

Regardless of the mode a backup is created with, the resulting files represent
a consistent database snapshot and they can be used to boot up a Neo4j
instance.

The database to be backed up is specified using a URI with syntax

<running mode>://<host>[:port]{,<host>[:port]*}

Running mode must be defined and is either single for non-HA or ha for HA
clusters. The <host>[:port] part points to a host running the database, on port
port if not the default. The additional host:port arguments are useful for
passing multiple coordinator instances.

Important

Backups can only be performed on databases which have the configuration
parameter enable_online_backup=true set. That will make the backup service
available on the default port (6362). To enable the backup service on a
different port use for example enable_online_backup=port=9999 instead.

24.1. Embedded and Server

To perform a backup from a running embedded or server database run:

# Performing a full backup
./neo4j-backup -full -from single://192.168.1.34 -to /mnt/backup/neo4j-backup

# Performing an incremental backup
./neo4j-backup -incremental -from single://192.168.1.34 -to /mnt/backup/neo4j-backup

# Performing an incremental backup where the service is registered on a custom port
./neo4j-backup -incremental -from single://192.168.1.34:9999 -to /mnt/backup/neo4j-backup

24.2. Online Backup from Java

In order to programmatically backup your data full or subsequently incremental
from a JVM based program, you need to write Java code like

OnlineBackup backup = OnlineBackup.from( "localhost" );
backup.full( backupPath );
backup.incremental( backupPath );

For more information, please see the Javadocs for OnlineBackup <http://
components.neo4j.org/neo4j-enterprise/1.8.M04/apidocs/org/neo4j/backup/
OnlineBackup.html>

24.3. High Availability

To perform a backup on an HA cluster you specify one or more coordinators
managing that cluster.

Note

If you have specified a cluster name for your HA cluster, you need to specify
it when doing backups, so that the backup system knows which cluster to back
up. Add the config parameter: -cluster my_custom_cluster_name

# Performing a full backup from HA cluster, specifying two possible coordinators
./neo4j-backup -full -from ha://192.168.1.15:2181,192.168.1.16:2181 -to /mnt/backup/neo4j-backup

# Performing an incremental backup from HA cluster, specifying only one coordinator
./neo4j-backup -incremental -from ha://192.168.1.15:2181 -to /mnt/backup/neo4j-backup

# Performing an incremental backup from HA cluster with a specific name (specified by neo4j configuration 'ha.cluster_name')
./neo4j-backup -incremental -from ha://192.168.1.15:2181 -to /mnt/backup/neo4j-backup -cluster my-cluster

24.4. Restoring Your Data

The Neo4j backups are fully functional databases. To use a backup, all you need
to do replace your database folder with the backup.

Chapter 25. Security

Neo4j in itself does not enforce security on the data level. However, there are
different aspects that should be considered when using Neo4j in different
scenarios.

25.1. Securing access to the Neo4j Server

25.1.1. Secure the port and remote client connection accepts

By default, the Neo4j Server is bundled with a Web server that binds to host
localhost on port 7474, answering only requests from the local machine.

This is configured in the conf/neo4j-server.properties file:

# http port (for all data, administrative, and UI access)
org.neo4j.server.webserver.port=7474

#let the webserver only listen on the specified IP. Default
#is localhost (only accept local connections). Uncomment to allow
#any connection.
#org.neo4j.server.webserver.address=0.0.0.0

If you need to enable access from external hosts, configure the Web server in
the conf/neo4j-server.properties by setting the property
org.neo4j.server.webserver.address=0.0.0.0 to enable access from any host.

25.1.2. Arbitrary code execution

By default, the Neo4j Server comes with some places where arbitrary code code
execution can happen. These are the Section 19.17, “Gremlin Plugin” and the
Section 19.11, “Traversals” REST endpoints. To secure these, either disable
them completely by removing the offending plugins from the server classpath, or
secure access to these URLs through proxies or Authorization Rules. Also, the
Java Security Manager <http://docs.oracle.com/javase/1.4.2/docs/api/java/lang/
SecurityManager.html> can be used to secure parts of the codebase.

25.1.3. HTTPS support

The Neo4j server includes built in support for SSL encrypted communication over
HTTPS. The first time the server starts, it automatically generates a
self-signed ssl certificate and a private key. Because the certificate is self
signed, it is not safe to rely on for production use, instead, you should
provide your own key and certificate for the server to use.

To provide your own key and certificate, replace the generated key and
certificate, or change the neo4j-server.properties file to set the location of
your certififacate and key:

# Certificate location (auto generated if the file does not exist)
org.neo4j.server.webserver.https.cert.location=ssl/snakeoil.cert

# Private key location (auto generated if the file does not exist)
org.neo4j.server.webserver.https.key.location=ssl/snakeoil.key

Note that the key should be unencrypted. Make sure you set correct permissions
to the private key, so that only the neo4j server user can read/write it.

You can set what port the https connector should bind to in the same
configuration file, as well as turn https off:

# Turn https-support on/off
org.neo4j.server.webserver.https.enabled=true

# https port (for all data, administrative, and UI access)
org.neo4j.server.webserver.https.port=443

25.1.4. Server Authorization Rules

Administrators may require more fine-grained security policies in addition to
IP-level restrictions on the Web server. Neo4j server supports administrators
in allowing or disallowing access the specific aspects of the database based on
credentials that users or applications provide.

To facilitate domain-specific authorization policies in Neo4j Server,
SecurityRules can be implemented and registered with the server. This makes
scenarios like user and role based security and authentication against external
lookup services possible.

25.1.4.1. Enforcing Server Authorization Rules

In this example, a (dummy) failing security rule is registered to deny access
to all URIs to the server by listing the rules class in neo4j-server.properties
:

org.neo4j.server.rest.security_rules=my.rules.PermanentlyFailingSecurityRule

with the rule source code of:

public class PermanentlyFailingSecurityRule implements SecurityRule
{

    public static final String REALM = "WallyWorld"; // as per RFC2617 :-)

    @Override
    public boolean isAuthorized( HttpServletRequest request )
    {
        return false; // always fails - a production implementation performs
                      // deployment-specific authorization logic here
    }

    @Override
    public String forUriPath()
    {
        return SecurityRule.DEFAULT_DATABASE_PATH;
    }

    @Override
    public String wwwAuthenticateHeader()
    {
        return SecurityFilter.basicAuthenticationResponse(REALM);
    }
}

With this rule registered, any access to the server will be denied. In a
production-quality implementation the rule will likely lookup credentials/
claims in a 3rd party directory service (e.g. LDAP) or in a local database of
authorized users.

Example request

  * POST http://localhost:7474/db/data/node
  * Accept: application/json

Example response

  * 401: Unauthorized
  * WWW-Authenticate: Basic realm="WallyWorld"

25.1.4.2. Using Wildcards to Target Security Rules

In this example, a (dummy) failing security rule is registered to deny access
to all URIs to the server by listing the rule(s) class(es) in
neo4j-server.properties In this case, the rule is registered using a wildcard
URI path (where * characters can be used to signify any part of the path). For
example /users* means the rule will be bound to any resources under the /users
root path. Similarly /users*type* will bind the rule to resources matching the
URIs like /users/fred/type/premium

org.neo4j.server.rest.security_rules=my.rules.PermanentlyFailingSecurityRuleWithWildcardPath

with the rule source code of:

public String forUriPath()
{
    return "/protected/*";
}

With this rule registered, any access to the server will be denied. Using
wildcards allows flexible targeting of security rules to arbitrary parts of the
server’s API, including any unmanaged extensions or managed plugins that have
been registered.

Example request

  * GET http://localhost:7474/protected/wildcard_replacement/x/y/z/something/
    else/more_wildcard_replacement/a/b/c/final/bit/more/stuff
  * Accept: text/plain

Example response

  * 401: Unauthorized
  * WWW-Authenticate: Basic realm="WallyWorld"

25.1.5. Hosted Scripting

Important

The neo4j server exposes remote scripting functionality by default that allow
full access to the underlying system. Exposing your server without implementing
a security layer poses a substantial security vulnerability.

25.1.6. Security in Depth

Although the Neo4j server has a number of security features built-in (see the
above chapters), for sensitive deployments it is often sensible to front
against the outside world it with a proxy like Apache mod_proxy ^[3].

This provides a number of advantages:

  * Control access to the Neo4j server to specific IP addresses, URL patterns
    and IP ranges. This can be used to make for instance only the /db/data
    namespace accessible to non-local clients, while the /db/admin URLs only
    respond to a specific IP address.

    <Proxy *>
      Order Deny,Allow
      Deny from all
      Allow from 192.168.0
    </Proxy>

While equivalent functionality can be implemented with Neo4j’s SecurityRule
plugins (see above), for operations professionals configuring servers like
Apache is often preferable to developing plugins. However it should be noted
that where both approaches are used, they will work harmoniously providing the
behavior is consistent across proxy server and SecurityRule plugins.

  * Run Neo4j Server as a non-root user on a Linux/Unix system on a port < 1000
    (e.g. port 80) using

    ProxyPass /neo4jdb/data http://localhost:7474/db/data
    ProxyPassReverse /neo4jdb/data http://localhost:7474/db/data

  * Simple load balancing in a clustered environment to load-balance read load
    using the Apache mod_proxy_balancer ^[4] plugin

    <Proxy balancer://mycluster>
    BalancerMember http://192.168.1.50:80
    BalancerMember http://192.168.1.51:80
    </Proxy>
    ProxyPass /test balancer://mycluster

25.1.7. Rewriting URLs with a Proxy installation

When installing Neo4j Server behind proxies, you need to enable rewriting of
the JSON calls, otherwise they will point back to the servers own base URL
(normally http://localhost:7474 <http://localhost:7474>).

To do this, you can use Apache mod_substitute <http://httpd.apache.org/docs/2.2
/mod/mod_substitute.html>

ProxyPass / http://localhost:7474/
ProxyPassReverse / http://localhost:7474/
<Location />
    AddOutputFilterByType SUBSTITUTE application/json
    AddOutputFilterByType SUBSTITUTE text/html
    Substitute s/localhost:7474/myproxy.example.com/n
    Substitute s/http/https/n
</Location>


--------------

^[3] http://httpd.apache.org/docs/2.2/mod/mod_proxy.html <http://
httpd.apache.org/docs/2.2/mod/mod_proxy.html>

^[4] http://httpd.apache.org/docs/2.2/mod/mod_proxy_balancer.html <http://
httpd.apache.org/docs/2.2/mod/mod_proxy_balancer.html>

Chapter 26. Monitoring

Note

Most of the monitoring features are only available in the Advanced and
Enterprise editions of Neo4j.

In order to be able to continuously get an overview of the health of a Neo4j
database, there are different levels of monitoring facilities available. Most
of these are exposed through the JMX API <http://www.oracle.com/technetwork/
java/javase/tech/javamanagement-140525.html>.

26.1. JMX

26.1.1. Adjusting remote JMX access to the Neo4j Server

Per default, the Neo4j Advanced Server and Neo4j Enterprise Server editions do
not allow remote JMX connections, since the relevant options in the conf/
neo4j-wrapper.conf configuration file are commented out. To enable this
feature, you have to remove the # characters from the various
com.sun.management.jmxremote options there.

When commented in, the default values are set up to allow remote JMX
connections with certain roles, refer to the conf/jmx.password, conf/jmx.access
and conf/wrapper.conf files for details.

Make sure that conf/jmx.password has the correct file permissions. The owner of
the file has to be the user that will run the service, and the permissions
should be read only for that user. On Unix systems, this is 0600.

On Windows, follow the tutorial at http://docs.oracle.com/javase/6/docs/
technotes/guides/management/security-windows.html <http://docs.oracle.com/
javase/6/docs/technotes/guides/management/security-windows.html> to set the
correct permissions. If you are running the service under the Local System
Account, the user that owns the file and has access to it should be SYSTEM.

With this setup, you should be able to connect to JMX monitoring of the Neo4j
server using <IP-OF-SERVER>:3637, with the username monitor and the password
Neo4j.

Note that it is possible that you have to update the permissions and/or
ownership of the conf/jmx.password and conf/jmx.access files — refer to the
relevant section in conf/wrapper.conf for details.

Warning

For maximum security, please adjust at least the password settings in conf/
jmx.password for a production installation.

For more details, see: http://download.oracle.com/javase/6/docs/technotes/
guides/management/agent.html <http://download.oracle.com/javase/6/docs/
technotes/guides/management/agent.html>

26.1.2. How to connect to a Neo4j instance using JMX and JConsole

First, start your embedded database or the Neo4j Server, for instance using

$NEO4j_HOME/bin/neo4j start

Now, start JConsole with

$JAVA_HOME/bin/jconsole

Connect to the process running your Neo4j database instance:

Figure 26.1. Connecting JConsole to the Neo4j Java process

Connecting with JConsole


Now, beside the MBeans exposed by the JVM, you will see an org.neo4j section in
the MBeans tab. Under that, you will have access to all the monitoring
information exposed by Neo4j.

For opening JMX to remote monitoring access, please see Section 26.1.1,
“Adjusting remote JMX access to the Neo4j Server” and the JMX documention
<http://docs.oracle.com/javase/6/docs/technotes/guides/management/agent.html#
gdenl>. When using Neo4j in embedded mode, make sure to pass the
com.sun.management.jmxremote.port=portNum or other configuration as JVM
parameters to your running Java process.

Figure 26.2. Neo4j MBeans View

Neo4j MBeans view


26.1.3. How to connect to the JMX monitoring programmatically

In order to programmatically connect to the Neo4j JMX server, there are some
convenience methods in the Neo4j Management component to help you find out the
most commonly used monitoring attributes of Neo4j. See Section 4.8, “Reading a
management attribute” for an example.

Once you have access to this information, you can use it to for instance expose
the values to SNMP <http://en.wikipedia.org/wiki/
Simple_Network_Management_Protocol> or other monitoring systems.

26.1.4. Reference of supported JMX MBeans

MBeans exposed by Neo4j

  * Branched Store: Information about the branched stores present in this HA
    cluster member
  * Cache/NodeCache: Information about the caching in Neo4j
  * Cache/RelationshipCache: Information about the caching in Neo4j
  * Configuration: The configuration parameters used to configure Neo4j
  * Diagnostics: Diagnostics provided by Neo4j
  * High Availability: Information about an instance participating in a HA
    cluster
  * Kernel: Information about the Neo4j kernel
  * Locking: Information about the Neo4j lock status
  * Memory Mapping: The status of Neo4j memory mapping
  * Primitive count: Estimates of the numbers of different kinds of Neo4j
    primitives
  * Store file sizes: Information about the sizes of the different parts of the
    Neo4j graph store
  * Transactions: Information about the Neo4j transaction manager
  * XA Resources: Information about the XA transaction manager

Note

For additional information on the primitive datatypes (int, long etc.) used in
the JMX attributes, please see Table 3.2, “Property value types”.

Table 26.1. MBean Branched Store (org.neo4j.management.BranchedStore)
Attributes

+-----------------------------------------------------------------------------+
|Name          |Description |Type                                  |Read|Write|
|-----------------------------------------------------------------------------|
|   Information about the branched stores present in this HA cluster member   |
|-----------------------------------------------------------------------------|
|BranchedStores|A list of   |org.neo4j.management.BranchedStoreInfo|yes |no   |
|              |the branched|[] as CompositeData[]                 |    |     |
|              |stores      |                                      |    |     |
+-----------------------------------------------------------------------------+


Table 26.2. MBean Cache/NodeCache (org.neo4j.management.Cache) Attributes

+-----------------------------------------------------------------------------+
|Name     |Description                                      |Type  |Read|Write|
|-----------------------------------------------------------------------------|
|                   Information about the caching in Neo4j                    |
|-----------------------------------------------------------------------------|
|CacheType|The type of cache used by Neo4j                  |String|yes |no   |
|---------+-------------------------------------------------+------+----+-----|
|MissCount|The number of times a cache query did not return |long  |yes |no   |
|         |a result                                         |      |    |     |
|---------+-------------------------------------------------+------+----+-----|
|CacheSize|The size of this cache (nr of entities or total  |long  |yes |no   |
|         |size in bytes)                                   |      |    |     |
|---------+-------------------------------------------------+------+----+-----|
|HitCount |The number of times a cache query returned a     |long  |yes |no   |
|         |result                                           |      |    |     |
+-----------------------------------------------------------------------------+


Table 26.3. MBean Cache/NodeCache (org.neo4j.management.Cache) Operations

+--------------------------------------------------------+
|Name |Description            |ReturnType|Signature      |
|-----+-----------------------+----------+---------------|
|clear|Clears the Neo4j caches|void      |(no parameters)|
+--------------------------------------------------------+


Table 26.4. MBean Cache/RelationshipCache (org.neo4j.management.Cache)
Attributes

+-----------------------------------------------------------------------------+
|Name     |Description                                      |Type  |Read|Write|
|-----------------------------------------------------------------------------|
|                   Information about the caching in Neo4j                    |
|-----------------------------------------------------------------------------|
|CacheType|The type of cache used by Neo4j                  |String|yes |no   |
|---------+-------------------------------------------------+------+----+-----|
|MissCount|The number of times a cache query did not return |long  |yes |no   |
|         |a result                                         |      |    |     |
|---------+-------------------------------------------------+------+----+-----|
|CacheSize|The size of this cache (nr of entities or total  |long  |yes |no   |
|         |size in bytes)                                   |      |    |     |
|---------+-------------------------------------------------+------+----+-----|
|HitCount |The number of times a cache query returned a     |long  |yes |no   |
|         |result                                           |      |    |     |
+-----------------------------------------------------------------------------+


Table 26.5. MBean Cache/RelationshipCache (org.neo4j.management.Cache)
Operations

+--------------------------------------------------------+
|Name |Description            |ReturnType|Signature      |
|-----+-----------------------+----------+---------------|
|clear|Clears the Neo4j caches|void      |(no parameters)|
+--------------------------------------------------------+


Table 26.6. MBean Configuration (org.neo4j.jmx.impl.ConfigurationBean)
Attributes

+------------------------------------------------------------------------------------------------------+
|Name                                              |Description                      |Type  |Read|Write|
|------------------------------------------------------------------------------------------------------|
|                         The configuration parameters used to configure Neo4j                         |
|------------------------------------------------------------------------------------------------------|
|ha.zk_session_timeout                             |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.allow_init_cluster                             |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|read_only                                         |Only allow read operations from  |String|yes |yes  |
|                                                  |this Neo4j instance. Valid       |      |    |     |
|                                                  |options:[true, false]            |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|logical_log                                       |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|node_auto_indexing                                |Controls the auto indexing       |String|yes |yes  |
|                                                  |feature for nodes. Setting to    |      |    |     |
|                                                  |false shuts it down              |      |    |     |
|                                                  |unconditionally, while true      |      |    |     |
|                                                  |enables it for every property,   |      |    |     |
|                                                  |subject to restrictions in the   |      |    |     |
|                                                  |configuration.. Valid options:   |      |    |     |
|                                                  |[true, false]                    |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|intercept_committing_transactions                 |Determines whether any           |String|yes |yes  |
|                                                  |TransactionInterceptors loaded   |      |    |     |
|                                                  |will intercept prepared          |      |    |     |
|                                                  |transactions before they reach   |      |    |     |
|                                                  |the logical log. Valid options:  |      |    |     |
|                                                  |[true, false]                    |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_shell_name                                 |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|cache_type                                        |The type of cache to use for     |String|yes |yes  |
|                                                  |nodes and relationships. Valid   |      |    |     |
|                                                  |options:[gcr, soft, weak, strong,|      |    |     |
|                                                  |none]                            |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|intercept_deserialized_transactions               |Determines whether any           |String|yes |yes  |
|                                                  |TransactionInterceptors loaded   |      |    |     |
|                                                  |will intercept externally        |      |    |     |
|                                                  |received transactions (e.g. in   |      |    |     |
|                                                  |HA) before they reach the logical|      |    |     |
|                                                  |log and are applied to the       |      |    |     |
|                                                  |store.. Valid options:[true,     |      |    |     |
|                                                  |false]                           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|lucene_searcher_cache_size                        |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.coordinators                                   |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|use_memory_mapped_buffers                         |Tell Neo4j to use memory mapped  |String|yes |yes  |
|                                                  |buffers for accessing the native |      |    |     |
|                                                  |storage layer. Valid options:    |      |    |     |
|                                                  |[true, false]                    |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|rebuild_idgenerators_fast                         |Use a quick approach for         |String|yes |yes  |
|                                                  |rebuilding the ID generators.    |      |    |     |
|                                                  |This give quicker recovery time, |      |    |     |
|                                                  |but will limit the ability to    |      |    |     |
|                                                  |reuse the space of deleted       |      |    |     |
|                                                  |entities.. Valid options:[true,  |      |    |     |
|                                                  |false]                           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.propertystore.db.index.keys.mapped_memory|The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the store for property   |      |    |     |
|                                                  |key strings                      |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.propertystore.db.strings.mapped_memory   |The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the string property store|      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.propertystore.db.arrays.mapped_memory    |The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the array property store |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|gcr_cache_min_log_interval                        |The minimal time that must pass  |String|yes |yes  |
|                                                  |in between logging statistics    |      |    |     |
|                                                  |from the cache (when using the   |      |    |     |
|                                                  |gcr cache)                       |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.slave_coordinator_update_mode                  |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|relationship_auto_indexing                        |Controls the auto indexing       |String|yes |yes  |
|                                                  |feature for relationships.       |      |    |     |
|                                                  |Setting to false shuts it down   |      |    |     |
|                                                  |unconditionally, while true      |      |    |     |
|                                                  |enables it for every property,   |      |    |     |
|                                                  |subject to restrictions in the   |      |    |     |
|                                                  |configuration.. Valid options:   |      |    |     |
|                                                  |[true, false]                    |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|relationship_grab_size                            |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_shell_read_only                            |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|lucene_writer_cache_size                          |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|node_cache_array_fraction                         |The fraction of the heap (1%-10%)|String|yes |yes  |
|                                                  |to use for the base array in the |      |    |     |
|                                                  |node cache (when using the gcr   |      |    |     |
|                                                  |cache). 1.0 <                    |      |    |     |
|                                                  |node_cache_array_fraction < 10.0 |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.read_timeout                                   |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|allow_store_upgrade                               |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|execution_guard_enabled                           |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|jmx.port                                          |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|relationship_cache_array_fraction                 |The fraction of the heap (1%-10%)|String|yes |yes  |
|                                                  |to use for the base array in the |      |    |     |
|                                                  |relationship cache (when using   |      |    |     |
|                                                  |the gcr cache). 1.0 <            |      |    |     |
|                                                  |relationship_cache_array_fraction|      |    |     |
|                                                  |< 10.0                           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.branched_data_policy                           |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|store_dir                                         |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_logging_host                               |Host for remote logging using    |String|yes |yes  |
|                                                  |LogBack SocketAppender           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|online_backup_enabled                             |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_logging_port                               |Port for remote logging using    |String|yes |yes  |
|                                                  |LogBack SocketAppender. 1 <      |      |    |     |
|                                                  |remote_logging_port < 65535      |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|gc_monitor_threshold                              |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|array_block_size                                  |Specifies the block size for     |String|yes |yes  |
|                                                  |storing arrays. This parameter is|      |    |     |
|                                                  |only honored when the store is   |      |    |     |
|                                                  |created, otherwise it is ignored.|      |    |     |
|                                                  |The default block size is 120    |      |    |     |
|                                                  |bytes, and the overhead of each  |      |    |     |
|                                                  |block is the same as for string  |      |    |     |
|                                                  |blocks, i.e., 8 bytes.. 1 <      |      |    |     |
|                                                  |array_block_size                 |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|load_kernel_extensions                            |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.relationshipstore.db.mapped_memory       |The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the relationship store   |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|keep_logical_logs                                 |Make Neo4j keep the logical      |String|yes |yes  |
|                                                  |transaction logs for being able  |      |    |     |
|                                                  |to backup the database           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|dump_configuration                                |Print out the effective Neo4j    |String|yes |yes  |
|                                                  |configuration after startup.     |      |    |     |
|                                                  |Valid options:[true, false]      |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|gc_monitor_wait_time                              |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.nodestore.db.mapped_memory               |The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the node store           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_shell_enabled                              |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_shell_port                                 |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.cluster_name                                   |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ephemeral                                         |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.server_id                                      |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neo_store                                         |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.propertystore.db.index.mapped_memory     |The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the store for property   |      |    |     |
|                                                  |key indexes                      |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|backup_slave                                      |Mark this database as a backup   |String|yes |yes  |
|                                                  |slave. Valid options:[true,      |      |    |     |
|                                                  |false]                           |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.max_concurrent_channels_per_slave              |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|neostore.propertystore.db.mapped_memory           |The size to allocate for memory  |String|yes |yes  |
|                                                  |mapping the property value store |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|string_block_size                                 |Specifies the block size for     |String|yes |yes  |
|                                                  |storing strings. This parameter  |      |    |     |
|                                                  |is only honored when the store is|      |    |     |
|                                                  |created, otherwise it is ignored.|      |    |     |
|                                                  |Note that each character in a    |      |    |     |
|                                                  |string occupies two bytes,       |      |    |     |
|                                                  |meaning that a block size of 120 |      |    |     |
|                                                  |(the default size) will hold a 60|      |    |     |
|                                                  |character long string before     |      |    |     |
|                                                  |overflowing into a second block. |      |    |     |
|                                                  |Also note that each block carries|      |    |     |
|                                                  |an overhead of 8 bytes. This     |      |    |     |
|                                                  |means that if the block size is  |      |    |     |
|                                                  |120, the size of the stored      |      |    |     |
|                                                  |records will be 128 bytes.. 1 <  |      |    |     |
|                                                  |string_block_size                |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|grab_file_lock                                    |Whether to grab locks on files or|String|yes |yes  |
|                                                  |not. Valid options:[true, false] |      |    |     |
|--------------------------------------------------+---------------------------------+------+----+-----|
|remote_logging_enabled                            |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.server                                         |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.pull_interval                                  |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|ha.coordinator_fetch_info_timeout                 |Configuration attribute          |String|yes |yes  |
|--------------------------------------------------+---------------------------------+------+----+-----|
|online_backup_port                                |Configuration attribute          |String|yes |yes  |
+------------------------------------------------------------------------------------------------------+


Table 26.7. MBean Configuration (org.neo4j.jmx.impl.ConfigurationBean)
Operations

+-----------------------------------------------+
|Name |Description   |ReturnType|Signature      |
|-----+--------------+----------+---------------|
|apply|Apply settings|void      |(no parameters)|
+-----------------------------------------------+


Table 26.8. MBean Diagnostics (org.neo4j.management.Diagnostics) Attributes

+-----------------------------------------------------------------------------+
|Name                |Description                 |Type            |Read|Write|
|-----------------------------------------------------------------------------|
|                        Diagnostics provided by Neo4j                        |
|-----------------------------------------------------------------------------|
|DiagnosticsProviders|A list of the ids for the   |List            |yes |no   |
|                    |registered diagnostics      |(java.util.List)|    |     |
|                    |providers.                  |                |    |     |
+-----------------------------------------------------------------------------+


Table 26.9. MBean Diagnostics (org.neo4j.management.Diagnostics) Operations

+-----------------------------------------------------------------------------+
|Name     |Description                            |ReturnType|Signature       |
|---------+---------------------------------------+----------+----------------|
|extract  |Operation exposed for management       |String    |java.lang.String|
|---------+---------------------------------------+----------+----------------|
|dumpToLog|Dump diagnostics information to the    |void      |(no parameters) |
|         |log.                                   |          |                |
|---------+---------------------------------------+----------+----------------|
|dumpToLog|Dump diagnostics information to the    |void      |java.lang.String|
|         |log.                                   |          |                |
+-----------------------------------------------------------------------------+


Table 26.10. MBean High Availability (org.neo4j.management.HighAvailability)
Attributes

+-----------------------------------------------------------------------------+
|Name              |Description  |Type                             |Read|Write|
|-----------------------------------------------------------------------------|
|         Information about an instance participating in a HA cluster         |
|-----------------------------------------------------------------------------|
|MachineId         |The          |String                           |yes |no   |
|                  |identifier   |                                 |    |     |
|                  |used to      |                                 |    |     |
|                  |identify this|                                 |    |     |
|                  |machine in   |                                 |    |     |
|                  |the HA       |                                 |    |     |
|                  |cluster      |                                 |    |     |
|------------------+-------------+---------------------------------+----+-----|
|Master            |Whether this |boolean                          |yes |no   |
|                  |instance is  |                                 |    |     |
|                  |master or not|                                 |    |     |
|------------------+-------------+---------------------------------+----+-----|
|ConnectedSlaves   |(If this is a|org.neo4j.management.SlaveInfo[] |yes |no   |
|                  |master)      |as CompositeData[]               |    |     |
|                  |Information  |                                 |    |     |
|                  |about the    |                                 |    |     |
|                  |instances    |                                 |    |     |
|                  |connected to |                                 |    |     |
|                  |this instance|                                 |    |     |
|------------------+-------------+---------------------------------+----+-----|
|InstancesInCluster|Information  |org.neo4j.management.InstanceInfo|yes |no   |
|                  |about all    |[] as CompositeData[]            |    |     |
|                  |instances in |                                 |    |     |
|                  |this cluster |                                 |    |     |
|------------------+-------------+---------------------------------+----+-----|
|LastUpdateTime    |The time when|String                           |yes |no   |
|                  |the data on  |                                 |    |     |
|                  |this instance|                                 |    |     |
|                  |was last     |                                 |    |     |
|                  |updated from |                                 |    |     |
|                  |the master   |                                 |    |     |
+-----------------------------------------------------------------------------+


Table 26.11. MBean High Availability (org.neo4j.management.HighAvailability)
Operations

+-----------------------------------------------------------------------------+
|Name  |Description                                    |ReturnType|Signature  |
|------+-----------------------------------------------+----------+-----------|
|update|(If this is a slave) Update the database on    |String    |(no        |
|      |this instance with the latest transactions from|          |parameters)|
|      |the master                                     |          |           |
+-----------------------------------------------------------------------------+


Table 26.12. MBean Kernel (org.neo4j.jmx.Kernel) Attributes

+-----------------------------------------------------------------------------+
|Name             |Description         |Type                       |Read|Write|
|-----------------------------------------------------------------------------|
|                     Information about the Neo4j kernel                      |
|-----------------------------------------------------------------------------|
|ReadOnly         |Whether this is a   |boolean                    |yes |no   |
|                 |read only instance  |                           |    |     |
|-----------------+--------------------+---------------------------+----+-----|
|StoreId          |An identifier that, |String                     |yes |no   |
|                 |together with store |                           |    |     |
|                 |creation time,      |                           |    |     |
|                 |uniquely identifies |                           |    |     |
|                 |this Neo4j graph    |                           |    |     |
|                 |store.              |                           |    |     |
|-----------------+--------------------+---------------------------+----+-----|
|MBeanQuery       |An ObjectName that  |javax.management.ObjectName|yes |no   |
|                 |can be used as a    |                           |    |     |
|                 |query for getting   |                           |    |     |
|                 |all management beans|                           |    |     |
|                 |for this Neo4j      |                           |    |     |
|                 |instance.           |                           |    |     |
|-----------------+--------------------+---------------------------+----+-----|
|KernelStartTime  |The time from which |Date (java.util.Date)      |yes |no   |
|                 |this Neo4j instance |                           |    |     |
|                 |was in operational  |                           |    |     |
|                 |mode.               |                           |    |     |
|-----------------+--------------------+---------------------------+----+-----|
|StoreCreationDate|The time when this  |Date (java.util.Date)      |yes |no   |
|                 |Neo4j graph store   |                           |    |     |
|                 |was created.        |                           |    |     |
|-----------------+--------------------+---------------------------+----+-----|
|StoreLogVersion  |The current version |long                       |yes |no   |
|                 |of the Neo4j store  |                           |    |     |
|                 |logical log.        |                           |    |     |
|-----------------+--------------------+---------------------------+----+-----|
|KernelVersion    |The version of Neo4j|String                     |yes |no   |
|-----------------+--------------------+---------------------------+----+-----|
|StoreDirectory   |The location where  |String                     |yes |no   |
|                 |the Neo4j store is  |                           |    |     |
|                 |located             |                           |    |     |
+-----------------------------------------------------------------------------+


Table 26.13. MBean Locking (org.neo4j.management.LockManager) Attributes

+-------------------------------------------------------------------------------------------------+
|Name                     |Description                |Type                            |Read|Write|
|-------------------------------------------------------------------------------------------------|
|                             Information about the Neo4j lock status                             |
|-------------------------------------------------------------------------------------------------|
|NumberOfAdvertedDeadlocks|The number of lock         |long                            |yes |no   |
|                         |sequences that would have  |                                |    |     |
|                         |lead to a deadlock         |                                |    |     |
|                         |situation that Neo4j has   |                                |    |     |
|                         |detected and adverted (by  |                                |    |     |
|                         |throwing                   |                                |    |     |
|                         |DeadlockDetectedException).|                                |    |     |
|-------------------------+---------------------------+--------------------------------+----+-----|
|Locks                    |Information about all locks|java.util.List                  |yes |no   |
|                         |held by Neo4j              |<org.neo4j.kernel.info.LockInfo>|    |     |
|                         |                           |as CompositeData[]              |    |     |
+-------------------------------------------------------------------------------------------------+


Table 26.14. MBean Locking (org.neo4j.management.LockManager) Operations

+------------------------------------------------------------------------------+
|Name             |Description      |ReturnType                      |Signature|
|-----------------+-----------------+--------------------------------+---------|
|getContendedLocks|getContendedLocks|java.util.List                  |long     |
|                 |                 |<org.neo4j.kernel.info.LockInfo>|         |
|                 |                 |as CompositeData[]              |         |
+------------------------------------------------------------------------------+


Table 26.15. MBean Memory Mapping (org.neo4j.management.MemoryMapping)
Attributes

+-----------------------------------------------------------------------------+
|Name       |Description       |Type                               |Read|Write|
|-----------------------------------------------------------------------------|
|                     The status of Neo4j memory mapping                      |
|-----------------------------------------------------------------------------|
|MemoryPools|Get information   |org.neo4j.management.WindowPoolInfo|yes |no   |
|           |about each pool of|[] as CompositeData[]              |    |     |
|           |memory mapped     |                                   |    |     |
|           |regions from store|                                   |    |     |
|           |files with memory |                                   |    |     |
|           |mapping enabled   |                                   |    |     |
+-----------------------------------------------------------------------------+


Table 26.16. MBean Primitive count (org.neo4j.jmx.Primitives) Attributes

+-----------------------------------------------------------------------------+
|Name                            |Description                 |Type|Read|Write|
|-----------------------------------------------------------------------------|
|       Estimates of the numbers of different kinds of Neo4j primitives       |
|-----------------------------------------------------------------------------|
|NumberOfNodeIdsInUse            |An estimation of the number |long|yes |no   |
|                                |of nodes used in this Neo4j |    |    |     |
|                                |instance                    |    |    |     |
|--------------------------------+----------------------------+----+----+-----|
|NumberOfRelationshipIdsInUse    |An estimation of the number |long|yes |no   |
|                                |of relationships used in    |    |    |     |
|                                |this Neo4j instance         |    |    |     |
|--------------------------------+----------------------------+----+----+-----|
|NumberOfPropertyIdsInUse        |An estimation of the number |long|yes |no   |
|                                |of properties used in this  |    |    |     |
|                                |Neo4j instance              |    |    |     |
|--------------------------------+----------------------------+----+----+-----|
|NumberOfRelationshipTypeIdsInUse|The number of relationship  |long|yes |no   |
|                                |types used in this Neo4j    |    |    |     |
|                                |instance                    |    |    |     |
+-----------------------------------------------------------------------------+


Table 26.17. MBean Store file sizes (org.neo4j.management.StoreFile) Attributes

+-----------------------------------------------------------------------------+
|Name                 |Description                            |Type|Read|Write|
|-----------------------------------------------------------------------------|
| Information about the sizes of the different parts of the Neo4j graph store |
|-----------------------------------------------------------------------------|
|TotalStoreSize       |The total disk space used by this Neo4j|long|yes |no   |
|                     |instance, in bytes.                    |    |    |     |
|---------------------+---------------------------------------+----+----+-----|
|LogicalLogSize       |The amount of disk space used by the   |long|yes |no   |
|                     |current Neo4j logical log, in bytes.   |    |    |     |
|---------------------+---------------------------------------+----+----+-----|
|ArrayStoreSize       |The amount of disk space used to store |long|yes |no   |
|                     |array properties, in bytes.            |    |    |     |
|---------------------+---------------------------------------+----+----+-----|
|NodeStoreSize        |The amount of disk space used to store |long|yes |no   |
|                     |nodes, in bytes.                       |    |    |     |
|---------------------+---------------------------------------+----+----+-----|
|PropertyStoreSize    |The amount of disk space used to store |long|yes |no   |
|                     |properties (excluding string values and|    |    |     |
|                     |array values), in bytes.               |    |    |     |
|---------------------+---------------------------------------+----+----+-----|
|RelationshipStoreSize|The amount of disk space used to store |long|yes |no   |
|                     |relationships, in bytes.               |    |    |     |
|---------------------+---------------------------------------+----+----+-----|
|StringStoreSize      |The amount of disk space used to store |long|yes |no   |
|                     |string properties, in bytes.           |    |    |     |
+-----------------------------------------------------------------------------+


Table 26.18. MBean Transactions (org.neo4j.management.TransactionManager)
Attributes

+-----------------------------------------------------------------------------+
|Name                              |Description               |Type|Read|Write|
|-----------------------------------------------------------------------------|
|               Information about the Neo4j transaction manager               |
|-----------------------------------------------------------------------------|
|LastCommittedTxId                 |The id of the latest      |long|yes |no   |
|                                  |committed transaction     |    |    |     |
|----------------------------------+--------------------------+----+----+-----|
|NumberOfOpenTransactions          |The number of currently   |int |yes |no   |
|                                  |open transactions         |    |    |     |
|----------------------------------+--------------------------+----+----+-----|
|PeakNumberOfConcurrentTransactions|The highest number of     |int |yes |no   |
|                                  |transactions ever opened  |    |    |     |
|                                  |concurrently              |    |    |     |
|----------------------------------+--------------------------+----+----+-----|
|NumberOfOpenedTransactions        |The total number started  |int |yes |no   |
|                                  |transactions              |    |    |     |
|----------------------------------+--------------------------+----+----+-----|
|NumberOfCommittedTransactions     |The total number of       |long|yes |no   |
|                                  |committed transactions    |    |    |     |
|----------------------------------+--------------------------+----+----+-----|
|NumberOfRolledBackTransactions    |The total number of rolled|long|yes |no   |
|                                  |back transactions         |    |    |     |
+-----------------------------------------------------------------------------+


Table 26.19. MBean XA Resources (org.neo4j.management.XaManager) Attributes

+-----------------------------------------------------------------------------+
|Name       |Description       |Type                               |Read|Write|
|-----------------------------------------------------------------------------|
|                Information about the XA transaction manager                 |
|-----------------------------------------------------------------------------|
|XaResources|Information about |org.neo4j.management.XaResourceInfo|yes |no   |
|           |all XA resources  |[] as CompositeData[]              |    |     |
|           |managed by the    |                                   |    |     |
|           |transaction       |                                   |    |     |
|           |manager           |                                   |    |     |
+-----------------------------------------------------------------------------+


Part V. Tools

The Tools part describes available Neo4j tools and how to use them.

Table of Contents

27. Web Administration

    27.1. Dashboard tab

        27.1.1. Entity chart
        27.1.2. Status monitoring

    27.2. Data tab
    27.3. Console tab
    27.4. The Server Info tab

28. Neo4j Shell

    28.1. Starting the shell

        28.1.1. Enabling the shell server
        28.1.2. Connecting to a shell server
        28.1.3. Pointing the shell to a path
        28.1.4. Read-only mode
        28.1.5. Run a command and then exit

    28.2. Passing options and arguments
    28.3. Enum options
    28.4. Filters
    28.5. Node titles
    28.6. How to use (individual commands)

        28.6.1. Current node/relationship and path
        28.6.2. Listing the contents of a node/relationship
        28.6.3. Creating nodes and relationships
        28.6.4. Setting, renaming and removing properties
        28.6.5. Deleting nodes and relationships
        28.6.6. Environment variables
        28.6.7. Executing groovy/python scripts
        28.6.8. Traverse
        28.6.9. Query with Cypher
        28.6.10. Indexing
        28.6.11. Transactions

    28.7. Extending the shell: Adding your own commands
    28.8. An example shell session
    28.9. A Matrix example

Chapter 27. Web Administration

The Neo4j Web Administration is the primary user interface for Neo4j. With it,
you can:

  * monitor the Neo4j Server
  * manipulate and browse data
  * interact with the database via various consoles
  * view raw data management objects (JMX MBeans)

The tool is available at http://127.0.0.1:7474/ <http://127.0.0.1:7474/> after
you have installed the Neo4j Server. To use it together with an embedded
database, see Section 18.4, “Using the server (including web administration)
with an embedded database”.

27.1. Dashboard tab

The Dashboard tab provides an overview of a running Neo4j instance.

Figure 27.1. Web Administration Dashboard

Dashboard tab


27.1.1. Entity chart

The charts show entity counts over time: node, relationship and properties.

Figure 27.2. Entity charting

Entity charts


27.1.2. Status monitoring

Below the entity chart is a collection of status panels, displaying current
resource usage.

Figure 27.3. Status indicator panels

Status indicator panels


27.2. Data tab

Use the Data tab to browse, add or modify nodes, relationships and their
properties.

Figure 27.4. Browsing and manipulating data

Data tab


Figure 27.5. Editing properties

Node properties


27.3. Console tab

The Console tab gives:

  * scripting access to the database via the Gremlin <http://
    gremlin.tinkerpop.com> scripting engine,
  * query access via Cypher,
  * HTTP access via the HTTP console.

Figure 27.6. Traverse data with Gremlin

Data manipulation with Gremlin


Figure 27.7. Query data with Cypher

Queries with Cypher


Figure 27.8. Interact over HTTP

Queries with Cypher


27.4. The Server Info tab

The Server Info tab provides raw access to all available management objects
(see Chapter 26, Monitoring for details).

Figure 27.9. JMX Attributes

JMX


Chapter 28. Neo4j Shell

Neo4j shell is a command-line shell for browsing the graph, much like how the
Unix shell along with commands like cd, ls and pwd can be used to browse your
local file system. It consists of two parts:

  * a lightweight client that sends commands via RMI and
  * a server that processes those commands and sends the result back to the
    client.

It’s a nice tool for development and debugging. This guide will show you how to
get it going!

28.1. Starting the shell

When used together with Neo4j started as a server, simply issue the following
at the command line:

./bin/neo4j-shell

For the full list of options, see the reference in the Shell manual page.

To connect to a running Neo4j database, use Section 28.1.4, “Read-only mode”
for local databases and see Section 28.1.1, “Enabling the shell server” for
remote databases.

You need to make sure that the shell jar file is on the classpath when you
start up your Neo4j instance.

28.1.1. Enabling the shell server

Shell is enabled from the configuration of the Neo4j kernel, see Section 18.2,
“Server Configuration”. Here’s some sample configurations:

# Using default values
enable_remote_shell = true
# ...or specify custom port, use default values for the others
enable_remote_shell = port=1234

When using the Neo4j server, see Section 18.2, “Server Configuration” for how
to add configuration settings in that case.

There are two ways to start the shell, either by connecting to a remote shell
server or by pointing it to a Neo4j store path.

28.1.2. Connecting to a shell server

To start the shell and connect to a running server, run:

neo4j-shell

Alternatively supply -port and -name options depending on how the remote shell
server was enabled. Then you’ll get the shell prompt like this:

neo4j-sh (0)$

28.1.3. Pointing the shell to a path

To start the shell by just pointing it to a Neo4j store path you run the shell
jar file. Given that the right neo4j-kernel-<version>.jar and jta jar files are
in the same path as your neo4j-shell-<version>.jar file you run it with:

$ neo4j-shell -path path/to/neo4j-db

28.1.4. Read-only mode

By issuing the -readonly switch when starting the shell with a store path,
changes cannot be made to the database during the session.

$ neo4j-shell -readonly -path path/to/neo4j-db

28.1.5. Run a command and then exit

It is possible to tell the shell to just start, execute a command and then
exit. This opens up for uses of background jobs and also handling of huge
output of f.ex. an ''ls'' command where you then could pipe the output to 
''less'' or another reader of your choice, or even to a file. So some examples
of usage:

$ neo4j-shell -c "cd -a 24 && set name Mattias"
$ neo4j-shell -c "trav -r KNOWS" | less

28.2. Passing options and arguments

Passing options and arguments to your commands is very similar to many CLI
commands in an *nix environment. Options are prefixed with a - and can contain
one or more options. Some options expect a value to be associated with it.
Arguments are string values which aren’t prefixed with -. Let’s look at ls as
an example:

ls -r -f KNOWS:out -v 12345 will make a verbose listing of node 12345's
outgoing relationships of type KNOWS. The node id, 12345, is an argument to ls
which tells it to do the listing on that node instead of the current node (see
pwd command). However a shorter version of this can be written:

ls -rfv KNOWS:out 12345. Here all three options are written together after a
single - prefix. Even though f is in the middle it gets associated with the
KNOWS:out value. The reason for this is that the ls command doesn’t expect any
values associated with the r or v options. So, it can infer the right values
for the rights options.

28.3. Enum options

Some options expects a value which is one of the values in an enum, f.ex.
direction part of relationship type filtering where there’s INCOMING, OUTGOING
and BOTH. All such values can be supplied in an easier way. It’s enough that
you write the start of the value and the interpreter will find what you really
meant. F.ex. out, in, i or even INCOMING.

28.4. Filters

Some commands makes use of filters for varying purposes. F.ex. -f in ls and in
trav. A filter is supplied as a json <http://www.json.org/> object (w/ or w/o
the surrounding {} brackets. Both keys and values can contain regular
expressions for a more flexible matching. An example of a filter could be
.*url.*:http.*neo4j.*,name:Neo4j. The filter option is also accompanied by the
options -i and -l which stands for ignore case (ignore casing of the
characters) and loose matching (it’s considered a match even if the filter
value just matches a part of the compared value, not necessarily the entire
value). So for a case-insensitive, loose filter you can supply a filter with -f
-i -l or -fil for short.

28.5. Node titles

To make it easier to navigate your graph the shell can display a title for each
node, f.ex. in ls -r. It will display the relationships as well as the nodes on
the other side of the relationships. The title is displayed together with each
node and its best suited property value from a list of property keys.

If you’re standing on a node which has two KNOWS relationships to other nodes
it’d be difficult to know which friend is which. The title feature addresses
this by reading a list of property keys and grabbing the first existing
property value of those keys and displays it as a title for the node. So you
may specify a list (with or without regular expressions), f.ex:
name,title.*,caption and the title for each node will be the property value of
the first existing key in that list. The list is defined by the client (you)
using the TITLE_KEYS environment variable and the default being
.*name.*,.*title.*

28.6. How to use (individual commands)

The shell is modeled after Unix shells like bash that you use to walk around
your local file system. It has some of the same commands, like cd and ls. When
you first start the shell (see instructions above), you will get a list of all
the available commands. Use man <command> to get more info about a particular
command. Some notes:

28.6.1. Current node/relationship and path

You have a current node/relationship and a "current path" (like a current
working directory in bash) that you’ve traversed so far. You start at the
reference node <http://api.neo4j.org/current/org/neo4j/graphdb/
GraphDatabaseService.html#getReferenceNode()> and can then cd your way through
the graph (check your current path at any time with the pwd command). cd can be
used in different ways:

  * cd <node-id> will traverse one relationship to the supplied node id. The
    node must have a direct relationship to the current node.
  * cd -a <node-id> will do an absolute path change, which means the supplied
    node doesn’t have to have a direct relationship to the current node.
  * cd -r <relationship-id> will traverse to a relationship instead of a node.
    The relationship must have the current node as either start or end point.
    To see the relationship ids use the ls -vr command on nodes.
  * cd -ar <relationship-id> will do an absolute path change which means the
    relationship can be any relationship in the graph.
  * cd will take you back to the reference node, where you started in the first
    place.
  * cd .. will traverse back one step to the previous location, removing the
    last path item from your current path (pwd).
  * cd start (only if your current location is a relationship). Traverses to
    the start node of the relationship.
  * cd end (only if your current location is a relationship). Traverses to the
    end node of the relationship.

28.6.2. Listing the contents of a node/relationship

List contents of the current node/relationship (or any other node) with the ls
command. Please note that it will give an empty output if the current node/
relationship has no properties or relationships (for example in the case of a
brand new graph). ls can take a node id as argument as well as filters, see
Section 28.4, “Filters” and for information about how to specify direction see
Section 28.3, “Enum options”. Use man ls for more info.

28.6.3. Creating nodes and relationships

You create new nodes by connecting them with relationships to the current node.
For example, mkrel -t A_RELATIONSHIP_TYPE -d OUTGOING -c will create a new node
(-c) and draw to it an OUTGOING relationship of type A_RELATIONSHIP_TYPE from
the current node. If you already have two nodes which you’d like to draw a
relationship between (without creating a new node) you can do for example,
mkrel -t A_RELATIONSHIP_TYPE -d OUTGOING -n <other-node-id> and it will just
create a new relationship between the current node and that other node.

28.6.4. Setting, renaming and removing properties

Property operations are done with the set, mv and rm commands. These commands
operates on the current node/relationship. * set <key> <value> with optionally
the -t option (for value type) sets a property. Supports every type of value
that Neo4j supports. Examples of a property of type int:

$ set -t int age 29

And an example of setting a double[] property:

$ set -t double[] my_values [1.4,12.2,13]

Example of setting a String property containing a JSON string:

mkrel -c -d i -t DOMAIN_OF --np "{'app':'foobar'}"

  * rm <key> removes a property.
  * mv <key> <new-key> renames a property from one key to another.

28.6.5. Deleting nodes and relationships

Deletion of nodes and relationships is done with the rmnode and rmrel commands.
rmnode can delete nodes, if the node to be deleted still has relationships they
can also be deleted by supplying -f option. rmrel can delete relationships, it
tries to ensure connectedness in the graph, but relationships can be deleted
regardless with the -f option. rmrel can also delete the node on the other side
of the deleted relationship if it’s left with no more relationships, see -d
option.

28.6.6. Environment variables

The shell uses environment variables a-la bash to keep session information,
such as the current path and more. The commands for this mimics the bash
commands export and env. For example you can at anytime issue a export
STACKTRACES=true command to set the STACKTRACES environment variable to true.
This will then result in stacktraces being printed if an exception or error
should occur. List environment variables using env

28.6.7. Executing groovy/python scripts

The shell has support for executing scripts, such as Groovy <http://
groovy.codehaus.org> and Python <http://www.python.org> (via Jython <http://
www.jython.org>). As of now the scripts (*.groovy, *.py) must exist on the
server side and gets called from a client with for example, gsh --renamePerson
1234 "Mathias" "Mattias" --doSomethingElse where the scripts
renamePerson.groovy and doSomethingElse.groovy must exist on the server side in
any of the paths given by the GSH_PATH environment variable (defaults to
.:src:src/script). This variable is like the java classpath, separated by a :.
The python/jython scripts can be executed with the jsh in a similar fashion,
however the scripts have the .py extension and the environment variable for the
paths is JSH_PATH.

When writing the scripts assume that there’s made available an args variable (a
String[]) which contains the supplied arguments. In the case of the
renamePerson example above the array would contain ["1234", "Mathias",
"Mattias"]. Also please write your outputs to the out variable, such as
out.println( "My tracing text" ) so that it will be printed at the shell client
instead of the server.

28.6.8. Traverse

You can traverse the graph with the trav command which allows for simple
traversing from the current node. You can supply which relationship types (w/
regex matching) and optionally direction as well as property filters for
matching nodes. In addition to that you can supply a command line to execute
for each match. An example: trav -o depth -r KNOWS:both,HAS_.*:incoming -c "ls
$n". Which means traverse depth first for relationships with type KNOWS
disregarding direction and incoming relationships with type matching HAS_.\*
and do a ls <matching node> for each match. The node filtering is supplied with
the -f option, see Section 28.4, “Filters”. See Section 28.3, “Enum options”
for the traversal order option. Even relationship types/directions are supplied
using the same format as filters.

28.6.9. Query with Cypher

You can use Cypher to query the graph. For that, use the start command.

  * start n = (0) return n will give you a listing of the node with ID 0

28.6.10. Indexing

It’s possible to query and manipulate indexes via the index command. Example:
index -i persons name (will index the name for the current node or relationship
in the "persons" index).

  * -g will do exact lookup in the index and display hits. You can supply -c
    with a command to be executed for each hit.
  * -q will ask the index a query and display hits. You can supply -c with a
    command to be executed for each hit.
  * --cd will change current location to the hit from the query. It’s just a
    convenience for using the -c option.
  * --ls will do a listing of the contents for each hit. It’s just a
    convenience for using the -c option.
  * -i will index a key-value pair in an index for the current node/
    relationship. If no value is given the property value for that key for the
    current node is used as value.
  * -r will remove a key-value pair (if it exists) from an index for the
    current node/relationship. Key and value is optional.

28.6.11. Transactions

It is useful to be able to test changes, and then being able to commit or
rollback said changes.

Transactions can be nested. With a nested transaction, a commit does not write
any changes to disk, except for the top level transaction. A rollback, however
works regardless of the level of the transaction. It will roll back all open
transactions.

  * begin transaction Starts a transaction.
  * commit Commits a transaction.
  * rollback Rollbacks all open transactions.

28.7. Extending the shell: Adding your own commands

Of course the shell is extendable and has a generic core which has nothing to
do with Neo4j… only some of the commands <http://components.neo4j.org/
neo4j-shell/1.8.M04/apidocs/org/neo4j/shell/App.html> do.

So you say you’d like to start a Neo4j graph database <http://api.neo4j.org/
current/org/neo4j/graphdb/GraphDatabaseService.html>, enable the remote shell
and add your own apps to it so that your apps and the standard Neo4j apps
co-exist side by side? Well, here’s an example of how an app could look like:

import org.neo4j.helpers.Service;
import org.neo4j.shell.kernel.apps.GraphDatabaseApp;

@Service.Implementation( App.class )
public class LsRelTypes extends GraphDatabaseApp
{
    @Override
    protected String exec( AppCommandParser parser, Session session, Output out )
            throws ShellException, RemoteException
    {
        GraphDatabaseService graphDb = getServer().getDb();
        out.println( "Types:" );
        for ( RelationshipType type : graphDb.getRelationshipTypes() )
        {
            out.println( type.name() );
        }
        return null;
    }
}

And you could now use it in the shell by typing lsreltypes (its name is based
on the class name) if getName method isn’t overridden.

If you’d like it to display some nice help information when using the help (or
man) app, override the getDescription method for a general description and use
addValueType method to add descriptions about (and logic to) the options you
can supply when using your app.

Know that the apps reside server-side so if you have a running server and
starts a remote client to it from another JVM you can’t add your apps on the
client.

28.8. An example shell session

 # where are we?
 neo4j-sh (0)$ pwd
 Current is (0)
 (0)


 # On the current node, set the key "name" to value "Jon"
 neo4j-sh (0)$ set name "Jon"

 # send a cypher query
 neo4j-sh (Jon,0)$ start n=node(0) return n;
 +---------------------+
 | n                   |
 +---------------------+
 | Node[0]{name:"Jon"} |
 +---------------------+
 1 row
 0 ms



 # make an incoming relationship of type LIKES, create the end node with the node properties specified.
 neo4j-sh (Jon,0)$ mkrel -c -d i -t LIKES --np "{'app':'foobar'}"

 # where are we?
 neo4j-sh (Jon,0)$ ls
 *name =[Jon]
 (me)<-[:LIKES]-(1)


 # change to the newly created node
 neo4j-sh (Jon,0)$ cd 1

 # list relationships, including relationshship id
 neo4j-sh (1)$ ls -avr
 (me)-[:LIKES,0]->(Jon,0)


 # create one more KNOWS relationship and the end node
 neo4j-sh (1)$ mkrel -c -d i -t KNOWS --np "{'name':'Bob'}"

 # print current history stack
 neo4j-sh (1)$ pwd
 Current is (1)
 (Jon,0)-->(1)


 # verbose list relationships
 neo4j-sh (1)$ ls -avr
 (me)-[:LIKES,0]->(Jon,0)
 (me)<-[:KNOWS,1]-(Bob,2)

28.9. A Matrix example

This example is creating a graph of the characters in the Matrix via the shell
and then executing Cypher queries against it:

Figure 28.1. Shell Matrix Example

Shell-Matrix-Example-graph.svg


Neo4j is configured for autoindexing, in this case with the following in the
Neo4j configuration file:

node_auto_indexing=true
node_keys_indexable=name,age

relationship_auto_indexing=true
relationship_keys_indexable=ROOT,KNOWS,CODED_BY

The following is a sample shell session creating the Matrix graph and querying
it.

 # create the Thomas Andersson node
 neo4j-sh (0)$ mkrel -t ROOT -c -v
 Node (1) created
 Relationship [:ROOT,0] created


 # go to the new node
 neo4j-sh (0)$ cd 1

 # set the name property
 neo4j-sh (1)$ set name "Thomas Andersson"

 # create Thomas direct friends
 neo4j-sh (Thomas Andersson,1)$ mkrel -t KNOWS -cv
 Node (2) created
 Relationship [:KNOWS,1] created


 # go to the new node
 neo4j-sh (Thomas Andersson,1)$ cd 2

 # set the name property
 neo4j-sh (2)$ set name "Trinity"

 # go back in the history stack
 neo4j-sh (Trinity,2)$ cd ..

 # create Thomas direct friends
 neo4j-sh (Thomas Andersson,1)$ mkrel -t KNOWS -cv
 Node (3) created
 Relationship [:KNOWS,2] created


 # go to the new node
 neo4j-sh (Thomas Andersson,1)$ cd 3

 # set the name property
 neo4j-sh (3)$ set name "Morpheus"

 # create relationship to Trinity
 neo4j-sh (Morpheus,3)$ mkrel -t KNOWS 2

 # list the relationships of node 3
 neo4j-sh (Morpheus,3)$ ls -rv
 (me)-[:KNOWS,3]->(Trinity,2)
 (me)<-[:KNOWS,2]-(Thomas Andersson,1)


 # change the current position to relationship #2
 neo4j-sh (Morpheus,3)$ cd -r 2

 # set the age property on the relationship
 neo4j-sh [:KNOWS,2]$ set -t int age 3

 # back to Morpheus
 neo4j-sh [:KNOWS,2]$ cd ..

 # next relationsip
 neo4j-sh (Morpheus,3)$ cd -r 3

 # set the age property on the relationship
 neo4j-sh [:KNOWS,3]$ set -t int age 90

 # position to the start node of the current relationship
 neo4j-sh [:KNOWS,3]$ cd start

 # new node
 neo4j-sh (Morpheus,3)$ mkrel -t KNOWS -c

 # list relationships on the current node
 neo4j-sh (Morpheus,3)$ ls -r
 (me)-[:KNOWS]->(Trinity,2)
 (me)-[:KNOWS]->(4)
 (me)<-[:KNOWS]-(Thomas Andersson,1)


 # go to Cypher
 neo4j-sh (Morpheus,3)$ cd 4

 # set the name
 neo4j-sh (4)$ set name Cypher

 # create new node from Cypher
 neo4j-sh (Cypher,4)$ mkrel -ct KNOWS

 # list relationships
 neo4j-sh (Cypher,4)$ ls -r
 (me)-[:KNOWS]->(5)
 (me)<-[:KNOWS]-(Morpheus,3)


 # go to the Agent Smith node
 neo4j-sh (Cypher,4)$ cd 5

 # set the name
 neo4j-sh (5)$ set name "Agent Smith"

 # outgoing relationship and new node
 neo4j-sh (Agent Smith,5)$ mkrel -cvt CODED_BY
 Node (6) created
 Relationship [:CODED_BY,6] created


 # go there
 neo4j-sh (Agent Smith,5)$ cd 6

 # set the name
 neo4j-sh (6)$ set name "The Architect"

 # go to the first node in the history stack
 neo4j-sh (The Architect,6)$ cd

 # Morpheus' friends, looking up Morpheus by name in the Neo4j autoindex
 neo4j-sh (0)$ start morpheus = node:node_auto_index(name='Morpheus') match morpheus-[:KNOWS]-zionist return zionist.name

 # Morpheus' friends, looking up Morpheus by name in the Neo4j autoindex
 > cypher 1.5 start morpheus = node:node_auto_index(name='Morpheus') match morpheus-[:KNOWS]-zionist return zionist.name

Part VI. Community

The Neo4j project has a strong community around it. Read about how to get help
from the community and how to contribute to it.

Table of Contents

29. Community Support
30. Contributing to Neo4j

    30.1. Contributor License Agreement

        30.1.1. Summary
        30.1.2. Common questions
        30.1.3. How to sign

    30.2. Areas for contribution

        30.2.1. Neo4j Distribution
        30.2.2. Maintaining Neo4j Documentation
        30.2.3. Drivers and bindings to Neo4j

    30.3. Writing Neo4j Documentation

        30.3.1. Overall Flow
        30.3.2. File Structure in docs.jar
        30.3.3. Headings and document structure
        30.3.4. Writing
        30.3.5. Gotchas
        30.3.6. Links
        30.3.7. Text Formatting
        30.3.8. Admonitions
        30.3.9. Images
        30.3.10. Attributes
        30.3.11. Comments
        30.3.12. Code Snippets
        30.3.13. A sample Java based documentation test
        30.3.14. Hello world Sample Chapter
        30.3.15. Integrated Live Console
        30.3.16. Toolchain

    30.4. Contributing Code to Neo4j

        30.4.1. Intro
        30.4.2. The Fast Track
        30.4.3. Governance fundamentals
        30.4.4. Contributor roles
        30.4.5. Code Style
        30.4.6. Unit Tests
        30.4.7. Workflow
        30.4.8. Commit messages

    30.5. Contributors

Chapter 29. Community Support

You can learn a lot about Neo4j on different events. To get information on
upcoming Neo4j events, have a look here:

  * http://events.neo4j.org/ <http://events.neo4j.org/>
  * http://neo4j.meetup.com/ <http://neo4j.meetup.com/>

Get help from the Neo4j open source community; here are some starting points.

  * Neo4j Community Discussions: https://groups.google.com/forum/#!forum/neo4j
    <https://groups.google.com/forum/#!forum/neo4j>
  * Twitter: http://twitter.com/neo4j <http://twitter.com/neo4j>
  * IRC channel: irc://irc.freenode.net/neo4j <irc://irc.freenode.net/neo4j>
    web chat <http://webchat.freenode.net/?randomnick=1&channels=neo4j>.

Report a bug or add a feature request:

  * General: https://github.com/neo4j/community/issues <https://github.com/
    neo4j/community/issues>
  * Monitoring: https://github.com/neo4j/advanced/issues <https://github.com/
    neo4j/advanced/issues>
  * Backup and High Availability: https://github.com/neo4j/enterprise/issues
    <https://github.com/neo4j/enterprise/issues>

Questions regarding the documentation: The Neo4j Manual is published online
with a comment function, please use that to post any questions or comments. See
http://docs.neo4j.org/ <http://docs.neo4j.org/>.

Chapter 30. Contributing to Neo4j

The Neo4j project is an Open Source effort to bring fast complex data storage
and processing to life. Every form of help is highly appreciated by the
community - and you are not alone, see Section 30.5, “Contributors”!

One crucial aspect of contributing to the Neo4j project is the Section 30.1,
“Contributor License Agreement”.

In short: make sure to sign the CLA and send in the email, or the Neo4j project
won’t be able to accept your contribution.

Note that you can contribute to Neo4j also by contributing documentation or
giving feedback on the current documentation. Basically, at all the places
where you can get help, there’s also room for contributions.

If you want to contribute, there are some good areas to start with, especially
for getting in contact with the community, Chapter 29, Community Support.

To document your efforts, we highly recommend to read Section 30.3, “Writing
Neo4j Documentation”.

30.1. Contributor License Agreement

30.1.1. Summary

We require all source code that is hosted on the Neo4j infrastructure to be
contributed through the Neo4j Contributor License Agreement <http://
dist.neo4j.org/neo4j-cla.pdf> (CLA). The purpose of the Neo4j Contributor
License Agreement is to protect the integrity of the code base, which in turn
protects the community around that code base: the founding entity Neo
Technology, the Neo4j developer community and the Neo4j users. This kind of
contributor agreement is common amongst free software and open source projects
(it is in fact very similar to the widely signed Oracle Contributor Agreement
<http://www.oracle.com/technetwork/community/oca-486395.html>).

Please see the below or send a mail to admins [at] neofourjay.org if you have
any other questions about the intent of the CLA. If you have a legal question,
please ask a lawyer.

30.1.2. Common questions

30.1.2.1. Am I losing the rights to my own code?

No, the Neo4j CLA <http://dist.neo4j.org/neo4j-cla.pdf> only asks you to share
your rights, not relinquish them. Unlike some contribution agreements that
require you to transfer copyrights to another organization, the CLA does not
take away your rights to your contributed intellectual property. When you agree
to the CLA, you grant us joint ownership in copyright, and a patent license for
your contributions. You retain all rights, title, and interest in your
contributions and may use them for any purpose you wish. Other than revoking
our rights, you can still do whatever you want with your code.

30.1.2.2. What can you do with my contribution?

We may exercise all rights that a copyright holder has, as well as the rights
you grant in the Neo4j CLA <http://dist.neo4j.org/neo4j-cla.pdf> to use any
patents you have in your contributions. As the CLA provides for joint copyright
ownership, you may exercise the same rights as we in your contributions.

30.1.2.3. What are the community benefits of this?

Well, it allows us to sponsor the Neo4j projects and provide an infrastructure
for the community, while making sure that we can include this in software that
we ship to our customers without any nasty surprises. Without this ability, we
as a small company would be hard pressed to release all our code as free
software.

Moreover, the CLA lets us protect community members (both developers and users)
from hostile intellectual property litigation should the need arise. This is in
line with how other free software stewards like the Free Software Foundation -
FSF <http://fsf.org> defend projects (except with the FSF, there’s no shared
copyright but instead you completely sign it over to the FSF). The contributor
agreement also includes a "free software covenant," or a promise that a
contribution will remain available as free software.

At the end of the day, you still retain all rights to your contribution and we
can stand confident that we can protect the Neo4j community and the Neo
Technology customers.

30.1.2.4. Can we discuss some items in the CLA?

Absolutely! Please give us feedback! But let’s keep the legalese off the
mailing lists. Please mail your feedback directly to cla (@t) neotechnology dot
cöm and we’ll get back to you.

30.1.2.5. I still don’t like this CLA.

That’s fine. You can still host it anywhere else, of course. Please do! We’re
only talking here about the rules for the infrastructure that we provide.

30.1.3. How to sign

When you’ve read through the CLA, please send a mail to cla (@t) neotechnology
dot cöm. Include the following information:

  * Your full name.
  * Your e-mail address.
  * An attached copy of the Neo4j CLA <http://dist.neo4j.org/neo4j-cla.pdf>.
  * That you agree to its terms.

For example:

Hi. My name is John Doe (john@doe.com).
I agree to the terms in the attached Neo4j Contributor License Agreement.

30.2. Areas for contribution

Neo4j is a project with a vast ecosystem and a lot of space for contributions.
Where you can and want to pitch in depends of course on your time, skill set
and interests. Below are some of the areas that might interest you:

30.2.1. Neo4j Distribution

  * The Neo4j Community open issues <https://github.com/neo4j/community/issues>
    for some starting points for contribution
  * See the GitHub Neo4j area <https://github.com/neo4j/> for a list of
    projects

30.2.2. Maintaining Neo4j Documentation

Some parts of the documentation need extra care from the community to stay up
to date. They typically refer to different kinds of community contributions.
Below is a list of such places, feel free to look into them and check for
outdated or missing content! The easiest way to contribute fixes is to comment
at the online HTML version <http://docs.neo4j.org/chunked/snapshot/>.

  * Chapter 6, Neo4j Remote Client Libraries

30.2.3. Drivers and bindings to Neo4j

  * REST: see Chapter 6, Neo4j Remote Client Libraries for a list of active
    projects

30.3. Writing Neo4j Documentation

Note

Other than writing documentation, you can help out by providing comments - head
over to the online HTML version <http://docs.neo4j.org/chunked/snapshot/> to do
that!

For how to build the manual see: readme <https://github.com/neo4j/manual/blob/
master/README.asciidoc>

The documents use the asciidoc format, see:

  * Aciidoc Reference <http://www.methods.co.nz/asciidoc/>
  * AsciiDoc cheatsheet <http://powerman.name/doc/asciidoc>

The cheatsheet is really useful!

30.3.1. Overall Flow

Each (sub)project has its own documentation, which will produce a docs.jar
file. By default this file is assembled from the contents in src/docs/.
Asciidoc documents have the .txt file extension.

The documents can use code snippets which will extract code from the project.
The corresponding code must be deployed to the sources.jar or test-sources.jar
file.

By setting up a unit test accordingly, documentation can be written directly in
the JavaDoc comment.

The above files are all consumed by the build of the manual (by adding them as
dependencies). To get content included in the manual, it has to be explicitly
included by a document in the manual as well.

Note that different ways to add documentation works best for different cases:

  * For detail level documentation, it works well to write the documentation as
    part of unit tests (in the JavaDoc comment). In this case, you typically do
    not want to link to the source code in the documentation.
  * For tutorial level documentation, the result will be best by writing a .txt
    file containing the text. Source snippets and output examples can then be
    included from there. In this case you typically want to link to the source
    code, and users should be able to run it without any special setup.

30.3.2. File Structure in docs.jar

+---------------------------------------+
|Directory  |Contents                   |
|-----------+---------------------------|
|dev/       |content aimed at developers|
|-----------+---------------------------|
|dev/images/|images used by the dev docs|
|-----------+---------------------------|
|ops/       |content aimed at operations|
|-----------+---------------------------|
|ops/images/|images used by the ops docs|
|-----------+---------------------------|
|man/       |manpages                   |
+---------------------------------------+

Additional subdirectories are used as needed to structure the documents, like 
dev/tutorial/, ops/tutorial/ etc.

30.3.3. Headings and document structure

Each document starts over with headings from level zero (the document title).
Each document should have an id. In some cases sections in the document need to
have id’s as well, this depends on where they fit in the overall structure. To
be able to link to content, it has to have an id. Missing id’s in mandatory
places will fail the build.

This is how a document should start:

[[unique-id-verbose-is-ok]]
The Document Title
==================

To push the headings down to the right level in the output, the leveloffset
attribute is used when including the document inside of another document.

Subsequent headings in a document should use the following syntax:

== Subheading ==

... content here ...

=== Subsubheading ===

content here ...

Asciidoc comes with one more syntax for headings, but in this project it’s not
used.

30.3.4. Writing

Put one sentence on each line. This makes it easy to move content around, and
also easy to spot (too) long sentences.

30.3.5. Gotchas

  * A chapter can’t be empty. (the build will fail on the docbook xml validity
    check)
  * The document title should be "underlined" by the same number of = as there
    are characters in the title.
  * Always leave a blank line at the end of documents (or the title of the next
    document might end up in the last paragraph of the document)
  * As {} are used for Asciidoc attributes, everything inside will be treated
    as an attribute. What you have to do is to escape the opening brace: \{. If
    you don’t, the braces and the text inside them will be removed without any
    warning being issued!

30.3.6. Links

To link to other parts of the manual the id of the target is used. This is how
such a reference looks:

<<community-docs-overall-flow>>

Which will render like: Section 30.3.1, “Overall Flow”

Note

Just write "see <<target-id>>" and similar, that should suffice in most cases.

If you need to link to another document with your own link text, this is what
to do:

<<target-id, link text that fits in the context>>

Note

Having lots of linked text may work well in a web context but is a pain in
print, and we aim for both!

External links are added like this:

http://neo4j.org/[Link text here]

Which renders like: Link text here <http://neo4j.org/>

For short links it may be better not to add a link text, just do:

http://neo4j.org/

Which renders like: http://neo4j.org/ <http://neo4j.org/>

Note

It’s ok to have a dot right after the URL, it won’t be part of the link.

30.3.7. Text Formatting

  * _Italics_ is rendered as Italics
  * Bold - just don’t do it, the editor in charge is likely to remove it
    anyhow!
  * +methodName()+ is rendered as methodName() and is used for literals as well
    (note: the content between the + signs will be parsed).
  * `command` is rendered as command (typically used for command-line) (note:
    the content between the ` signs will not be parsed).
  * 'my/path/' is rendered as my/path/ (used for file names and paths).
  * ``Double quoted'' (that is two grave accents to the left and two acute
    accents to the right) renders as “Double quoted”.
  * `Single quoted' (that is a single grave accent to the left and a single
    acute accent to the right) renders as ‘Single quoted’.

30.3.8. Admonitions

These are very useful and should be used where appropriate. Choose from the
following (write all caps and no, we can’t easily add new ones):

Note

Note.

Tip

Tip.

Important

Important

Caution

Caution

Warning

Warning

Here’s how it’s done:

NOTE: Note.

A multiline variation:

[TIP]
Tiptext.
Line 2.

Which is rendered as:

Tip

Tiptext. Line 2.

30.3.9. Images

Important

All images in the entire manual share the same namespace. You know how to
handle that.

30.3.9.1. Images Files

To include an image file, make sure it resides in the images/ directory
relative to the document you’re including it from. Then go:

image::neo4j-logo.png[]

Which is rendered as:

neo4j-logo.png

30.3.9.2. Static Graphviz/DOT

We use the Graphviz/DOT language to describe graphs. For documentation see
http://graphviz.org/ <http://graphviz.org/>.

This is how to include a simple example graph:

 ["dot", "community-docs-graphdb-rels.svg"]
 ----
 "Start node" -> "End node" [label="relationship"]
 ----

Which is rendered as:

community-docs-graphdb-rels.svg

Here’s an example using some predefined variables available in the build:

 ["dot", "community-docs-graphdb-rels-overview.svg", "meta"]
 ----
 "A Relationship" [fillcolor="NODEHIGHLIGHT"]
 "Start node" [fillcolor="NODE2HIGHLIGHT"]
 "A Relationship" -> "Start node" [label="has a"]
 "A Relationship" -> "End node" [label="has a"]
 "A Relationship" -> "Relationship type" [label="has a"]
 Name [TEXTNODE]
 "Relationship type" -> Name [label="uniquely identified by" color="EDGEHIGHLIGHT" fontcolor="EDGEHIGHLIGHT"]
 ----

Which is rendered as:

community-docs-graphdb-rels-overview.svg

The optional second argument given to the dot filter defines the style to use:

  * when not defined: Default styling for nodespace examples.
  * neoviz: Nodespace view generated by Neoviz.
  * meta: Graphs that don’t resemble db contents, but rather concepts.

Caution

Keywords of the DOT language have to be surrounded by double quotes when used
for other purposes. The keywords include node, edge, graph, digraph, subgraph,
and strict.

30.3.10. Attributes

Common attributes you can use in documents:

  * {neo4j-version} - rendered as "1.8.M04"
  * {neo4j-git-tag} - rendered as "1.8.M04"
  * {lucene-version} - rendered as "3_5_0"

These can substitute part of URLs that point to for example APIdocs or source
code. Note that neo4j-git-tag also handles the case of snapshot/master.

Sample Asciidoc attributes which can be used:

  * {docdir} - root directory of the documents
  * {nbsp} - non-breaking space

30.3.11. Comments

There’s a separate build including comments. The comments show up with a yellow
background. This build doesn’t run by default, but after a normal build, you
can use make annotated to build it. You can also use the resulting page to
search for content, as the full manual is on a single page.

Here’s how to write a comment:

// this is a comment

The comments are not visible in the normal build. Comment blocks won’t be
included in the output of any build at all. Here’s a comment block:

////
Note that includes in here will still be processed, but not make it into the output.
That is, missing includes here will still break the build!
////

30.3.12. Code Snippets

30.3.12.1. Explicitly defined in the document

Warning

Use this kind of code snippets as little as possible. They are well known to
get out of sync with reality after a while.

This is how to do it:

 [source,cypher]
 ----
 start n=(2, 1) where (n.age < 30 and n.name = "Tobias") or not(n.name = "Tobias")  return n
 ----

Which is rendered as:

start n=(2, 1) where (n.age < 30 and n.name = "Tobias") or not(n.name = "Tobias")  return n

If there’s no suitable syntax highlighter, just omit the language: [source].

Currently the following syntax highlighters are enabled:

  * Bash
  * Cypher
  * Groovy
  * Java
  * JavaScript
  * Python
  * XML

For other highlighters we could add see http://alexgorbatchev.com/
SyntaxHighlighter/manual/brushes/ <http://alexgorbatchev.com/SyntaxHighlighter/
manual/brushes/>.

30.3.12.2. Fetched from source code

Code can be automatically fetched from source files. You need to define:

  * component: the artifactId of the Maven coordinates,
  * source: path to the file inside the jar it’s deployed to,
  * classifier: sources or test-sources or any other classifier pointing to the
    artifact,
  * tag: tag name to search the file for,
  * the language of the code, if a corresponding syntax highlighter is
    available.

Note that the artifact has to be included as a Maven dependency of the Manual
project so that the files can be found.

Be aware of that the tag "abc" will match "abcd" as well. It’s a simple on/off
switch, meaning that multiple occurrences will be assembled into a single code
snippet in the output. This behavior can be user to hide away assertions from
code examples sourced from tests.

This is how to define a code snippet inclusion:

 [snippet,java]
 ----
 component=neo4j-examples
 source=org/neo4j/examples/JmxTest.java
 classifier=test-sources
 tag=getStartTime
 ----

This is how it renders:

private static Date getStartTimeFromManagementBean(
        GraphDatabaseService graphDbService )
{
    GraphDatabaseAPI graphDb = (GraphDatabaseAPI) graphDbService;
    Kernel kernel = graphDb.getSingleManagementBean( Kernel.class );
    Date startTime = kernel.getKernelStartTime();
    return startTime;
}

30.3.12.3. Query Results

There’s a special filter for Cypher query results. This is how to tag a query
result:

 .Result
 [queryresult]
 ----
 +----------------------------------+
 | friend_of_friend.name | count(*) |
 +----------------------------------+
 | Ian                   | 2        |
 | Derrick               | 1        |
 | Jill                  | 1        |
 +----------------------------------+
 3 rows, 12 ms
 ----

This is how it renders:

Table 30.1. Result

+-------------------------------+
|friend_of_friend.name |count(*)|
|-------------------------------|
|3 rows, 12 ms                  |
|-------------------------------|
|Ian                   |2       |
|----------------------+--------|
|Derrick               |1       |
|----------------------+--------|
|Jill                  |1       |
+-------------------------------+


30.3.13. A sample Java based documentation test

For Java, there are a couple of premade utilities that keep code and
documentation together in Javadocs and code snippets that generate Asciidoc for
the rest of the toolchain.

To illustrate this, look at the following documentation that generates the
Asciidoc file hello-world-title.txt with a content of:

[[examples-hello-world-sample-chapter]]
Hello world Sample Chapter
==========================

This is a sample documentation test, demonstrating different ways of
bringing code and other artifacts into Asciidoc form. The title of the
generated document is determined from the method name, replacing "+_+" with
" ".

Below you see a number of different ways to generate text from source,
inserting it into the JavaDoc documentation (really being Asciidoc markup)
via the +@@+ snippet markers and programmatic adding with runtime data
in the Java code.

- The annotated graph as http://www.graphviz.org/[GraphViz]-generated visualization:

.Hello World Graph
["dot", "Hello-World-Graph-hello-world-Sample-Chapter.svg", "neoviz"]
----
  N1 [
    label = "{Node\[1\]|name = \'you\'\l}"
  ]
  N2 [
    label = "{Node\[2\]|name = \'I\'\l}"
  ]
  N2 -> N1 [
    color = "#2e3436"
    fontcolor = "#2e3436"
    label = "know\n"
  ]
----

- A sample Cypher query:

[source,cypher]
----
START n = node(2)
RETURN n
----

- A sample text output snippet:

[source]
----
Hello graphy world!
----

- a generated source link to the original GIThub source for this test:

https://github.com/neo4j/community/blob/{neo4j-git-tag}/embedded-examples/src/test/java/org/neo4j/examples/DocumentationTest.java[DocumentationTest.java]

- The full source for this example as a source snippet, highlighted as Java code:

[snippet,java]
----
component=neo4j-examples
source=org/neo4j/examples/DocumentationTest.java
classifier=test-sources
tag=sampleDocumentation
----

This is the end of this chapter.

this file is included in this documentation via

  :leveloffset: 3
  include::{importdir}/neo4j-examples-docs-jar/dev/examples/hello-world-sample-chapter.txt[]

which renders the following chapter:

30.3.14. Hello world Sample Chapter

This is a sample documentation test, demonstrating different ways of bringing
code and other artifacts into Asciidoc form. The title of the generated
document is determined from the method name, replacing "_" with " ".

Below you see a number of different ways to generate text from source,
inserting it into the JavaDoc documentation (really being Asciidoc markup) via
the @@ snippet markers and programmatic adding with runtime data in the Java
code.

  * The annotated graph as GraphViz <http://www.graphviz.org/>-generated
    visualization:

Figure 30.1. Hello World Graph

Hello-World-Graph-hello-world-Sample-Chapter.svg


  * A sample Cypher query:

START n = node(2)
RETURN n

  * A sample text output snippet:

Hello graphy world!

  * a generated source link to the original GIThub source for this test:

DocumentationTest.java <https://github.com/neo4j/community/blob/1.8.M04/
embedded-examples/src/test/java/org/neo4j/examples/DocumentationTest.java>

  * The full source for this example as a source snippet, highlighted as Java
    code:

// START SNIPPET: _sampleDocumentation
package org.neo4j.examples;

import org.junit.Test;
import org.neo4j.kernel.impl.annotations.Documented;
import org.neo4j.test.GraphDescription.Graph;

import static org.neo4j.visualization.asciidoc.AsciidocHelper.*;

public class DocumentationTest extends AbstractJavaDocTestbase
{
    /**
     * This is a sample documentation test, demonstrating different ways of
     * bringing code and other artifacts into Asciidoc form. The title of the
     * generated document is determined from the method name, replacing "+_+" with
     * " ".
     *
     * Below you see a number of different ways to generate text from source,
     * inserting it into the JavaDoc documentation (really being Asciidoc markup)
     * via the +@@+ snippet markers and programmatic adding with runtime data
     * in the Java code.
     *
     * - The annotated graph as http://www.graphviz.org/[GraphViz]-generated visualization:
     *
     * @@graph
     *
     * - A sample Cypher query:
     *
     * @@cypher
     *
     * - A sample text output snippet:
     *
     * @@output
     *
     * - a generated source link to the original GIThub source for this test:
     *
     * @@github
     *
     * - The full source for this example as a source snippet, highlighted as Java code:
     *
     * @@sampleDocumentation
     *
     * This is the end of this chapter.
     */
    @Test
    // signaling this to be a documentation test
    @Documented
    // the graph data setup as simple statements
    @Graph( "I know you" )
    // title is determined from the method name
    public void hello_world_Sample_Chapter()
    {
        // initialize the graph with the annotation data
        data.get();
        gen.get().addTestSourceSnippets( this.getClass(), "sampleDocumentation" );
        gen.get().addGithubTestSourceLink( "github", this.getClass(), "neo4j/community",
                "embedded-examples" );

        gen.get().addSnippet( "output",
                createOutputSnippet( "Hello graphy world!" ) );

        gen.get().addSnippet(
                "graph",
                createGraphVizWithNodeId( "Hello World Graph", graphdb(),
                        gen.get().getTitle() ) );
        // A cypher snippet referring to the generated graph in the start clause
        gen.get().addSnippet(
                "cypher",
                createCypherSnippet( "start n = node(" + data.get().get( "I" ).getId()
                                     + ") return n" ) );
    }
}
// END SNIPPET: _sampleDocumentation

This is the end of this chapter.

30.3.15. Integrated Live Console

An interactive console can be added and will show up in the online HTML
version. An optional title can be added, which will be used for the text of the
button.

This is how to do it, using Geoff to define the data, with an empty line to
separate it from the query:

 .Interactive Matrix Example
 [console]
 ----
 (A) {"name" : "Neo"};
 (B) {"name" : "Trinity"};
 (A)-[:LOVES]->(B)

 start n = node(*)
 return n
 ----

And this is the result:

30.3.16. Toolchain

Useful links when configuring the docbook toolchain:

  * http://www.docbook.org/tdg/en/html/docbook.html <http://www.docbook.org/tdg
    /en/html/docbook.html>
  * http://www.sagehill.net/docbookxsl/index.html <http://www.sagehill.net/
    docbookxsl/index.html>
  * http://docbook.sourceforge.net/release/xsl/1.76.1/doc/html/index.html
    <http://docbook.sourceforge.net/release/xsl/1.76.1/doc/html/index.html>
  * http://docbook.sourceforge.net/release/xsl/1.76.1/doc/fo/index.html <http:/
    /docbook.sourceforge.net/release/xsl/1.76.1/doc/fo/index.html>

30.4. Contributing Code to Neo4j

30.4.1. Intro

The Neo4j community is a free software and open source community centered
around software and components for the Neo4j Graph Database. It is sponsored by
Neo Technology <http://neotechnology.com>, which provides infrastructure
(different kinds of hosting, documentation, etc) as well as people to manage
it. The Neo4j community is an open community, in so far as it welcomes any
member that accepts the basic criterias of contribution and adheres to the
community’s Code of Conduct.

Contribution can be in many forms (documentation, discussions, bug reports).
This document outlines the rules of governance for a contributor of code.

30.4.2. The Fast Track

One crucial aspect of contributing is the Contributor License Agreement. In
short: make sure to sign the CLA, or the Neo4j project won’t be able to accept
your contribution.

30.4.3. Governance fundamentals

In a nutshell, you need to be aware of the following fundamentals if you wish
to contribute code:

  * All software published by the Neo4j project must have been contributed
    under the Neo4j Code Contributor License Agreement.
  * Neo4j is a free software and open source community. As a contributor, you
    are free to place your work under any license that has been approved by
    either the Free Software Foundation <http://fsf.org> or the Open Source
    Initiative <http://opensource.org>. You still retain copyright, so in
    addition to that license you can of course release your work under any
    other license (for example a fully proprietary license), just not on the
    Neo4j infrastructure.
  * The Neo4j software is split into components. A Git repository holds either
    a single or multiple components.
  * The source code should follow the Neo4j Code Style and “fit in” with the
    Neo4j infrastructure as much as is reasonable for the specific component.

30.4.4. Contributor roles

Every individual that contributes code does so in the context of a role (a
single individual can have multiple roles). The role defines their
responsibilities and privileges:

  * A patch submitter is a person who wishes to contribute a patch to an
    existing component. See Workflow below.
  * A committer can contribute code directly to one or more components.
  * A component maintainer is in charge of a specific component. They can:

      o commit code in their component’s repository,
      o manage tickets for the repository,
      o grant push rights to the repository.
  * A Neo4j admin manages the Neo4j infrastructure. They:

      o define new components and assign component maintainership,
      o drive, mentor and coach Neo4j component development.

30.4.5. Code Style

The Neo4j Code style is maintained on GitHub in styles for the different IDEs
<https://github.com/neo4j/neo4j.github.com/tree/master/code-style>.

30.4.6. Unit Tests

You have a much higher chance of getting your changes accepted if you supply us
with small, readable unit tests that test the code you’ve written. Also, make
sure your code doesn’t break any existing tests. See the advice on building
below. Note that there may be downstream components that need to be tested as
well, depending on what you change.

30.4.7. Workflow

  * Fork the appropriate repository on GitHub, and clone it.
  * Create a new, appropriately named branch in your local repository for that
    specific feature or bugfix. Keeping a new branch for each feature ensures
    we can easily pull in your changes without pulling in any other commits
    that are not supposed to be pulled.
  * Modify the code to do what you want (e.g. fix a bug, implement a feature).
  * Make sure your changeset has unit tests that are readable and relevant for
    your change. Try to do this even for small fixes. You never know whether
    you have introduced some weird bug without testing.
  * Run the Maven build frequently so you know if you’ve introduced any
    unexpected issues (mvn clean verify). Running tests from your IDE isn’t
    repeatable enough, even if you run all of the tests in the project.
  * When adding new functionality or changing existing code significantly, be
    sure to add or update Javadoc comments to non-trivial classes and methods.
    Also check if the manual is affected by your change and needs to be
    updated, see Section 30.3, “Writing Neo4j Documentation”.
  * Give each commit an appropriate commit message, so that others who are not
    familiar with the matter get a good idea of what you have changed.
  * Once you are satisfied with your changes, merge with our upstream
    repository. We can pull your stuff, but since you know best what you
    changed, you should do the merge. Use rebase and/or squash commits as
    appropriate!
  * This is a good point to do one last clean build to see that the merge
    hasn’t broken your code.
  * Push to your remote repository on GitHub.
  * Send a Pull Request with a description of what you changed via the button
    in the GitHub interface of your repository. If you know the person
    responsible for the component, be sure to mention him in the Pull Request
    (e.g. @user) so he will be notified.

30.4.8. Commit messages

Please take some care in providing good commit messages. Use your common sense.
In particular:

  * Use english. This includes proper punctuation and correct spelling. Commit
    messages are supposed to convey some information at a glance — they’re not
    a chat room.
  * Remember that a commit is a changeset, which describes a cohesive set of
    changes across potentially many files. Try to group every commit as a
    logical change. Explain what it changes. If you have to redo work, you
    might want to clean up your commit log before doing a pull request.
  * If you fix a bug or an issue that’s related to a ticket, then refer to the
    ticket in the message. For example, `‘Added this and then changed that.
    This fixes #14.’' Just mentioning #xxx in the commit will connect it to the
    GitHub issue with that number, see GitHub issues <https://github.com/blog/
    831-issues-2-0-the-next-generation>. Any of these synonyms will also work:

      o fixes #xxx
      o fixed #xxx
      o fix #xxx
      o closes #xxx
      o close #xxx
      o closed #xxx.
  * Remember to convey intent. Don’t be too brief but don’t provide too much
    detail, either. That’s what git diff is for.

30.5. Contributors

As an Open Source Project, the Neo4j User community extends its warmest thanks
to all the contributors who have signed the Section 30.1, “Contributor License
Agreement” to date and are contributing to this collective effort.

+-------------------------------------------------------------------------+
|name                |GIThub ID                                           |
|--------------------+----------------------------------------------------|
|Johan Svensson      |johan-neo <https://github.com/johan-neo>            |
|--------------------+----------------------------------------------------|
|Emil Eifrem         |emileifrem <https://github.com/emileifrem>          |
|--------------------+----------------------------------------------------|
|Peter Neubauer      |peterneubauer <https://github.com/peterneubauer>    |
|--------------------+----------------------------------------------------|
|Mattias Persson     |tinwelint <https://github.com/tinwelint>            |
|--------------------+----------------------------------------------------|
|Tobias Ivarsson     |thobe <https://github.com/thobe>                    |
|--------------------+----------------------------------------------------|
|Anders Nawroth      |nawroth <https://github.com/nawroth>                |
|--------------------+----------------------------------------------------|
|Andres Taylor       |systay <https://github.com/systay>                  |
|--------------------+----------------------------------------------------|
|Jacob Hansson       |jakewins <https://github.com/jakewins>              |
|--------------------+----------------------------------------------------|
|Jim Webber          |jimwebber <https://github.com/jimwebber>            |
|--------------------+----------------------------------------------------|
|Josh Adell          |jadell <https://github.com/jadell>                  |
|--------------------+----------------------------------------------------|
|Andreas Kollegger   |akollegger <https://github.com/akollegger>          |
|--------------------+----------------------------------------------------|
|Chris Gioran        |digitalstain <https://github.com/digitalstain>      |
|--------------------+----------------------------------------------------|
|Thomas Baum         |tbaum <https://github.com/tbaum>                    |
|--------------------+----------------------------------------------------|
|Alistair Jones      |apcj <https://github.com/apcj>                      |
|--------------------+----------------------------------------------------|
|Michael Hunger      |jexp <https://github.com/jexp>                      |
|--------------------+----------------------------------------------------|
|Jesper Nilsson      |jespernilsson <https://github.com/jespernilsson>    |
|--------------------+----------------------------------------------------|
|Tom Sulston         |tomsulston <https://github.com/tomsulston>          |
|--------------------+----------------------------------------------------|
|David Montag        |dmontag <https://github.com/dmontag>                |
|--------------------+----------------------------------------------------|
|Marlon Richtert     |marlonrichert <https://github.com/marlonrichert>    |
|--------------------+----------------------------------------------------|
|Hugo Josefson       |hugojosefson <https://github.com/hugojosefson>      |
|--------------------+----------------------------------------------------|
|Vivek Prahlad       |vivekprahlad <https://github.com/vivekprahlad>      |
|--------------------+----------------------------------------------------|
|Andriano Almeida    |adrianoalmeida7 <https://github.com/adrianoalmeida7>|
|--------------------+----------------------------------------------------|
|Kevin Moore         |kevmoo <https://github.com/kevmoo>                  |
|--------------------+----------------------------------------------------|
|Benjamin Gehrels    |BGehrels <https://github.com/BGehrels>              |
|--------------------+----------------------------------------------------|
|Christopher Schmidt |FaKod <https://github.com/FaKod>                    |
|--------------------+----------------------------------------------------|
|Pascal Rehfeldt     |prehfeldt <https://github.com/prehfeldt>            |
|--------------------+----------------------------------------------------|
|Björn Söderqvist    |cybear <https://github.com/cybear>                  |
|--------------------+----------------------------------------------------|
|Abdul Azeez         |abdulazeez1984 <https://github.com/abdulazeez1984>  |
|--------------------+----------------------------------------------------|
|James Thornton      |espeed <https://github.com/espeed>                  |
|--------------------+----------------------------------------------------|
|Radhakrishna Kalyan |nrkkalyan <https://github.com/nrkkalyan>            |
|--------------------+----------------------------------------------------|
|Michel van den Berg |promontis <https://github.com/promontis>            |
|--------------------+----------------------------------------------------|
|Brandon McCauslin   |bm3780 <https://github.com/bm3780>                  |
|--------------------+----------------------------------------------------|
|Hendy Irawan        |ceefour <https://github.com/ceefour>                |
|--------------------+----------------------------------------------------|
|Luanne Misquitta    |luanne <https://github.com/luanne>                  |
|--------------------+----------------------------------------------------|
|Jim Radford         |radford <https://github.com/radford>                |
|--------------------+----------------------------------------------------|
|Axel Morgner        |amorgner <https://github.com/amorgner>              |
|--------------------+----------------------------------------------------|
|Taylor Buley        |editor <https://github.com/editor>                  |
|--------------------+----------------------------------------------------|
|Alex Smirnow        |alexsmirnov <https://github.com/alexsmirnov>        |
|--------------------+----------------------------------------------------|
|Johannes Mockenhaupt|jotomo <https://github.com/jotomo>                  |
+-------------------------------------------------------------------------+

-------------------------------------------------------------------------------

Appendix A. Manpages

-------------------------------------------------------------------------------

The Neo4j Unix manual pages are included on the following pages.

Name

neo4j — Neo4j Server control and management

Synopsis

neo4j <command>

DESCRIPTION

Neo4j is a graph database, perfect for working with highly connected data.

COMMANDS

console
    Start the server as an application, running as a foreground proces. Stop
    the server using CTRL-C.
start
    Start server as daemon, running as a background process.
stop
    Stops a running daemonized server.
restart
    Restarts the server.
status
    Current running state of the server.
install
    Installs the server as a platform-appropriate system service.
remove
    Uninstalls the system service.
info
    Displays configuration information, such as the current NEO4J_HOME and
    CLASSPATH.

Usage - Windows

Neo4j.bat

Double-clicking on the Neo4j.bat script will start the server in a console. To
quit, just press control-C in the console window.

Neo4j.bat install/remove

Neo4j can be installed and run as a Windows Service, running without a console
window. You’ll need to run the scripts with Administrator priveleges. Just use
the Neo4j.bat script with the proper argument:

  * Neo4j.bat install - install as a Windows service

      o will install the service
  * Neo4j.bat remove - remove the Neo4j service

      o will stop and remove the Neo4j service
  * Neo4j.bat start - will start the Neo4j service

      o will start the Neo4j service if installed or a console
      o session otherwise.
  * Neo4j.bat stop - stop the Neo4j service if running
  * Neo4j.bat restart - restart the Neo4j service if installed
  * Neo4j.bat status - report on the status of the Neo4j service

      o returns RUNNING, STOPPED or NOT INSTALLED

FILES

conf/neo4j-server.properties
    Server configuration.
conf/neo4j-wrapper.conf
    Configuration for service wrapper.
conf/neo4j.properties
    Tuning configuration for the database.

-------------------------------------------------------------------------------

Name

neo4j-shell — a command-line tool for exploring and manipulating a graph
database

Synopsis

neo4j-shell [REMOTE OPTIONS]

neo4j-shell [LOCAL OPTIONS]

DESCRIPTION

Neo4j shell is a command-line shell for browsing the graph, much like how the
Unix shell along with commands like cd, ls and pwd can be used to browse your
local file system. The shell can connect directly to a graph database on the
file system. To access local a local database used by other processes, use the
readonly mode.

REMOTE OPTIONS

-port PORT
    Port of host to connect to (default: 1337).
-host HOST
    Domain name or IP of host to connect to (default: localhost).
-name NAME
    RMI name, i.e. rmi://<host>:<port>/<name> (default: shell).
-readonly
    Access the database in read-only mode. The read-only mode enables browsing
    a database that is used by other processes.

LOCAL OPTIONS

-path PATH
    The path to the database directory. If there is no database at the
    location, a new one will e created.
-pid PID
    Process ID to connect to.
-readonly
    Access the database in read-only mode. The read-only mode enables browsing
    a database that is used by other processes.
-c COMMAND
    Command line to execute. After executing it the shell exits.
-config CONFIG
    The path to the Neo4j configuration file to be used.

EXAMPLES

Examples for remote:

  neo4j-shell
  neo4j-shell -port 1337
  neo4j-shell -host 192.168.1.234 -port 1337 -name shell
  neo4j-shell -host localhost -readonly

Examples for local:

  neo4j-shell -path /path/to/db
  neo4j-shell -path /path/to/db -config /path/to/neo4j.config
  neo4j-shell -path /path/to/db -readonly

-------------------------------------------------------------------------------

Name

neo4j-backup — Neo4j Backup Tool

Synopsis

neo4j-backup {-full|-incremental} -from SourceURI -to Directory [-cluster
ClusterName]

DESCRIPTION

A tool to perform live backups over the network from a running Neo4j graph
database onto a local filesystem. Backups can be either full or incremental.
The first backup must be a full backup, after that incremental backups can be
performed.

The source(s) are given as URIs in a special format, the target is a filesystem
location.

BACKUP TYPE

-full
    copies the entire database to a directory.
-incremental
    copies the changes that have taken place since the last full or incremental
    backup to an existing backup store.

SOURCE URI

Backup sources are given in the following format:

<running mode>://<host>[:<port>][,<host>[:<port>]]…

Note that multiple hosts can be defined.

running mode
    'single' or 'ha'. 'ha' is for instances in High Availability mode, 'single'
    is for standalone databases.
host
    In single mode, the host of a source database; in ha mode, the host of a
    coordinator instance. Note that multiple hosts can be given when using High
    Availability mode.
port
    In single mode, the port of a source database backup service; in ha mode,
    the port of a coordinator instance backup service. If not given, the
    default value 6362 will be used.

CLUSTER NAME

-cluster
    If you have specified a cluster name for your High Availability cluster,
    you need to specify it when doing backups. Add the config parameter:
    -cluster my_custom_cluster_name

IMPORTANT

Backups can only be performed on databases which have the configuration
parameter enable_online_backup=true set. That will make the backup service
available on the default port (6362). To enable the backup service on a
different port use for example enable_online_backup=port=9999 instead.

Usage - Windows

The Neo4jBackup.bat script is used in the same way.

EXAMPLES

# Performing a full backup
neo4j-backup -full -from single://192.168.1.34 -to /mnt/backup/neo4j-backup

# Performing an incremental backup
neo4j-backup -incremental -from single://freja -to /mnt/backup/neo4j-backup

# Performing an incremental backup where the service is registered on a custom port
neo4j-backup -incremental -from single://freja:9999 -to /mnt/backup/neo4j-backup

# Performing a full backup from HA cluster, specifying two possible coordinators
./neo4j-backup -full -from ha://oden:2181,loke:2181 -to /mnt/backup/neo4j-backup

# Performing an incremental backup from HA cluster, specifying only one coordinator
./neo4j-backup -incremental -from ha://oden:2181 -to /mnt/backup/neo4j-backup

# Performing an incremental backup from HA cluster with a specific name
# (specified by neo4j configuration 'ha.cluster_name')
./neo4j-backup -incremental -from ha://balder:2181 -to /mnt/backup/neo4j-backup -cluster my-cluster

RESTORE FROM BACKUP

The Neo4j backups are fully functional databases. To use a backup, replace your
database directory with the backup.

-------------------------------------------------------------------------------

Name

neo4j-coordinator — Neo4j Coordinator for High-Availability clusters

Synopsis

neo4j-coordinator <command>

DESCRIPTION

Neo4j Coordinator is a server which provides coordination for a Neo4j High
Availability Data cluster. A "coordination cluster" must be started and
available before the "data cluster" can be started. This server is a member of
the cluster.

COMMANDS

console
    Start the server as an application, running as a foreground proces. Stop
    the server using CTRL-C.
start
    Start server as daemon, running as a background process.
stop
    Stops a running daemonized server.
restart
    Restarts a running server.
status
    Current running state of the server
install
    Installs the server as a platform-appropriate system service.
remove
    Uninstalls the system service

FILES

conf/coord.cfg
    Coordination server configuration.
conf/coord-wrapper.cfg
    Configuration for service wrapper.
data/coordinator/myid
    Unique identifier for coordinator instance.

-------------------------------------------------------------------------------

Name

neo4j-coordinator-shell — Neo4j Coordinator Shell interactive interface

Synopsis

neo4j-coordinator-shell -server <host:port> [<cmd> <args>]

DESCRIPTION

Neo4j Coordinator Shell provides an interactive text-based interface to a
running Neo4j Coordinator server.

OPTIONS

-server HOST:PORT
    Connects to a Neo4j Coordinator at the specified host and port.


-------------------------------------------------------------------------------

Appendix B. Questions & Answers

-------------------------------------------------------------------------------

Q: What is the maximum number of nodes supported? What is the maximum number of
   edges supported per node?

A: At the moment it is 34.4 billion nodes, 34.4 billion relationships, and 68.7
   billion properties, in total.

Q: What is the largest complete connected graph supported (i.e. every node is
   connecting to all other nodes)?

A: Theoretical limits can be derived from numbers above: It basically comes out
   to a full graph of 262144 nodes and 34359607296 relationships. We have never
   seen this use case though.

Q: Are read/write depending on the number of nodes/edges in the DB?

A: This question can mean a couple of different things. The performance of a
   single read/write operation does not depend on the size of the DB. Whether
   the graph has 10 nodes or 10 million nodes does not matter.  — There is
   however another facet here, which is that if your graph is big on disk, you
   may not be able to fit it all into the cache in RAM. Therefore, you may end
   up hitting disk more often. Most customers don’t have graphs of this size,
   but some do. If you happen to reach these sizes, we have approaches for
   scaling out on multiple machines to mitigate the performance impact by
   increasing the cache "surface area" across machines.

Q: How many concurrent read/write requests supported?

A: There is no limit on the number of concurrent requests. The amount of
   requests we can serve per second depends very much on the operation
   performed (heavy write operation, simple read, complex traversal, etc.), and
   the hardware used. A rough estimate is 1,000 hops per millisecond while
   traversing the graph in the simplest way possible. After a discussion about
   the specific use case, we would be able to give a better idea of the
   performance one can expect.

Q: How is data consistency maintained in cluster environment?

A: Master-slave replication. Slaves pull changes from the master. The pull
   interval can be configured per slave, from subsecond to minutes, as
   necessary. HA can also write through slaves. When that happens, the slave
   that is being written through catches up with the master, and then the write
   is made durable on the slave and the master. The other slaves then catch up
   as normal.

Q: How is the latency in updating all the servers when there is an update on
   the DB from one of them?

A: Pull interval can be configured per slave, from subsecond to minutes, as
   necessary. When writing through a slave, the slave is immediately
   synchronized with the master before the write is committed on the slave and
   the master. In general, read/write load does not affect slaves syncing up. A
   heavy write load will however put pressure on the filesystem of the master,
   which is also required for reading changes for the slaves. In practice, we
   have however not seen this become a notable issue.

Q: Will the latency increase proportional to the number of servers in the
   cluster?

A: When scaling beyond 10s of slaves in a cluster, we anticipate that the
   number of pull requests coming from slaves will reduce the performance of
   the master. Only write performance on the cluster would be affected. Read
   performance would continue to scale linearly.

Q: Is online expansion supported? In other words, do we need to bring down all
   the servers and the DB if we want to add new servers to the cluster?

A: New slaves can be added to an existing cluster without having to stop and
   start the whole cluster. Our HA protocol will bring a newly added slave
   up-to-date. Slaves can also be removed simply by shutting them down.

Q: How long will it take for the newly joined servers to sync up?

A: We recommend providing a new slave with a recent snapshot of the database
   before bringing it online. This is typically done from a backup. The slave
   will then only need to synchronize the most recent updates, which will
   typically be a matter of seconds.

Q: How long does it take to reboot?

A: If by reboot, you mean take the cluster down and take it up again, it’s
   pretty much dependent on how fast you can type. So it could be <10s. The
   Neo4j caches will however not auto-warm up, but the OS filesystem cache will
   retain its data.

Q: Are there any backup and restore/recovery mechanisms?

A: Neo4j Enterprise Edition provides an online backup feature for full and
   incremental backups during operation.

Q: Is cross-continental clustering supported? Say, can servers in the cluster
   be located in different continents provided that the chance for
   inter-continental communication is much lower than the intra one?

A: We have customers who have tested multi-region deployments in AWS.
   Cross-continental latencies will have an impact, however on the efficiency
   of the cluster management and synchronization protocols; large latencies in
   the cluster management can trigger frequent master re-elections, which will
   slow down the cluster. Feature support in this area will be improving over
   time.

Q: Is there any special handling/policy for this kind of setup?

A: We’d have to have a more in-depth discussion about the requirements
   pertaining to this specific deployment.

Q: Is writing to the DB thread-safe? Or is it the application logic to protect
   writing to the same nodes/edges?

A: Whether in single instance or HA mode, the database provides thread safety
   by way of locking on nodes and relationships upon modification.

Q: What is the best strategy for reading back your writes on HA?

A:  1. Sticky sessions.
    2. Send back data in response, removing the need to read back in a separate
       request.
    3. Force a pull of updates from the master when required by the operation.

Q: What is the best strategy for get-or-create semantics?

A:  1. Single thread.
    2. If not exists, pessimistically lock on a common node (or set of common
       nodes).
    3. If not exists, optimistically create, and then double check afterwards.
       (explanation will be extended)

Q: How does locking work?

A: Pessimistic locking. Locks are never required for reading. Writers will not
   block readers. It’s impossible to make a read operation block without using
   explicit locking facilities. Read locks prevent writes. Acquiring a read
   lock means consistent view for all holders while held. Grabbing write locks
   is done automatically when a node/rel is modified/created, or through
   explicit locking facilities. It can be used to provide read committed
   semantics and data consistency when necessary.

Q: What about on-size storage?

A: Neo4j is currently not suitable for storing BLOBs/CLOBs. Nodes,
   relationships, and properties are not co-located on disk. This might be
   introduced in the future.

Q: What about indexing?

A: Neo4j supports composite property indices. Promote index providers over
   in-graph indices. Lucene engine manages index paging separately and requires
   some heap for itself Neo4j currently supports one auto indexer and many
   individual indexes (search done via API)

Q: How do I query the database?

A: Core API, Traversal API, REST API, Cypher, Gremlin

Q: Does Neo4j use journaling?

A: Based on write change delta between master and slaves in HA cluster.

Q: How do I tune Neo4j for performance?

A: Uses memory-mapped store files Neo4j caching strategies need to be
   explained:

     * Soft-ref cache: Soft references are cleaned when the GC thinks it’s
       needed. Use if app load isn’t very high & needs memory-sensitive cache
     * Weak-ref cache: GC cleans weak references whenever it finds it. Use if
       app is under heavy load with lots of reads and traversals
     * Strong-ref cache: all nodes & edges are fully cached in memory JVM needs
       pausing under heavy load, e.g., 1/2 minutes pause interval. Larger heap
       sizes good, however 12G and beyond is impractical with GC. 100x
       performance improvement with memory mapped file cache and 1000
       improvement with Java heap comparing to fetching from disk I/O

Q: ACID transactions between master & slaves

A: Synchronous between slave-initiated transaction to master, eventual from
   master to slaves. Concurrent multi slave-initiated transaction support with
   deadlock detection. It’s fully consistent from a data integrity point of
   view, but eventually consistent from sync point of view.

Q: What about the standalone server?

A: The REST API is completely stateless, but it can do batches for larger
   transaction scopes. Thread pooling & thread per socket: For standalone
   server & HA nodes, Neo4j uses Jetty for connection pooling (e.g., 25/node in
   HA cluster)

Q: How is a load balancer used with HA?

A: Typically a small server extension can be written to return 200 or 404
   depending on whether the machine is master or slave. This extension can then
   be polled by the load balancer to determine the master and slave machine
   sets. Writing only to slaves ensures that committed transactions exist in at
   least two places.

Q: What kind of monitoring support does Neo4j provide?

A: Neo4j does not currently have built-in tracing or explain plans. JMX is the
   primary interface for statistics and monitoring. Thread dumps can be used to
   debug a malfunctioning system.

Q: How do I import my data into Neo4j?

A: The Neo4j batch inserter can be used to fill an initial database with data.
   After batch insertion, the store can be used in an embedded or HA
   environment. Future data load/refresh should go directly to Production
   server SQL Importer (built on top of Batch Inserter) is not officially
   supported

